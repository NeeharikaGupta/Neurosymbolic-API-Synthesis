{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"obAfvGV1l_Ho"},"outputs":[],"source":["import pandas as pd\n","import re"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QwVGGPL3v2Og","executionInfo":{"status":"ok","timestamp":1749057194611,"user_tz":420,"elapsed":504,"user":{"displayName":"Vishesh Agrawal","userId":"16926083185186864017"}},"outputId":"ec2b04e3-bd19-45d7-c5f0-e5616fcea9e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Stanford NLP/step2-responses.csv')\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":786},"id":"CTizWm4Ru5Qg","executionInfo":{"status":"ok","timestamp":1749057196555,"user_tz":420,"elapsed":238,"user":{"displayName":"Vishesh Agrawal","userId":"16926083185186864017"}},"outputId":"afb56de9-b2b1-459d-a793-bd357025d4da"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Task  \\\n","0  Write a Python function using TensorFlow to cr...   \n","1  Write a Python script using PyTorch to train a...   \n","2  Create a scikit-learn pipeline that generates ...   \n","3  Write a Python function that uses Hugging Face...   \n","4  Build a TensorFlow model for image classificat...   \n","5  Write a PyTorch class that subclasses torch.ut...   \n","6  Write a Python script that loads the Iris data...   \n","7  Write a Java program using the Hadoop MapReduc...   \n","\n","                                 direct_response_gpt  \\\n","0  ```python\\nimport tensorflow as tf\\nfrom sklea...   \n","1  ```python\\nimport torch\\nimport torch.nn as nn...   \n","2  ```python\\nfrom sklearn.datasets import make_c...   \n","3  ```python\\nfrom datasets import load_dataset\\n...   \n","4  ```python\\nimport tensorflow as tf\\nfrom tenso...   \n","5  ```python\\nimport os\\nfrom PIL import Image\\nf...   \n","6  ```python\\nfrom sklearn.datasets import load_i...   \n","7  ```java\\nimport java.io.IOException;\\nimport j...   \n","\n","                                    cot_response_gpt  \\\n","0  To create a simple linear regression model wit...   \n","1  Certainly! Training a convolutional neural net...   \n","2  Certainly! Let's break down the task and under...   \n","3  To train a `distilbert-base-uncased` model usi...   \n","4  To build an image classification model using t...   \n","5  To create a custom PyTorch dataset class for l...   \n","6  Certainly! I'll guide you step-by-step through...   \n","7  To write a Java program using the Hadoop MapRe...   \n","\n","                                        few_shot_gpt  \\\n","0  Sure, I'll guide you through creating and comp...   \n","1  Below is a complete Python script using PyTorc...   \n","2  To create a complete pipeline that includes da...   \n","3  To train a binary classification model using t...   \n","4  To build an image classification model using t...   \n","5  To create a custom `Dataset` class in PyTorch ...   \n","6  Certainly! Here's a Python script that loads t...   \n","7  Below is the Java program using the Hadoop Map...   \n","\n","                              direct_response_gemini  \\\n","0  ```python\\nimport tensorflow as tf\\nimport num...   \n","1  ```python\\nimport torch\\nimport torch.nn as nn...   \n","2  ```python\\nimport numpy as np\\nfrom sklearn.da...   \n","3  ```python\\nimport torch\\nfrom datasets import ...   \n","4  ```python\\nimport tensorflow as tf\\nfrom tenso...   \n","5  ```python\\nimport torch\\nimport os\\nfrom PIL i...   \n","6  ```python\\nfrom sklearn.datasets import load_i...   \n","7  ```java\\nimport java.io.IOException;\\nimport j...   \n","\n","                                 cot_response_gemini  \\\n","0  Okay, let's create a Python function using Ten...   \n","1  Okay, let's build a Python script using PyTorc...   \n","2  Okay, let's build this scikit-learn pipeline s...   \n","3  Okay, let's create a Python function using Hug...   \n","4  Okay, let's build a TensorFlow model for Fashi...   \n","5  Okay, let's create a PyTorch `Dataset` subclas...   \n","6  Okay, let's write a Python script using scikit...   \n","7  Okay, let's break down how to write a Word Cou...   \n","\n","                                     few_shot_gemini  \n","0  Okay, here is the Python function using Tensor...  \n","1  Okay, here is a complete Python script using P...  \n","2  Okay, here is the scikit-learn code to generat...  \n","3  Okay, here is the Python function `train_tense...  \n","4  Okay, here is the TensorFlow code to build an ...  \n","5  Okay, you've provided examples of a custom dat...  \n","6  ```python\\nimport numpy as np\\nimport matplotl...  \n","7  Okay, here is the Java program using the Hadoo...  "],"text/html":["\n","  <div id=\"df-13176dc6-ad16-48b3-a99d-91f6e73f1ea2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Task</th>\n","      <th>direct_response_gpt</th>\n","      <th>cot_response_gpt</th>\n","      <th>few_shot_gpt</th>\n","      <th>direct_response_gemini</th>\n","      <th>cot_response_gemini</th>\n","      <th>few_shot_gemini</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Write a Python function using TensorFlow to cr...</td>\n","      <td>```python\\nimport tensorflow as tf\\nfrom sklea...</td>\n","      <td>To create a simple linear regression model wit...</td>\n","      <td>Sure, I'll guide you through creating and comp...</td>\n","      <td>```python\\nimport tensorflow as tf\\nimport num...</td>\n","      <td>Okay, let's create a Python function using Ten...</td>\n","      <td>Okay, here is the Python function using Tensor...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Write a Python script using PyTorch to train a...</td>\n","      <td>```python\\nimport torch\\nimport torch.nn as nn...</td>\n","      <td>Certainly! Training a convolutional neural net...</td>\n","      <td>Below is a complete Python script using PyTorc...</td>\n","      <td>```python\\nimport torch\\nimport torch.nn as nn...</td>\n","      <td>Okay, let's build a Python script using PyTorc...</td>\n","      <td>Okay, here is a complete Python script using P...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Create a scikit-learn pipeline that generates ...</td>\n","      <td>```python\\nfrom sklearn.datasets import make_c...</td>\n","      <td>Certainly! Let's break down the task and under...</td>\n","      <td>To create a complete pipeline that includes da...</td>\n","      <td>```python\\nimport numpy as np\\nfrom sklearn.da...</td>\n","      <td>Okay, let's build this scikit-learn pipeline s...</td>\n","      <td>Okay, here is the scikit-learn code to generat...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Write a Python function that uses Hugging Face...</td>\n","      <td>```python\\nfrom datasets import load_dataset\\n...</td>\n","      <td>To train a `distilbert-base-uncased` model usi...</td>\n","      <td>To train a binary classification model using t...</td>\n","      <td>```python\\nimport torch\\nfrom datasets import ...</td>\n","      <td>Okay, let's create a Python function using Hug...</td>\n","      <td>Okay, here is the Python function `train_tense...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Build a TensorFlow model for image classificat...</td>\n","      <td>```python\\nimport tensorflow as tf\\nfrom tenso...</td>\n","      <td>To build an image classification model using t...</td>\n","      <td>To build an image classification model using t...</td>\n","      <td>```python\\nimport tensorflow as tf\\nfrom tenso...</td>\n","      <td>Okay, let's build a TensorFlow model for Fashi...</td>\n","      <td>Okay, here is the TensorFlow code to build an ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Write a PyTorch class that subclasses torch.ut...</td>\n","      <td>```python\\nimport os\\nfrom PIL import Image\\nf...</td>\n","      <td>To create a custom PyTorch dataset class for l...</td>\n","      <td>To create a custom `Dataset` class in PyTorch ...</td>\n","      <td>```python\\nimport torch\\nimport os\\nfrom PIL i...</td>\n","      <td>Okay, let's create a PyTorch `Dataset` subclas...</td>\n","      <td>Okay, you've provided examples of a custom dat...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Write a Python script that loads the Iris data...</td>\n","      <td>```python\\nfrom sklearn.datasets import load_i...</td>\n","      <td>Certainly! I'll guide you step-by-step through...</td>\n","      <td>Certainly! Here's a Python script that loads t...</td>\n","      <td>```python\\nfrom sklearn.datasets import load_i...</td>\n","      <td>Okay, let's write a Python script using scikit...</td>\n","      <td>```python\\nimport numpy as np\\nimport matplotl...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Write a Java program using the Hadoop MapReduc...</td>\n","      <td>```java\\nimport java.io.IOException;\\nimport j...</td>\n","      <td>To write a Java program using the Hadoop MapRe...</td>\n","      <td>Below is the Java program using the Hadoop Map...</td>\n","      <td>```java\\nimport java.io.IOException;\\nimport j...</td>\n","      <td>Okay, let's break down how to write a Word Cou...</td>\n","      <td>Okay, here is the Java program using the Hadoo...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13176dc6-ad16-48b3-a99d-91f6e73f1ea2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-13176dc6-ad16-48b3-a99d-91f6e73f1ea2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-13176dc6-ad16-48b3-a99d-91f6e73f1ea2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-0a7ee2bf-6f50-48af-b02c-1a1180c5d4ef\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a7ee2bf-6f50-48af-b02c-1a1180c5d4ef')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-0a7ee2bf-6f50-48af-b02c-1a1180c5d4ef button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_edc6f363-fcb0-4775-91f6-dd5c8de0bfba\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_edc6f363-fcb0-4775-91f6-dd5c8de0bfba button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Task\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Write a Python script using PyTorch to train a convolutional neural network (CNN) on the Cifar 10 dataset. Include data loading, model definition, training loop, and evaluation\",\n          \"Write a PyTorch class that subclasses torch.utils.data.Dataset to load image files and labels from a folder. Use this class with a DataLoader for batching. Use FashionMNIST dataset.\",\n          \"Write a Python function using TensorFlow to create and compile a simple linear regression model with one dense layer. Train it on the classic California housing dataset.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"direct_response_gpt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"```python\\nimport torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\nimport torchvision\\nimport torchvision.transforms as transforms\\nfrom torch.utils.data import DataLoader\\n\\n# Hyperparameters\\nbatch_size = 32\\nlearning_rate = 0.001\\nnum_epochs = 10\\n\\n# Transformations for the training and test datasets\\ntransform = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\\n])\\n\\n# Loading the CIFAR-10 dataset\\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\\n\\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\\n\\n# Define a simple CNN model\\nclass SimpleCNN(nn.Module):\\n    def __init__(self):\\n        super(SimpleCNN, self).__init__()\\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\\n        self.fc1 = nn.Linear(64 * 8 * 8, 512)\\n        self.fc2 = nn.Linear(512, 10)\\n        self.relu = nn.ReLU()\\n\\n    def forward(self, x):\\n        x = self.pool(self.relu(self.conv1(x)))\\n        x = self.pool(self.relu(self.conv2(x)))\\n        x = x.view(-1, 64 * 8 * 8)\\n        x = self.relu(self.fc1(x))\\n        x = self.fc2(x)\\n        return x\\n\\n# Instantiate the model, define the loss function and the optimizer\\nmodel = SimpleCNN()\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\\n\\n# Training loop\\nfor epoch in range(num_epochs):\\n    running_loss = 0.0\\n    for i, (inputs, labels) in enumerate(train_loader):\\n        optimizer.zero_grad()\\n        outputs = model(inputs)\\n        loss = criterion(outputs, labels)\\n        loss.backward()\\n        optimizer.step()\\n\\n        running_loss += loss.item()\\n        if i % 200 == 199:  # Print every 200 mini-batches\\n            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 200:.3f}')\\n            running_loss = 0.0\\n\\n# Evaluation loop\\ncorrect = 0\\ntotal = 0\\nwith torch.no_grad():\\n    for inputs, labels in test_loader:\\n        outputs = model(inputs)\\n        _, predicted = torch.max(outputs.data, 1)\\n        total += labels.size(0)\\n        correct += (predicted == labels).sum().item()\\n\\nprint('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\\n```\",\n          \"```python\\nimport os\\nfrom PIL import Image\\nfrom torch.utils.data import Dataset, DataLoader\\nfrom torchvision import transforms\\nimport torchvision.datasets as datasets\\n\\nclass FashionMNISTDataset(Dataset):\\n    def __init__(self, root_dir, transform=None):\\n        self.root_dir = root_dir\\n        self.transform = transform\\n        self.data = datasets.FashionMNIST(root=self.root_dir, train=True, download=True)\\n\\n    def __len__(self):\\n        return len(self.data)\\n\\n    def __getitem__(self, idx):\\n        image, label = self.data[idx]\\n        if self.transform:\\n            image = self.transform(image)\\n        return image, label\\n\\n# Define the transform to convert PIL images to tensors\\ntransform = transforms.Compose([\\n    transforms.ToTensor(),\\n])\\n\\n# Initialize the dataset and data loader\\ndataset = FashionMNISTDataset(root_dir='./data', transform=transform)\\ndataloader = DataLoader(dataset, batch_size=64, shuffle=True)\\n\\n# Example of iterating through the DataLoader\\n# for batch in dataloader:\\n#     images, labels = batch\\n#     # process images and labels\\n```\\n\\nThis code defines a `FashionMNISTDataset` class that uses the `FashionMNIST` dataset from `torchvision.datasets`. It then creates an instance of this `Dataset` and wraps it in a `DataLoader` for batching. The data is downloaded and stored in the specified `root_dir`. The transform converts images to tensors, suitable for input into a PyTorch model.\",\n          \"```python\\nimport tensorflow as tf\\nfrom sklearn.datasets import fetch_california_housing\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\n\\ndef create_and_train_linear_regression_model():\\n    # Load and split the California housing dataset\\n    housing = fetch_california_housing()\\n    X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, test_size=0.2, random_state=42)\\n\\n    # Feature scaling\\n    scaler = StandardScaler()\\n    X_train_scaled = scaler.fit_transform(X_train)\\n    X_test_scaled = scaler.transform(X_test)\\n\\n    # Create a simple linear regression model\\n    model = tf.keras.models.Sequential([\\n        tf.keras.layers.Dense(1, input_shape=[X_train.shape[1]])\\n    ])\\n\\n    # Compile the model\\n    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\\n\\n    # Train the model\\n    model.fit(X_train_scaled, y_train, epochs=20, validation_data=(X_test_scaled, y_test))\\n    \\n    return model\\n\\n# Create and train the model\\nmodel = create_and_train_linear_regression_model()\\n```\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cot_response_gpt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Certainly! Training a convolutional neural network (CNN) on the CIFAR-10 dataset using PyTorch involves several steps. I'll guide you through the entire process with detailed explanations.\\n\\n### Step 1: Install Libraries\\n\\nMake sure you have Python and PyTorch installed. You can install PyTorch following the instructions on the [PyTorch website](https://pytorch.org/get-started/locally/). Other libraries we will use can be installed via `pip` if necessary.\\n\\n### Step 2: Import Required Libraries\\n\\nWe need several libraries from PyTorch for handling datasets, defining models, and training. We will also use torchvision, which provides convenient functions for loading datasets like CIFAR-10 and for common network layers.\\n\\n```python\\nimport torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\nimport torchvision\\nimport torchvision.transforms as transforms\\nfrom torch.utils.data import DataLoader\\n```\\n\\n### Step 3: Data Loading\\n\\nThe CIFAR-10 dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. We\\u2019ll use `torchvision` to load this dataset, applying transformations for normalization.\\n\\n```python\\n# Define transformations for the training and test sets\\ntransform = transforms.Compose([\\n    transforms.ToTensor(),  # Convert images to PyTorch tensors\\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the images\\n])\\n\\n# Load the dataset\\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\\ntrainloader = DataLoader(trainset, batch_size=100, shuffle=True)\\n\\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\\ntestloader = DataLoader(testset, batch_size=100, shuffle=False)\\n```\\n\\n### Step 4: Define a CNN Model\\n\\nA simple CNN consists of convolutional layers, followed by pooling layers (for down-sampling), and finally, fully connected layers.\\n\\n```python\\nclass SimpleCNN(nn.Module):\\n    def __init__(self):\\n        super(SimpleCNN, self).__init__()\\n        self.conv1 = nn.Conv2d(3, 6, 5)  # 3 input channels (RGB), 6 output channels, 5x5 kernel\\n        self.pool = nn.MaxPool2d(2, 2)  # 2x2 pooling\\n        self.conv2 = nn.Conv2d(6, 16, 5)  # 6 input channels, 16 output channels, 5x5 kernel\\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Linear layer for 5x5 feature maps to 120 outputs\\n        self.fc2 = nn.Linear(120, 84)\\n        self.fc3 = nn.Linear(84, 10)  # 10 output neurons for 10 classes\\n\\n    def forward(self, x):\\n        x = self.pool(F.relu(self.conv1(x)))\\n        x = self.pool(F.relu(self.conv2(x)))\\n        x = x.view(-1, 16 * 5 * 5)  # Flatten feature map\\n        x = F.relu(self.fc1(x))\\n        x = F.relu(self.fc2(x))\\n        x = self.fc3(x)\\n        return x\\n```\\n\\n### Step 5: Define the Loss and Optimizer\\n\\nThe CrossEntropyLoss is typically used for classification problems, and we will use Stochastic Gradient Descent (SGD) for optimization.\\n\\n```python\\nnet = SimpleCNN()\\n\\ncriterion = nn.CrossEntropyLoss()  # Loss function\\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  # Optimizer\\n```\\n\\n### Step 6: Training Loop\\n\\nThe core of the training process involves looping over our data, performing the forward and backward passes, and updating the weights.\\n\\n```python\\n# Training the network\\nfor epoch in range(10):  # Let's train for 10 epochs\\n    running_loss = 0.0\\n    for i, data in enumerate(trainloader, 0):\\n        # Get the inputs and labels\\n        inputs, labels = data\\n        \\n        # Zero the parameter gradients\\n        optimizer.zero_grad()\\n        \\n        # Forward pass\\n        outputs = net(inputs)\\n        \\n        # Compute the loss\\n        loss = criterion(outputs, labels)\\n        \\n        # Backward pass and optimize\\n        loss.backward()\\n        optimizer.step()\\n        \\n        # Print statistics\\n        running_loss += loss.item()\\n        if i % 100 == 99:  # Print every 100 mini-batches\\n            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\\n            running_loss = 0.0\\n\\nprint('Finished Training')\\n```\\n\\n### Step 7: Model Evaluation\\n\\nAfter training, we evaluate the model on the test dataset to determine its accuracy.\\n\\n```python\\n# Evaluate the network on the test data\\ncorrect = 0\\ntotal = 0\\nwith torch.no_grad():  # Disable gradient computation for evaluation\\n    for data in testloader:\\n        images, labels = data\\n        outputs = net(images)\\n        _, predicted = torch.max(outputs, 1)\\n        total += labels.size(0)\\n        correct += (predicted == labels).sum().item()\\n\\nprint(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\\n```\\n\\n### Step 8: Save the Model\\n\\nFinally, after training, you might want to save the model for later use.\\n\\n```python\\ntorch.save(net.state_dict(), 'cifar10_net.pth')\\n```\\n\\nThere you have the basic steps with a Python script to train a CNN on the CIFAR-10 dataset using PyTorch, including loading data, defining the model, setting up the loss and optimization, training the model, evaluating its performance, and saving it. You can expand upon this by adding features like learning rate scheduling, data augmentation, more complex architectures, and so on, depending on your needs.\",\n          \"To create a custom PyTorch dataset class for loading images and labels from a local folder structure, we need to subclass `torch.utils.data.Dataset`. This custom dataset class will be used in conjunction with a `DataLoader` to handle batching. Here, we'll target the FashionMNIST dataset, which consists of fashion product images in a similar structure to the MNIST handwritten digit dataset.\\n\\nLet's breakdown the process step-by-step:\\n\\n### Step 1: Import Necessary Libraries\\nFirst, import the necessary PyTorch libraries and utilities.\\n\\n```python\\nimport os\\nfrom PIL import Image\\nimport torch\\nfrom torch.utils.data import Dataset, DataLoader\\nfrom torchvision import transforms\\n```\\n\\n- `os`: For operating system-dependent functionality, like directory traversal.\\n- `PIL`: To handle image processing.\\n- `torch`: To access PyTorch functionalities.\\n- `torch.utils.data.Dataset`: For creating custom datasets.\\n- `DataLoader`: For batching and shuffling data.\\n- `transforms`: For image data pre-processing.\\n\\n### Step 2: Create the Custom Dataset Class\\nWe'll define a `FashionMNISTDataset` class that inherits from `Dataset`.\\n\\n```python\\nclass FashionMNISTDataset(Dataset):\\n    def __init__(self, root_dir, transform=None):\\n        self.root_dir = root_dir\\n        self.transform = transform\\n        self.image_files = []\\n        self.labels = []\\n        \\n        # Assuming the directory structure is:\\n        # root_dir/class_name/image1.png\\n        # root_dir/class_name/image2.png\\n        for label, class_name in enumerate(sorted(os.listdir(root_dir))):\\n            class_dir = os.path.join(root_dir, class_name)\\n            if os.path.isdir(class_dir):\\n                for file_name in os.listdir(class_dir):\\n                    if file_name.endswith(('.png', '.jpg', '.jpeg')):\\n                        self.image_files.append(os.path.join(class_dir, file_name))\\n                        self.labels.append(label)\\n\\n    def __len__(self):\\n        return len(self.image_files)\\n\\n    def __getitem__(self, idx):\\n        image_path = self.image_files[idx]\\n        image = Image.open(image_path).convert('L')  # Convert to grayscale\\n        label = self.labels[idx]\\n\\n        if self.transform:\\n            image = self.transform(image)\\n\\n        return image, label\\n```\\n\\n- `__init__`: Initializes the dataset class. We go through the root directory, listing class subdirectories (each representing a label) and collecting image file paths with corresponding labels. Additionally, we assume the images are stored in a grayscale format representative of FashionMNIST.\\n  \\n- `__len__`: Returns the number of images in the dataset.\\n\\n- `__getitem__`: Loads and returns a single image and its corresponding label by applying any transforms defined during initialization.\\n\\n### Step 3: Use the Dataset with DataLoader\\nNow, use this custom dataset class with a `DataLoader` to manage batching, shuffling, and parallel processing.\\n\\n```python\\n# Define transformation\\ntransform = transforms.Compose([\\n    transforms.Resize((28, 28)),  # Resize images to 28x28 pixels\\n    transforms.ToTensor(),       # Convert image to tensor\\n    transforms.Normalize((0.5,), (0.5,))  # Normalization\\n])\\n\\n# Initialize the dataset\\ndataset = FashionMNISTDataset(root_dir='path/to/fashionmnist', transform=transform)\\n\\n# Create a DataLoader\\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)\\n\\n# Iterate through the DataLoader\\nfor images, labels in dataloader:\\n    print(images.size(), labels)\\n    # Here, you'd usually pass the data to your model for training or evaluation\\n```\\n\\n- **Transforms**: Resize images to 28x28 pixels (standard for FashionMNIST) and normalize them. Normalization is typically done based on the dataset's mean and standard deviation.\\n\\n- **Dataset Initialization**: `root_dir` should point to the root of the dataset folder.\\n\\n- **DataLoader**: Initializes with batch size, shuffling (to randomize input order each epoch), and multiple workers for parallel data loading.\\n\\n- **Iterating DataLoader**: The data is now ready to be fed into a neural network model.\\n\\nBy structuring our data pipeline this way, we create a flexible structure that allows simple integration with PyTorch's model training and evaluation workflows.\",\n          \"To create a simple linear regression model with TensorFlow and train it on the California housing dataset, we will follow these steps:\\n\\n1. Load and prepare the dataset.\\n2. Define the linear regression model using TensorFlow.\\n3. Compile the model.\\n4. Train the model.\\n5. Evaluate the model.\\n\\nHere's the step-by-step explanation along with the code:\\n\\n### Step 1: Load and Prepare the Dataset\\n\\nThe California housing dataset is included in `sklearn.datasets`. We will use `fetch_california_housing` to load the data and then split it into training and test sets using `train_test_split`.\\n\\n```python\\nfrom sklearn.datasets import fetch_california_housing\\nfrom sklearn.model_selection import train_test_split\\nimport numpy as np\\n\\n# Load the dataset\\nhousing = fetch_california_housing()\\n\\n# Split the dataset into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, test_size=0.2, random_state=42)\\n\\n# Normalize the features (assuming this helps the model converge better)\\nmean = X_train.mean(axis=0)\\nstd = X_train.std(axis=0)\\n\\nX_train = (X_train - mean) / std\\nX_test = (X_test - mean) / std\\n```\\n\\n### Step 2: Define the Linear Regression Model\\n\\nLinear regression can be modeled using a dense layer with a single output neuron. In TensorFlow Keras, you can create a simple sequential model with one dense layer.\\n\\n```python\\nimport tensorflow as tf\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\n\\n# Define the model\\nmodel = keras.Sequential([\\n    layers.Dense(1, input_shape=(X_train.shape[1],))  # Single output neuron\\n])\\n```\\n\\n### Step 3: Compile the Model\\n\\nWe'll compile the model using the mean squared error (MSE) loss function, which is typical for regression tasks, and the Adam optimizer, which is robust and performs well in many scenarios.\\n\\n```python\\n# Compile the model\\nmodel.compile(optimizer='adam',\\n              loss='mse',\\n              metrics=['mae'])  # Mean Absolute Error for evaluation\\n```\\n\\n### Step 4: Train the Model\\n\\nTrain the model with the training data. We'll use a reasonable number of epochs, say 100, but this can be adjusted depending on how well the model performs. We will also specify a validation split to monitor the performance on unseen data.\\n\\n```python\\n# Train the model\\nhistory = model.fit(X_train, y_train,\\n                    epochs=100,\\n                    batch_size=32,\\n                    validation_split=0.2,\\n                    verbose=1)\\n```\\n\\n### Step 5: Evaluate the Model\\n\\nAfter training, we can evaluate the model's performance on the test set.\\n\\n```python\\n# Evaluate the model on the test set\\ntest_loss, test_mae = model.evaluate(X_test, y_test)\\nprint(f\\\"Test MAE: {test_mae}\\\")\\n```\\n\\n### Full Code\\n\\nHere's the complete code combining all steps above:\\n\\n```python\\nfrom sklearn.datasets import fetch_california_housing\\nfrom sklearn.model_selection import train_test_split\\nimport numpy as np\\nimport tensorflow as tf\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\n\\n# Load the dataset\\nhousing = fetch_california_housing()\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, test_size=0.2, random_state=42)\\n\\n# Normalize the features\\nmean = X_train.mean(axis=0)\\nstd = X_train.std(axis=0)\\nX_train = (X_train - mean) / std\\nX_test = (X_test - mean) / std\\n\\n# Define the linear regression model with one dense layer\\nmodel = keras.Sequential([\\n    layers.Dense(1, input_shape=(X_train.shape[1],))\\n])\\n\\n# Compile the model using Mean Squared Error loss and Adam optimizer\\nmodel.compile(optimizer='adam',\\n              loss='mse',\\n              metrics=['mae'])\\n\\n# Train the model for a modest number of epochs\\nhistory = model.fit(X_train, y_train,\\n                    epochs=100,\\n                    batch_size=32,\\n                    validation_split=0.2,\\n                    verbose=1)\\n\\n# Evaluate the model on the test set\\ntest_loss, test_mae = model.evaluate(X_test, y_test)\\nprint(f\\\"Test MAE: {test_mae}\\\")\\n```\\n\\nThis code demonstrates how to set up and train a simple linear regression model using TensorFlow to predict house prices from the California housing dataset. The use of normalization, evaluation, and validation helps ensure the model is trained effectively.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"few_shot_gpt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Below is a complete Python script using PyTorch to train a convolutional neural network (CNN) on the CIFAR-10 dataset. This script includes steps for data loading, model definition, training loop, and evaluation.\\n\\n```python\\nimport torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\nimport torchvision\\nimport torchvision.transforms as transforms\\nfrom torch.utils.data import DataLoader\\nfrom torchvision.datasets import CIFAR10\\nimport torch.nn.functional as F\\nfrom tqdm import tqdm\\n\\n# Device configuration\\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\\n# Hyperparameters\\nnum_epochs = 10\\nbatch_size = 100\\nlearning_rate = 0.001\\n\\n# Define a simple CNN\\nclass ConvNet(nn.Module):\\n    def __init__(self):\\n        super(ConvNet, self).__init__()\\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2)\\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\\n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\\n        self.fc1 = nn.Linear(32 * 8 * 8, 256)\\n        self.fc2 = nn.Linear(256, 10)\\n\\n    def forward(self, x):\\n        x = self.pool(F.relu(self.conv1(x)))\\n        x = self.pool(F.relu(self.conv2(x)))\\n        x = x.view(-1, 32 * 8 * 8)  # Flatten the tensor\\n        x = F.relu(self.fc1(x))\\n        x = self.fc2(x)\\n        return x\\n\\n# Data transformation and dataset loading\\ntransform = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\\n])\\n\\ntrain_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\\n\\ntest_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\\n\\n# Initialize the network\\nmodel = ConvNet().to(device)\\n\\n# Loss and optimizer\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\\n\\n# Training the network\\ndef train():\\n    model.train()\\n    for epoch in range(num_epochs):\\n        running_loss = 0.0\\n        for images, labels in tqdm(train_loader, desc=f\\\"Epoch {epoch+1}/{num_epochs}\\\"):\\n            images = images.to(device)\\n            labels = labels.to(device)\\n\\n            # Forward pass\\n            outputs = model(images)\\n            loss = criterion(outputs, labels)\\n\\n            # Backward and optimize\\n            optimizer.zero_grad()\\n            loss.backward()\\n            optimizer.step()\\n\\n            running_loss += loss.item()\\n\\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\\n\\n# Evaluating the network\\ndef evaluate():\\n    model.eval()\\n    with torch.no_grad():\\n        correct = 0\\n        total = 0\\n        for images, labels in test_loader:\\n            images = images.to(device)\\n            labels = labels.to(device)\\n            outputs = model(images)\\n            _, predicted = torch.max(outputs.data, 1)\\n            total += labels.size(0)\\n            correct += (predicted == labels).sum().item()\\n\\n        print(f'Accuracy: {100 * correct / total:.2f}%')\\n\\nif __name__ == \\\"__main__\\\":\\n    print(\\\"Starting training...\\\")\\n    train()\\n    print(\\\"Evaluating model...\\\")\\n    evaluate()\\n```\\n\\nHere is a step-by-step explanation of the script:\\n\\n1. **Imports**: The necessary libraries and modules are imported, including PyTorch libraries and utilities for data loading and transformations.\\n\\n2. **Device Configuration**: The script defines `device` to use a GPU if available for faster training.\\n\\n3. **Hyperparameters**: These define the number of epochs, batch size, and learning rate for training.\\n\\n4. **Define the CNN**: The `ConvNet` class implements a simple CNN with two convolutional layers followed by two fully connected layers.\\n\\n5. **Data Loading**: The CIFAR-10 dataset is loaded using torchvision with transformations applied, including normalization.\\n\\n6. **Initialize Network, Loss, and Optimizer**: The CNN model is created and moved to the appropriate device, with a cross-entropy loss and Adam optimizer defined.\\n\\n7. **Training Function**: The function `train` implements the training loop, iterating over the dataset, calculating loss, and updating model weights.\\n\\n8. **Evaluation Function**: The function `evaluate` assesses the model's performance on the test data.\\n\\n9. **Execution**: The script's main section calls the training and evaluation functions.\\n\\nTo run the script, ensure you have the required dependencies installed (`torch` and `torchvision`) and execute the script in an environment with these dependencies.\",\n          \"To create a custom `Dataset` class in PyTorch that loads image files and labels from a folder, we will subclass `torch.utils.data.Dataset`. For this example, we will simulate loading the FashionMNIST dataset.\\n\\nLet's start with setting up the class, assuming our data is organized as follows:\\n\\n- Images are stored in a directory.\\n- Labels are stored in a CSV file where each row maps an image filename to its label.\\n\\nHere's an example implementation of the custom dataset class and how you can use it with a DataLoader:\\n\\n```python\\nimport os\\nimport pandas as pd\\nimport torch\\nfrom torch.utils.data import Dataset, DataLoader\\nfrom torchvision.io import read_image\\nfrom torchvision import transforms\\nfrom torchvision.datasets import FashionMNIST\\nimport random\\n\\n# Define a transformation for the FashionMNIST dataset (if needed)\\ntransform = transforms.Compose([\\n    transforms.ToTensor(),\\n    # Add additional transformations, e.g., normalization, if needed\\n])\\n\\n# Custom Dataset class\\nclass FashionMNISTDataset(Dataset):\\n    def __init__(self, img_dir, annotations_file, transform=None):\\n        self.img_labels = pd.read_csv(annotations_file)\\n        self.img_dir = img_dir\\n        self.transform = transform\\n\\n    def __len__(self):\\n        return len(self.img_labels)\\n\\n    def __getitem__(self, idx):\\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\\n        image = read_image(img_path)\\n        label = self.img_labels.iloc[idx, 1]\\n        if self.transform:\\n            image = self.transform(image)\\n        return image, label\\n\\n# Example usage:\\n# Assume you have the FashionMNIST dataset downloaded somewhere\\ndef create_fashion_mnist_dataset():\\n    # This is just an example to simulate: normally, you'd have a path to your dataset\\n    # You can use torchvision to download FashionMNIST and subsequently use it in practice\\n\\n    # Create a temporary dataset with random filenames and labels\\n    img_dir = 'path_to_images'\\n    annotations_file = 'path_to_annotations.csv'\\n\\n    fashion_mnist_data = FashionMNIST(root='./data', train=True, download=True)\\n    os.makedirs(img_dir, exist_ok=True)\\n    annotations = []\\n\\n    for idx in range(len(fashion_mnist_data)):\\n        image, label = fashion_mnist_data[idx]\\n        image_filename = f'image_{idx}.png'\\n        image.save(os.path.join(img_dir, image_filename))  # Save images locally\\n        annotations.append([image_filename, label])\\n\\n    # Save annotations to a CSV file\\n    annotations_df = pd.DataFrame(annotations, columns=['filename', 'label'])\\n    annotations_df.to_csv(annotations_file, index=False)\\n\\n    return img_dir, annotations_file\\n\\n# Setup your train dataset\\nimg_dir, annotations_file = create_fashion_mnist_dataset()\\n\\n# Instantiate the dataset\\ndataset = FashionMNISTDataset(img_dir=img_dir, annotations_file=annotations_file, transform=transform)\\n\\n# Create DataLoader\\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)\\n\\n# Iterate through the dataloader\\nfor images, labels in dataloader:\\n    print(images.size(), labels.size())\\n    # process the batch\\n```\\n\\n### Explanation\\n\\n1. **Dataset Class**: Subclass `torch.utils.data.Dataset` and implement the `__init__`, `__len__`, and `__getitem__` methods. This class will handle loading image paths from a CSV file and applying any specified transforms.\\n\\n2. **DataLoader**: Use PyTorch's `DataLoader` to handle batching, shuffling, and loading the dataset in mini-batches for training.\\n\\n3. **Image Processing**: Make sure images are converted to tensors using `transforms.ToTensor()` and optionally apply more transformations such as normalization or augmentation.\\n\\n4. **Creating and Saving Data**: For illustration, I've shown how you can use the `FashionMNIST` dataset from torchvision to create a mock directory of images and a CSV file with labels. You would typically organize your data similarly in practice.\\n\\nMake sure you modify `img_dir` and `annotations_file` to point to your actual paths where your images and labels CSV are stored.\",\n          \"Sure, I'll guide you through creating and compiling a simple linear regression model using TensorFlow that trains on the California housing dataset. We'll write a function to achieve this.\\n\\nFirst, ensure you have TensorFlow and the necessary libraries installed. If not, use `!pip install tensorflow` in your Jupyter or Colab notebook environment.\\n\\nBelow is a Python function that does this task:\\n\\n```python\\nimport numpy as np\\nimport pandas as pd\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.datasets import fetch_california_housing\\n\\n\\ndef create_and_train_linear_model():\\n    # Fetch California housing dataset\\n    cali_housing = fetch_california_housing()\\n\\n    # Convert to Pandas DataFrame\\n    data = pd.DataFrame(\\n        cali_housing.data, columns=cali_housing.feature_names)\\n    labels = pd.DataFrame(cali_housing.target, columns=[\\\"MedHouseVal\\\"])\\n\\n    # Feature selection\\n    feature = 'AveRooms'  # We will perform linear regression with respect to AveRooms\\n\\n    # Split the data: 80% train, 20% test\\n    train_features, test_features, train_labels, test_labels = train_test_split(\\n        data[[feature]], labels, test_size=0.2, random_state=42)\\n\\n    # Normalization layer\\n    normalizer = layers.Normalization(input_shape=[1,], axis=None)\\n    normalizer.adapt(np.array(train_features))\\n\\n    # Create the sequential model\\n    model = tf.keras.Sequential([\\n        normalizer,\\n        layers.Dense(units=1)\\n    ])\\n\\n    model.summary()\\n\\n    # Compile the model\\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\\n                  loss='mean_absolute_error')\\n\\n    # Train the model\\n    history = model.fit(\\n        train_features,\\n        train_labels,\\n        epochs=100,\\n        verbose=0,\\n        validation_split=0.2\\n    )\\n\\n    # Evaluate the model\\n    loss = model.evaluate(test_features, test_labels, verbose=2)\\n    print(f\\\"Test set Mean Absolute Error: {loss}\\\")\\n\\n# Call the function\\ncreate_and_train_linear_model()\\n```\\n\\n### Explanation:\\n\\n1. **Fetch the Dataset**: We use `fetch_california_housing()` to get the dataset.\\n\\n2. **Data Preparation**: Convert the dataset into Pandas DataFrame and select one feature for linear regression (`AveRooms`).\\n\\n3. **Normalization**: We use a `Normalization` layer adapted to the `AveRooms` data to standardize the inputs.\\n\\n4. **Model Creation**: Build a sequential model with one normalizer layer followed by a dense layer with a single unit. This setup models a linear regression considering one feature.\\n\\n5. **Compile**: The model is compiled using the Adam optimizer and Mean Absolute Error as the loss function.\\n\\n6. **Train**: Train the model with 80% of the training data and validate with 20% using the training set.\\n\\n7. **Evaluate**: The model is evaluated on the test dataset.\\n\\nThis function defines a simple linear regression model focusing on a single feature and demonstrates basic usage of TensorFlow's `Sequential` API to perform regression tasks. Adjust the feature and model complexity as needed depending on your dataset's specific aspects or other variables of interest.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"direct_response_gemini\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"```python\\nimport torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\nimport torchvision\\nimport torchvision.transforms as transforms\\nfrom torch.utils.data import DataLoader\\nfrom tqdm import tqdm\\n\\n# Device configuration\\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\\n# Hyperparameters\\nnum_epochs = 10\\nbatch_size = 64\\nlearning_rate = 0.001\\n\\n# CIFAR10 dataset\\ntransform_train = transforms.Compose([\\n    transforms.RandomCrop(32, padding=4),\\n    transforms.RandomHorizontalFlip(),\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\\n])\\n\\ntransform_test = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\\n])\\n\\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\\n                                             download=True, transform=transform_train)\\n\\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\\n                                            download=True, transform=transform_test)\\n\\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size,\\n                          shuffle=True, num_workers=2)\\n\\ntest_loader = DataLoader(test_dataset, batch_size=batch_size,\\n                         shuffle=False, num_workers=2)\\n\\n# Convolutional neural network (simple architecture)\\nclass Net(nn.Module):\\n    def __init__(self):\\n        super(Net, self).__init__()\\n        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\\n        self.relu = nn.ReLU()\\n        self.pool = nn.MaxPool2d(2, 2)\\n        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\\n        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\\n        self.fc1 = nn.Linear(128 * 4 * 4, 512)\\n        self.fc2 = nn.Linear(512, 10)\\n\\n    def forward(self, x):\\n        x = self.pool(self.relu(self.conv1(x)))\\n        x = self.pool(self.relu(self.conv2(x)))\\n        x = self.pool(self.relu(self.conv3(x)))\\n        x = x.view(-1, 128 * 4 * 4) # Flatten the tensor\\n        x = self.relu(self.fc1(x))\\n        x = self.fc2(x)\\n        return x\\n\\nmodel = Net().to(device)\\n\\n# Loss and optimizer\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\\n\\n# Training loop\\nprint(\\\"Starting training...\\\")\\nfor epoch in range(num_epochs):\\n    model.train()\\n    running_loss = 0.0\\n    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=f\\\"Epoch {epoch+1}/{num_epochs}\\\")):\\n        inputs, labels = inputs.to(device), labels.to(device)\\n\\n        # Forward pass\\n        outputs = model(inputs)\\n        loss = criterion(outputs, labels)\\n\\n        # Backward and optimize\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\n        running_loss += loss.item()\\n\\n    avg_loss = running_loss / len(train_loader)\\n    print(f\\\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\\\")\\n\\nprint(\\\"Finished Training\\\")\\n\\n# Evaluation\\nprint(\\\"Starting evaluation...\\\")\\nmodel.eval()\\ncorrect = 0\\ntotal = 0\\nwith torch.no_grad():\\n    for inputs, labels in tqdm(test_loader, desc=\\\"Evaluating\\\"):\\n        inputs, labels = inputs.to(device), labels.to(device)\\n        outputs = model(inputs)\\n        _, predicted = torch.max(outputs.data, 1)\\n        total += labels.size(0)\\n        correct += (predicted == labels).sum().item()\\n\\naccuracy = 100 * correct / total\\nprint(f'Accuracy of the network on the 10000 test images: {accuracy:.2f} %')\\n\\n```\",\n          \"```python\\nimport torch\\nimport os\\nfrom PIL import Image\\nfrom torch.utils.data import Dataset, DataLoader\\nimport torchvision.transforms as transforms\\n\\n# Assume the FashionMNIST dataset has been organized into folders\\n# like this:\\n# root_dir/\\n#   train/\\n#     0/\\n#       image1.png\\n#       image2.png\\n#       ...\\n#     1/\\n#       imageX.png\\n#       ...\\n#     ...\\n#     9/\\n#   test/\\n#     0/\\n#       ...\\n#     ...\\n#     9/\\n\\nclass FashionMNISTFolderDataset(Dataset):\\n    \\\"\\\"\\\"\\n    A custom PyTorch Dataset for loading image files from a folder structure.\\n    Assumes the data is organized into subfolders where each subfolder\\n    represents a class.\\n    \\\"\\\"\\\"\\n    def __init__(self, root_dir, transform=None):\\n        \\\"\\\"\\\"\\n        Args:\\n            root_dir (string): Directory with all the class folders.\\n            transform (callable, optional): Optional transform to be applied\\n                on a sample.\\n        \\\"\\\"\\\"\\n        self.root_dir = root_dir\\n        self.transform = transform\\n        self.image_files = []\\n        self.labels = []\\n        self.classes = sorted(entry.name for entry in os.scandir(root_dir) if entry.is_dir())\\n        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\\n\\n        if not self.classes:\\n             raise FileNotFoundError(f\\\"No subdirectories found in {root_dir}. \\\"\\n                                     f\\\"Please organize images into class folders.\\\")\\n\\n        for class_name in self.classes:\\n            class_dir = os.path.join(root_dir, class_name)\\n            if not os.path.isdir(class_dir):\\n                continue # Skip if it's not a directory\\n\\n            for entry in os.scandir(class_dir):\\n                 if entry.is_file() and entry.name.lower().endswith(('.png', '.jpg', '.jpeg')):\\n                    self.image_files.append(entry.path)\\n                    self.labels.append(self.class_to_idx[class_name])\\n\\n        if not self.image_files:\\n             raise FileNotFoundError(f\\\"No image files found in subdirectories of {root_dir}. \\\"\\n                                     f\\\"Supported formats: .png, .jpg, .jpeg.\\\")\\n\\n\\n    def __len__(self):\\n        return len(self.image_files)\\n\\n    def __getitem__(self, idx):\\n        if torch.is_tensor(idx):\\n            idx = idx.tolist()\\n\\n        img_path = self.image_files[idx]\\n        image = Image.open(img_path).convert('L') # Convert to grayscale as FashionMNIST is grayscale\\n        label = self.labels[idx]\\n\\n        if self.transform:\\n            image = self.transform(image)\\n\\n        return image, label\\n\\n# --- Example Usage ---\\n\\n# Define transformations (example: resize, to tensor, normalize)\\n# FashionMNIST images are 28x28\\ndata_transform = transforms.Compose([\\n    transforms.Resize((32, 32)), # Example: resize to 32x32\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.5,), (0.5,)) # FashionMNIST is grayscale, use single mean/std\\n])\\n\\n# Define dummy root directories assuming the data is structured as described\\n# Replace with actual paths if you have the data organized this way\\ntrain_data_root = \\\"./dummy_fashion_mnist_folder/train\\\"\\ntest_data_root = \\\"./dummy_fashion_mnist_folder/test\\\"\\n\\n# --- Create Dummy Folders and Files for Demonstration ---\\n# This part is just to make the code runnable without a real dataset\\n# In a real scenario, you would already have the data organized.\\nif not os.path.exists(train_data_root):\\n    print(f\\\"Creating dummy data structure in {os.path.abspath('./dummy_fashion_mnist_folder')}\\\")\\n    os.makedirs(train_data_root, exist_ok=True)\\n    os.makedirs(test_data_root, exist_ok=True)\\n    # Create a few dummy files for 2 classes\\n    for class_id in [0, 1]:\\n        os.makedirs(os.path.join(train_data_root, str(class_id)), exist_ok=True)\\n        os.makedirs(os.path.join(test_data_root, str(class_id)), exist_ok=True)\\n        # Create dummy images (e.g., blank images)\\n        for i in range(5): # 5 dummy images per class\\n            dummy_img_train = Image.new('L', (28, 28), color='white')\\n            dummy_img_train.save(os.path.join(train_data_root, str(class_id), f'img_{i}.png'))\\n            dummy_img_test = Image.new('L', (28, 28), color='white')\\n            dummy_img_test.save(os.path.join(test_data_root, str(class_id), f'test_img_{i}.png'))\\n    print(\\\"Dummy data structure created.\\\")\\nelse:\\n    print(f\\\"Dummy data structure already exists in {os.path.abspath('./dummy_fashion_mnist_folder')}\\\")\\n# --- End of Dummy Data Creation ---\\n\\n\\n# Instantiate the custom Dataset\\ntry:\\n    fashion_mnist_dataset = FashionMNISTFolderDataset(root_dir=train_data_root, transform=data_transform)\\n\\n    # Check dataset size and classes\\n    print(f\\\"Number of samples in dataset: {len(fashion_mnist_dataset)}\\\")\\n    print(f\\\"Classes found: {fashion_mnist_dataset.classes}\\\")\\n    print(f\\\"Class to index mapping: {fashion_mnist_dataset.class_to_idx}\\\")\\n\\n    # Create a DataLoader\\n    batch_size = 32\\n    dataloader = DataLoader(fashion_mnist_dataset, batch_size=batch_size, shuffle=True)\\n\\n    # Iterate through the DataLoader (example)\\n    print(f\\\"\\\\nIterating through DataLoader with batch size {batch_size}...\\\")\\n    for i, (images, labels) in enumerate(dataloader):\\n        print(f\\\"Batch {i+1}:\\\")\\n        print(f\\\"  Image batch shape: {images.shape}\\\")\\n        print(f\\\"  Label batch shape: {labels.shape}\\\")\\n        # Stop after 2 batches for demonstration\\n        if i >= 1:\\n            break\\n\\n    print(\\\"\\\\nDataLoader usage demonstrated.\\\")\\n\\nexcept FileNotFoundError as e:\\n    print(f\\\"Error: {e}\\\")\\n    print(\\\"Please ensure the root_dir contains subdirectories for each class with image files inside.\\\")\\n    print(f\\\"The dummy data creation code created a structure in {os.path.abspath('./dummy_fashion_mnist_folder')}.\\\")\\n    print(\\\"You can point the `root_dir` to this location.\\\")\\n\\n```\",\n          \"```python\\nimport tensorflow as tf\\nimport numpy as np\\nfrom sklearn.datasets import fetch_california_housing\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\n\\ndef train_california_housing_linear_model():\\n    # Load the dataset\\n    housing = fetch_california_housing()\\n    X, y = housing.data, housing.target\\n\\n    # Preprocess the data (scaling)\\n    scaler = StandardScaler()\\n    X_scaled = scaler.fit_transform(X)\\n    y_scaled = y # For simplicity, we won't scale the target here, model will learn direct mapping\\n\\n    # Split data (optional but good practice)\\n    # X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\\n    # Using all data for training as requested implicitly\\n\\n    # Define the model\\n    model = tf.keras.Sequential([\\n        tf.keras.layers.Dense(units=1, input_shape=(X_scaled.shape[1],))\\n    ])\\n\\n    # Compile the model\\n    model.compile(optimizer='adam', loss='mean_squared_error')\\n\\n    # Train the model\\n    model.fit(X_scaled, y_scaled, epochs=50, batch_size=32, verbose=0)\\n\\n    return model\\n\\nif __name__ == '__main__':\\n    # Example usage:\\n    trained_model = train_california_housing_linear_model()\\n    print(\\\"Model training complete.\\\")\\n    # You can now use the trained_model for predictions\\n    # For example: trained_model.predict(some_scaled_data)\\n```\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cot_response_gemini\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Okay, let's build a Python script using PyTorch to train a Convolutional Neural Network (CNN) on the CIFAR-10 dataset. I will explain each step as we go.\\n\\nCIFAR-10 is a dataset of 60,000 32x32 colour images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images.\\n\\nHere's the plan:\\n1.  **Import necessary libraries:** PyTorch core, neural network module, optimizer module, data utilities, and torchvision for dataset and transforms.\\n2.  **Define Hyperparameters:** Set values like batch size, learning rate, number of epochs, etc.\\n3.  **Set up Device:** Check if a GPU is available and use it, otherwise use the CPU.\\n4.  **Load and Preprocess Data:** Download the CIFAR-10 dataset, apply necessary transformations (like converting to tensor and normalization), and create DataLoaders for training and testing.\\n5.  **Define the CNN Model:** Create a PyTorch `nn.Module` class for our CNN architecture.\\n6.  **Instantiate Model, Loss Function, and Optimizer:** Create an instance of the model, define the loss criterion (CrossEntropyLoss for classification), and choose an optimizer (e.g., Adam or SGD).\\n7.  **Define Training Loop:** Write a function or code block that iterates over the epochs, processing data in batches, calculating loss, performing backpropagation, and updating model weights.\\n8.  **Define Evaluation Function:** Write a function to evaluate the model's performance on the test dataset (calculate accuracy).\\n9.  **Run Training and Evaluation:** Execute the training loop and periodically evaluate the model.\\n10. **Optional: Plot Results:** Visualize training loss and test accuracy over epochs.\\n\\nLet's start coding!\\n\\n```python\\n# 1. Import necessary libraries\\nimport torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\nimport torchvision\\nimport torchvision.transforms as transforms\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport os # To create directory for saving model\\nfrom tqdm import tqdm # For progress bar\\n\\n# 2. Define Hyperparameters\\nnum_epochs = 10         # Number of training epochs\\nbatch_size = 100        # Number of images per batch\\nlearning_rate = 0.001   # Learning rate for the optimizer\\ndata_path = './data'    # Directory to download the dataset\\nmodel_path = './models' # Directory to save the trained model\\nmodel_save_name = 'cifar10_cnn.pth' # Name for the saved model file\\n\\n# 3. Set up Device\\n# This checks if a CUDA-enabled GPU is available. If yes, it uses the GPU; otherwise, it uses the CPU.\\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\nprint(f'Using device: {device}')\\n\\n# 4. Load and Preprocess Data\\n\\n# Data augmentation and normalization for training\\n# We define a sequence of transformations to apply to the images.\\n# transforms.ToTensor(): Converts a PIL Image or NumPy array (H x W x C)\\n#                        to a PyTorch Tensor (C x H x W) in the range [0.0, 1.0].\\n# transforms.Normalize(mean, std): Normalizes a tensor image with mean and standard deviation.\\n# We use the standard mean and std for CIFAR-10 across its channels.\\ntransform_train = transforms.Compose([\\n    transforms.RandomCrop(32, padding=4), # Pad and randomly crop to 32x32\\n    transforms.RandomHorizontalFlip(), # Randomly flip the image horizontally\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\\n])\\n\\n# Normalization for testing (no augmentation)\\ntransform_test = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\\n])\\n\\n# Load the CIFAR-10 training dataset\\n# root: directory where the dataset will be saved or loaded from.\\n# train=True: specifies the training set.\\n# download=True: downloads the dataset if it's not found in the root directory.\\n# transform: applies the specified transformations.\\ntrainset = torchvision.datasets.CIFAR10(root=data_path, train=True,\\n                                        download=True, transform=transform_train)\\n\\n# Create a DataLoader for the training set\\n# DataLoader is an iterator that provides batches of data.\\n# dataset: the dataset to load data from.\\n# batch_size: how many samples per batch to load.\\n# shuffle=True: shuffles the data at the beginning of each epoch (important for training).\\n# num_workers: how many subprocesses to use for data loading (higher values can speed up loading).\\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\\n                                          shuffle=True, num_workers=2)\\n\\n# Load the CIFAR-10 test dataset\\ntestset = torchvision.datasets.CIFAR10(root=data_path, train=False,\\n                                       download=True, transform=transform_test)\\n\\n# Create a DataLoader for the test set\\n# shuffle=False: shuffling is not necessary for testing/evaluation.\\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\\n                                         shuffle=False, num_workers=2)\\n\\n# Define the 10 class names for CIFAR-10\\nclasses = ('plane', 'car', 'bird', 'cat', 'deer',\\n           'dog', 'frog', 'horse', 'ship', 'truck')\\n\\nprint(f'Training data size: {len(trainset)}')\\nprint(f'Test data size: {len(testset)}')\\n\\n# Optional: Show a few images (for debugging/visualization)\\n# def imshow(img):\\n#     # Unnormalize the image\\n#     img = img / 2 + 0.5     # Assuming the normalization was done around mean 0.5, std 0.5 for simplicity here,\\n#                           # though we used CIFAR10 specific mean/std above.\\n#                           # For correct visualization with CIFAR10 norm:\\n#     mean = torch.tensor((0.4914, 0.4822, 0.4465)).reshape(3, 1, 1)\\n#     std = torch.tensor((0.2023, 0.1994, 0.2010)).reshape(3, 1, 1)\\n#     img = img * std + mean\\n#\\n#     npimg = img.numpy()\\n#     plt.imshow(np.transpose(npimg, (1, 2, 0))) # Convert from Tensor (C, H, W) to NumPy array (H, W, C)\\n#     plt.show()\\n\\n# Get some random training images\\n# dataiter = iter(trainloader)\\n# images, labels = next(dataiter)\\n# print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\\n# imshow(torchvision.utils.make_grid(images))\\n\\n\\n# 5. Define the CNN Model\\n# We create a class MyCNN that inherits from nn.Module.\\n# This is the standard way to define models in PyTorch.\\nclass MyCNN(nn.Module):\\n    def __init__(self):\\n        # Call the constructor of the parent class (nn.Module)\\n        super(MyCNN, self).__init__()\\n\\n        # Define the layers of the network\\n\\n        # Convolutional Layer 1\\n        # nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\\n        # Input image size: 3x32x32 (3 channels, 32x32 pixels)\\n        # Output size after conv1: (32 + 2*1 - 3)/1 + 1 = 32 -> 32x32x32\\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\\n        # Batch Normalization 1: Applied after convolution, before activation, helps stabilize training.\\n        self.bn1 = nn.BatchNorm2d(32)\\n        # ReLU Activation: Applies the rectified linear unit function element-wise (max(0, x)).\\n        self.relu = nn.ReLU()\\n        # Max Pooling Layer 1: Reduces spatial dimensions.\\n        # nn.MaxPool2d(kernel_size, stride)\\n        # Output size after pool1: 32/2 x 32/2 = 16x16 -> 32x16x16\\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\\n\\n        # Convolutional Layer 2\\n        # Input size: 32x16x16\\n        # Output size after conv2: (64 + 2*1 - 3)/1 + 1 = 16 -> 64x16x16\\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\\n        self.bn2 = nn.BatchNorm2d(64)\\n        # Output size after pool: 16/2 x 16/2 = 8x8 -> 64x8x8\\n\\n        # Convolutional Layer 3\\n        # Input size: 64x8x8\\n        # Output size after conv3: (128 + 2*1 - 3)/1 + 1 = 8 -> 128x8x8\\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\\n        self.bn3 = nn.BatchNorm2d(128)\\n        # Output size after pool: 8/2 x 8/2 = 4x4 -> 128x4x4\\n\\n        # Fully Connected Layers (also called Dense layers)\\n        # Input size for the first fully connected layer: Flat output from the last pooling layer\\n        # The output tensor from the last pooling layer is 128 channels of size 4x4.\\n        # Flattened size: 128 * 4 * 4 = 2048\\n        self.fc1 = nn.Linear(in_features=128 * 4 * 4, out_features=512)\\n        # Dropout Layer: Randomly sets a fraction of input units to 0 at each update during training. Helps prevent overfitting.\\n        self.dropout = nn.Dropout(p=0.5) # 50% probability of dropping an activation\\n        self.fc2 = nn.Linear(in_features=512, out_features=10) # Output layer: 10 features for 10 classes\\n\\n    # Define the forward pass (how data flows through the network)\\n    def forward(self, x):\\n        # Apply Conv -> BN -> ReLU -> Pool\\n        x = self.pool(self.relu(self.bn1(self.conv1(x))))\\n        x = self.pool(self.relu(self.bn2(self.conv2(x))))\\n        x = self.pool(self.relu(self.bn3(self.conv3(x))))\\n\\n        # Flatten the output from the convolutional layers for the fully connected layers\\n        # x.size(0) is the batch size\\n        x = x.view(-1, 128 * 4 * 4) # -1 lets PyTorch figure out the batch size\\n\\n        # Apply Fully Connected layers\\n        x = self.relu(self.fc1(x))\\n        x = self.dropout(x) # Apply dropout after the first FC layer\\n        x = self.fc2(x)\\n\\n        return x # The output layer doesn't typically have an activation for CrossEntropyLoss,\\n                 # as it includes LogSoftmax internally.\\n\\n# 6. Instantiate Model, Loss Function, and Optimizer\\nmodel = MyCNN().to(device) # Create an instance of the model and move it to the selected device (GPU/CPU)\\n\\n# Loss function: Cross-Entropy Loss is suitable for multi-class classification.\\ncriterion = nn.CrossEntropyLoss()\\n\\n# Optimizer: Adam is an adaptive learning rate optimization algorithm.\\n# model.parameters(): Provides all the learnable parameters of the model.\\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\\n\\n# Optional: Learning Rate Scheduler\\n# Decays the learning rate by a factor of 0.1 every 30 epochs\\n# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\\n\\n# 7. Define Training Loop\\n# This function trains the model for one epoch\\ndef train_epoch(model, train_loader, criterion, optimizer, device):\\n    model.train() # Set the model to training mode (enables dropout and batch normalization updates)\\n    running_loss = 0.0\\n    # Wrap the DataLoader with tqdm for a progress bar\\n    for i, data in enumerate(tqdm(train_loader, desc='Training', leave=False)):\\n        # Get the inputs; data is a list of [inputs, labels]\\n        inputs, labels = data\\n        # Move data to the appropriate device\\n        inputs, labels = inputs.to(device), labels.to(device)\\n\\n        # Zero the parameter gradients\\n        # It's important to zero the gradients before each backpropagation step,\\n        # as gradients are accumulated by default in PyTorch.\\n        optimizer.zero_grad()\\n\\n        # Forward pass: Compute the predicted outputs by passing inputs through the model\\n        outputs = model(inputs)\\n        # Compute the loss: Compare the predicted outputs with the true labels\\n        loss = criterion(outputs, labels)\\n\\n        # Backward pass: Compute gradients of the loss with respect to model parameters\\n        loss.backward()\\n        # Optimizer step: Update the model parameters using the computed gradients\\n        optimizer.step()\\n\\n        # Print statistics\\n        running_loss += loss.item() # .item() gets the scalar value from a tensor\\n    return running_loss / len(train_loader) # Return average loss for the epoch\\n\\n# 8. Define Evaluation Function\\n# This function evaluates the model on a given data loader (usually the test set)\\ndef evaluate(model, data_loader, device):\\n    model.eval() # Set the model to evaluation mode (disables dropout and batch normalization tracking/updates)\\n    correct = 0\\n    total = 0\\n    # Disable gradient calculations during evaluation\\n    # This reduces memory consumption and speeds up computation as we don't need gradients for evaluation.\\n    with torch.no_grad():\\n        for data in tqdm(data_loader, desc='Evaluating', leave=False):\\n            images, labels = data\\n            # Move data to the appropriate device\\n            images, labels = images.to(device), labels.to(device)\\n            # Forward pass: Get predictions\\n            outputs = model(images)\\n            # Get the predicted class with the highest score\\n            # torch.max returns (values, indices). We need the indices (the class predictions).\\n            _, predicted = torch.max(outputs.data, 1)\\n            # Update total number of images and correct predictions\\n            total += labels.size(0) # Add batch size to total count\\n            correct += (predicted == labels).sum().item() # Count correct predictions in the batch\\n\\n    accuracy = 100 * correct / total\\n    return accuracy\\n\\n# 9. Run Training and Evaluation\\ntrain_losses = []\\ntest_accuracies = []\\n\\n# Ensure model save directory exists\\nos.makedirs(model_path, exist_ok=True)\\nbest_accuracy = 0.0 # To keep track of the best test accuracy achieved\\n\\nprint(\\\"Starting Training...\\\")\\nfor epoch in range(num_epochs):\\n    print(f'\\\\nEpoch {epoch + 1}/{num_epochs}')\\n\\n    # Train for one epoch\\n    avg_train_loss = train_epoch(model, trainloader, criterion, optimizer, device)\\n    train_losses.append(avg_train_loss)\\n\\n    # Evaluate on the test set\\n    test_accuracy = evaluate(model, testloader, device)\\n    test_accuracies.append(test_accuracy)\\n\\n    print(f'Epoch {epoch + 1} finished.')\\n    print(f'Train Loss: {avg_train_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\\n\\n    # Optional: Save the model checkpoint if it's the best performing so far\\n    if test_accuracy > best_accuracy:\\n        best_accuracy = test_accuracy\\n        save_path = os.path.join(model_path, model_save_name)\\n        # Save the model's state dictionary\\n        # Saving state_dict is recommended as it's more flexible for loading later\\n        torch.save(model.state_dict(), save_path)\\n        print(f'Model saved to {save_path} with improved accuracy: {best_accuracy:.2f}%')\\n\\n    # Optional: Step the learning rate scheduler\\n    # if 'scheduler' in locals():\\n    #     scheduler.step()\\n\\nprint('Finished Training')\\n\\n# 10. Plot Results (Optional)\\nplt.figure(figsize=(10, 5))\\nplt.subplot(1, 2, 1)\\nplt.plot(range(1, num_epochs + 1), train_losses)\\nplt.xlabel('Epoch')\\nplt.ylabel('Training Loss')\\nplt.title('Training Loss per Epoch')\\n\\nplt.subplot(1, 2, 2)\\nplt.plot(range(1, num_epochs + 1), test_accuracies, color='orange')\\nplt.xlabel('Epoch')\\nplt.ylabel('Test Accuracy (%)')\\nplt.title('Test Accuracy per Epoch')\\n\\nplt.tight_layout()\\nplt.show()\\n\\n# Optional: Load the best model and evaluate one last time\\ntry:\\n    loaded_model = MyCNN().to(device)\\n    load_path = os.path.join(model_path, model_save_name)\\n    loaded_model.load_state_dict(torch.load(load_path))\\n    print(f'\\\\nLoaded model from {load_path}')\\n    final_test_accuracy = evaluate(loaded_model, testloader, device)\\n    print(f'Final Test Accuracy (loaded model): {final_test_accuracy:.2f}%')\\nexcept FileNotFoundError:\\n    print(f\\\"\\\\nModel file not found at {load_path}. Skipping final evaluation of loaded model.\\\")\\nexcept Exception as e:\\n    print(f\\\"\\\\nError loading or evaluating model: {e}\\\")\\n\\n```\\n\\n**Explanation of Steps and Reasoning:**\\n\\n1.  **Imports:** We import `torch` for the core framework, `torch.nn` for neural network modules (layers), `torch.optim` for optimizers, `torchvision` for datasets and common transforms, `torchvision.transforms` for data augmentation/preprocessing, `matplotlib.pyplot` for plotting, `numpy` for potential numerical operations (used implicitly by matplotlib), `os` to handle directories, and `tqdm` for progress bars.\\n2.  **Hyperparameters:** These are settings that control the training process. Defining them at the top makes it easy to experiment with different values without changing the core logic.\\n3.  **Device Setup:** Training neural networks is computationally intensive. Using a GPU (`cuda`) if available is crucial for performance. This snippet automatically detects and uses the GPU or falls back to the CPU.\\n4.  **Data Loading and Preprocessing:**\\n    *   We use `torchvision.datasets.CIFAR10` which handles downloading and loading the dataset.\\n    *   `transforms.Compose` chains together multiple transformations.\\n    *   `transforms.RandomCrop` and `RandomHorizontalFlip` are common data *augmentation* techniques. They artificially increase the size and variability of the training data, making the model more robust and reducing overfitting.\\n    *   `transforms.ToTensor()` converts images to PyTorch tensors and scales pixel values from \\\\[0, 255] to \\\\[0.0, 1.0].\\n    *   `transforms.Normalize()` scales pixel values based on the channel-wise mean and standard deviation of the dataset. This helps in speeding up convergence and improving performance.\\n    *   `torch.utils.data.DataLoader` is essential. It wraps the dataset and provides an iterable that yields data in batches. This is necessary because training is typically done using mini-batches, which makes gradient estimation more stable than training on individual samples and is more memory-efficient than training on the entire dataset at once. `shuffle=True` for training is important to prevent the model from learning the order of data.\\n5.  **Define the CNN Model:**\\n    *   We create a class `MyCNN` inheriting from `nn.Module`. The `__init__` method defines the layers, and the `forward` method defines how data passes through these layers.\\n    *   **Convolutional Layers (`nn.Conv2d`):** These are the core of the CNN. They apply filters (kernels) to the input image to extract features. `in_channels` is the number of input feature maps (3 for RGB images), `out_channels` is the number of filters (and thus output feature maps), `kernel_size` is the size of the filter (e.g., 3x3), `stride` is how many pixels the filter moves at each step, and `padding` adds zeros around the input borders (useful for controlling output size).\\n    *   **Batch Normalization (`nn.BatchNorm2d`):** Normalizes the output of a convolutional layer across the batch dimension. This helps in training deeper networks by making the training process more stable and allowing for higher learning rates. It's typically applied after the convolution and before the activation function.\\n    *   **Activation Function (`nn.ReLU`):** Introduces non-linearity into the network. Without non-linearities, a CNN would just be a sequence of linear operations, which cannot model complex patterns.\\n    *   **Pooling Layers (`nn.MaxPool2d`):** Reduces the spatial dimensions (height and width) of the feature maps. This reduces the number of parameters and computation in the network, and helps the network become more invariant to small translations in the input. Max pooling selects the maximum value in a given window.\\n    *   **Flattening:** After the convolutional and pooling layers, the 2D feature maps are flattened into a 1D vector to be fed into the fully connected layers. `x.view(x.size(0), -1)` reshapes the tensor while keeping the batch size the same and automatically calculating the required size for the flattened dimension.\\n    *   **Fully Connected Layers (`nn.Linear`):** These are standard feedforward layers. They take the flattened features and perform classification based on them. The last layer has `out_features=10` corresponding to the 10 classes of CIFAR-10.\\n    *   **Dropout (`nn.Dropout`):** A regularization technique where random connections are temporarily ignored during training. This prevents units from becoming too dependent on each other and helps reduce overfitting.\\n6.  **Instantiate Model, Loss, and Optimizer:**\\n    *   `model = MyCNN().to(device)` creates an instance of our defined network and moves all its parameters to the specified device (GPU or CPU).\\n    *   `nn.CrossEntropyLoss()` is the standard loss function for multi-class classification problems. It measures the difference between the model's output logits and the true class labels.\\n    *   `optim.Adam()` is a popular optimization algorithm that updates the model's weights based on the gradients computed during backpropagation. It's often a good default choice. We pass `model.parameters()` so the optimizer knows which parameters to update.\\n7.  **Training Loop (`train_epoch`):**\\n    *   `model.train()` sets the model to training mode. This is important because layers like Dropout and BatchNorm behave differently during training (e.g., Dropout is active, BatchNorm tracks running mean/variance and uses batch statistics) vs. evaluation.\\n    *   We iterate through the `train_loader`, getting batches of `inputs` and `labels`.\\n    *   `optimizer.zero_grad()` clears the gradients from the *previous* training step. Gradients are accumulated by default, so this reset is crucial for calculating gradients correctly for the *current* batch.\\n    *   `outputs = model(inputs)` performs the forward pass, feeding the inputs through the network to get predictions.\\n    *   `loss = criterion(outputs, labels)` calculates the loss between the predicted outputs and the ground truth labels.\\n    *   `loss.backward()` calculates the gradients of the loss with respect to every trainable parameter in the model using backpropagation.\\n    *   `optimizer.step()` updates the model's parameters using the computed gradients and the chosen optimization algorithm (Adam in this case).\\n    *   `loss.item()` gets the scalar value of the loss tensor.\\n8.  **Evaluation Function (`evaluate`):**\\n    *   `model.eval()` sets the model to evaluation mode. Dropout is disabled, and BatchNorm layers use their saved running statistics instead of batch statistics.\\n    *   `with torch.no_grad():` is a context manager that disables gradient calculation. This is important during evaluation because we don't need to compute gradients, saving memory and computation.\\n    *   We iterate through the `test_loader`.\\n    *   `torch.max(outputs.data, 1)` finds the index (class prediction) with the highest probability/logit score along dimension 1 (the class dimension).\\n    *   We compare the `predicted` classes with the true `labels` to count correct predictions and calculate the accuracy.\\n9.  **Run Training and Evaluation:** The main loop iterates for the specified number of `num_epochs`. In each epoch, it calls the `train_epoch` function and then the `evaluate` function on the test set to track performance. It prints the loss and accuracy for each epoch. Saving the model based on the best test accuracy is a common practice.\\n10. **Plot Results:** `matplotlib` is used to visualize the training loss and test accuracy over the epochs, providing insight into the training process (e.g., if the model is overfitting, if the loss is decreasing).\\n11. **Load and Evaluate Final Model:** After training, we load the `state_dict` of the model that achieved the best accuracy during training and perform a final evaluation on the test set to confirm its performance. Loading just the `state_dict` is standard practice as it's more portable than saving the entire model object.\\n\\nThis script provides a solid foundation for training a CNN on CIFAR-10. You can extend it by adding more complex model architectures, different optimizers or schedulers, more advanced data augmentations, logging, etc.\",\n          \"Okay, let's create a PyTorch `Dataset` subclass to load FashionMNIST images and labels from a folder structure, and then use it with a `DataLoader`.\\n\\nSince FashionMNIST doesn't *natively* come as individual image files in class subfolders, we first need a pre-processing step to download the standard dataset and save it in the desired folder structure. Then, we'll build the custom `Dataset` class that reads from this structure.\\n\\n**Step 1: Understand the Goal and Data Structure**\\n\\nWe want to load data organized like this:\\n\\n```\\nfashion_mnist_folder/\\n\\u251c\\u2500\\u2500 train/\\n\\u2502   \\u251c\\u2500\\u2500 T-shirt_top/\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 img_00001.png\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 img_00002.png\\n\\u2502   \\u2502   \\u2514\\u2500\\u2500 ...\\n\\u2502   \\u251c\\u2500\\u2500 Trouser/\\n\\u2502   \\u2502   \\u251c\\u2500\\u2500 img_01001.png\\n\\u2502   \\u2502   \\u2514\\u2500\\u2500 ...\\n\\u2502   \\u2514\\u2500\\u2500 ... (other class folders)\\n\\u2514\\u2500\\u2500 test/\\n    \\u251c\\u2500\\u2500 T-shirt_top/\\n    \\u2502   \\u251c\\u2500\\u2500 img_60001.png\\n    \\u2502   \\u2514\\u2500\\u2500 ...\\n    \\u2514\\u2500\\u2500 ... (other class folders)\\n```\\n\\nOur custom `Dataset` will need to traverse this structure, find all images, associate them with their labels based on the folder name, and provide a way to load individual images and labels when indexed.\\n\\n**Step 2: Pre-processing - Saving FashionMNIST to Folders**\\n\\nThis part is *not* the custom `Dataset` itself, but a necessary setup step before our custom `Dataset` can be used. We will use `torchvision.datasets.FashionMNIST` to easily download the data and then save it into the target folder structure.\\n\\n*   We'll need to map the integer labels (0-9) from the original dataset to class names (e.g., 0 -> 'T-shirt/top').\\n*   We'll iterate through the training and test sets.\\n*   For each image and label, we'll create the appropriate directory (`root_dir/split/class_name/`) if it doesn't exist and save the image (which is a PIL Image) as a file (e.g., PNG).\\n\\n```python\\nimport torch\\nimport torchvision\\nimport torchvision.transforms as transforms\\nimport os\\nfrom PIL import Image\\nimport shutil\\n\\n# --- Pre-processing: Save FashionMNIST to Folder Structure ---\\n# This part downloads the data and organizes it into folders.\\n# You only need to run this once.\\n\\ndef save_fashion_mnist_to_folder(root_output_dir='./fashion_mnist_folder'):\\n    \\\"\\\"\\\"\\n    Downloads FashionMNIST and saves images into a folder structure\\n    like root_output_dir/split/class_name/image.png\\n    \\\"\\\"\\\"\\n    print(f\\\"Saving FashionMNIST to folders in {root_output_dir}...\\\")\\n\\n    # Define class names for FashionMNIST\\n    classes = [\\n        'T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat',\\n        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle_boot'\\n    ]\\n\\n    # Ensure the root output directory is clean or created\\n    if os.path.exists(root_output_dir):\\n        print(f\\\"Removing existing directory: {root_output_dir}\\\")\\n        shutil.rmtree(root_output_dir)\\n    os.makedirs(root_output_dir)\\n\\n    # Download and process training data\\n    train_dataset_original = torchvision.datasets.FashionMNIST(\\n        root='./data', train=True, download=True\\n    )\\n    save_split(train_dataset_original, 'train', root_output_dir, classes)\\n\\n    # Download and process test data\\n    test_dataset_original = torchvision.datasets.FashionMNIST(\\n        root='./data', train=False, download=True\\n    )\\n    save_split(test_dataset_original, 'test', root_output_dir, classes)\\n\\n    print(\\\"FashionMNIST data saved successfully.\\\")\\n\\ndef save_split(dataset, split_name, root_output_dir, classes):\\n    \\\"\\\"\\\"Saves images from a single split (train/test) to folders.\\\"\\\"\\\"\\n    split_dir = os.path.join(root_output_dir, split_name)\\n    print(f\\\"Processing {split_name} split...\\\")\\n\\n    for class_name in classes:\\n        os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\\n\\n    for i, (img, label) in enumerate(dataset):\\n        class_name = classes[label]\\n        # FashionMNIST images are 28x28 grayscale PIL Images\\n        img_path = os.path.join(split_dir, class_name, f'img_{i:05d}.png')\\n        img.save(img_path) # PIL Image save\\n\\n# --- Run the pre-processing step ---\\n# Uncomment the line below to generate the folder structure.\\n# save_fashion_mnist_to_folder()\\n# print(\\\"Please run the save_fashion_mnist_to_folder() function to create the data structure.\\\")\\n\\n```\\n\\n**Reasoning for Pre-processing:**\\n\\n*   `torchvision.datasets.FashionMNIST` is the easiest way to get the data initially.\\n*   We need to convert the dataset object (which holds images and labels in memory or arrays) into a *file system* representation.\\n*   Saving as individual image files (like PNG) is a common practice and allows our custom `Dataset` to simulate loading data from scratch, as if it wasn't downloaded via `torchvision`.\\n*   Organizing by `split/class_name/` makes it straightforward for our `Dataset` to determine the label from the file path.\\n*   Using `PIL.Image.save()` is standard for saving image objects loaded or generated by PIL.\\n\\n**Step 3: Create the Custom `Dataset` Class**\\n\\nNow, we define `FashionMNISTFolderDataset` which inherits from `torch.utils.data.Dataset`.\\n\\n*   **`__init__(self, root_dir, split='train', transform=None)`:**\\n    *   Takes the `root_dir` (e.g., `./fashion_mnist_folder`), the `split` ('train' or 'test'), and an optional `transform`.\\n    *   It will build a list of all image file paths and their corresponding integer labels.\\n    *   It needs to map folder names (class names) to integer labels (0-9).\\n*   **`__len__(self)`:**\\n    *   Returns the total number of samples (images) in the dataset. This is simply the length of the list of (path, label) pairs created in `__init__`.\\n*   **`__getitem__(self, idx)`:**\\n    *   Takes an index `idx`.\\n    *   Retrieves the image path and label from the stored list at that index.\\n    *   Loads the image file using `PIL.Image.open()`.\\n    *   Applies the `transform` if provided.\\n    *   Returns the transformed image tensor and the label.\\n\\n```python\\nimport torch\\nfrom torch.utils.data import Dataset\\nimport torchvision.transforms as transforms\\nimport os\\nfrom PIL import Image\\n\\n# --- Custom Dataset Class ---\\n\\nclass FashionMNISTFolderDataset(Dataset):\\n    \\\"\\\"\\\"\\n    Custom Dataset to load FashionMNIST images from a folder structure\\n    like root_dir/split/class_name/image.png\\n    \\\"\\\"\\\"\\n    def __init__(self, root_dir, split='train', transform=None):\\n        \\\"\\\"\\\"\\n        Args:\\n            root_dir (string): Directory with all the split folders (e.g. 'fashion_mnist_folder/').\\n            split (string): 'train' or 'test' indicating the split to load.\\n            transform (callable, optional): Optional transform to be applied\\n                on a sample.\\n        \\\"\\\"\\\"\\n        self.root_dir = root_dir\\n        self.split = split\\n        self.transform = transform\\n        self.split_dir = os.path.join(root_dir, split)\\n\\n        if not os.path.exists(self.split_dir):\\n            raise FileNotFoundError(f\\\"Split directory not found: {self.split_dir}\\\")\\n\\n        # Store class names and create mapping from class name to index\\n        # FashionMNIST classes (sorted alphabetically would match the folder structure)\\n        self.classes = sorted(entry.name for entry in os.scandir(self.split_dir) if entry.is_dir())\\n        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\\n\\n        if not self.classes:\\n             raise RuntimeError(f\\\"No class directories found in {self.split_dir}\\\")\\n\\n\\n        # Build the list of (image_path, label) pairs\\n        self.samples = []\\n        for class_name in self.classes:\\n            class_dir = os.path.join(self.split_dir, class_name)\\n            if not os.path.isdir(class_dir):\\n                continue # Skip if it's not actually a directory\\n\\n            label = self.class_to_idx[class_name]\\n\\n            for img_file in os.listdir(class_dir):\\n                # Basic check for image files (can be expanded)\\n                if img_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\\n                    img_path = os.path.join(class_dir, img_file)\\n                    self.samples.append((img_path, label))\\n\\n        if not self.samples:\\n            raise RuntimeError(f\\\"No images found in {self.split_dir}. Make sure images are saved in class subfolders.\\\")\\n\\n        print(f\\\"Found {len(self.samples)} images in the '{split}' split.\\\")\\n        print(f\\\"Classes: {self.classes}\\\")\\n\\n\\n    def __len__(self):\\n        \\\"\\\"\\\"Returns the total number of samples.\\\"\\\"\\\"\\n        return len(self.samples)\\n\\n    def __getitem__(self, idx):\\n        \\\"\\\"\\\"Loads and returns a sample from the dataset at the given index.\\\"\\\"\\\"\\n        if not (0 <= idx < len(self)):\\n            raise IndexError(f\\\"Index {idx} is out of bounds for dataset of size {len(self)}\\\")\\n\\n        img_path, label = self.samples[idx]\\n\\n        # Load image using Pillow (PIL)\\n        # FashionMNIST is grayscale, so convert to 'L'\\n        try:\\n            img = Image.open(img_path).convert('L')\\n        except Exception as e:\\n            print(f\\\"Error loading image {img_path}: {e}\\\")\\n            # Return a dummy or handle error appropriately, e.g., skip sample\\n            # For simplicity here, we'll raise, but a real system might skip\\n            raise\\n\\n        # Apply transforms\\n        if self.transform:\\n            img = self.transform(img)\\n\\n        return img, label # Return the image tensor and the label\\n\\n```\\n\\n**Reasoning for Custom Dataset:**\\n\\n*   **Inheritance:** Subclassing `torch.utils.data.Dataset` is the contract PyTorch expects. It requires implementing `__len__` and `__getitem__`.\\n*   **`__init__`:**\\n    *   It finds all relevant image files and stores their paths along with their corresponding labels. This is done upfront to avoid repeatedly scanning the file system during training/inference.\\n    *   It relies on the folder structure: the parent directory of the image file *is* the class name.\\n    *   It creates `self.classes` and `self.class_to_idx` which are standard attributes for image datasets, providing the mapping between integer labels and human-readable names.\\n    *   `self.samples` stores the list of `(path, label)` tuples that `__getitem__` will use.\\n*   **`__len__`:** Simple lookup of the total number of samples stored in `self.samples`.\\n*   **`__getitem__`:**\\n    *   Takes the index `idx`.\\n    *   Retrieves the pre-calculated `img_path` and `label`.\\n    *   Uses `PIL.Image.open()` to load the image file from disk. `.convert('L')` is used because FashionMNIST is grayscale. This ensures the image is in a consistent format before transformations.\\n    *   Applies the `self.transform`. This is crucial because transforms handle conversion to PyTorch tensors (`ToTensor`) and often include resizing, augmentation, or normalization needed for model input.\\n    *   Returns the processed image tensor and the integer label. This is the format `DataLoader` expects: a tensor for the data and a number for the label.\\n\\n**Step 4: Using the Custom Dataset with `DataLoader`**\\n\\nNow we can instantiate our `FashionMNISTFolderDataset` and pass it to a `torch.utils.data.DataLoader`. The `DataLoader` handles batching, shuffling, and loading data in parallel processes (`num_workers`).\\n\\n```python\\nimport torch\\nfrom torch.utils.data import DataLoader\\nimport torchvision.transforms as transforms\\nimport matplotlib.pyplot as plt # Optional: for visualization\\nimport numpy as np # Optional: for visualization\\n\\n# --- Usage with DataLoader ---\\n\\n# Define the directory where data was saved (modify if you changed it)\\nDATA_FOLDER_ROOT = './fashion_mnist_folder'\\n\\n# Define transformations\\n# Common transforms for image data:\\n# 1. ToTensor: Converts PIL Image (H x W) to PyTorch Tensor (C x H x W)\\n#    and scales pixel values from [0, 255] to [0.0, 1.0].\\n# 2. Normalize: Standardizes pixel values using mean and standard deviation.\\n#    FashionMNIST mean and std for grayscale: mean=0.286, std=0.353 (approx)\\ntransform = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.286,), (0.353,)) # Mean and Std for grayscale FashionMNIST\\n])\\n\\n# --- Instantiate the Dataset ---\\n# Make sure you have run save_fashion_mnist_to_folder() at least once\\n# to create the ./fashion_mnist_folder directory.\\ntry:\\n    train_dataset = FashionMNISTFolderDataset(\\n        root_dir=DATA_FOLDER_ROOT,\\n        split='train',\\n        transform=transform\\n    )\\n\\n    test_dataset = FashionMNISTFolderDataset(\\n        root_dir=DATA_FOLDER_ROOT,\\n        split='test',\\n        transform=transform\\n    )\\n\\nexcept FileNotFoundError as e:\\n    print(f\\\"Data folder not found: {e}\\\")\\n    print(\\\"Please run the save_fashion_mnist_to_folder() function first.\\\")\\n    exit() # Exit if data isn't ready\\n\\n# --- Instantiate the DataLoader ---\\nBATCH_SIZE = 64\\nNUM_WORKERS = 2 # Number of subprocesses for data loading (set to 0 for debugging)\\n\\ntrain_loader = DataLoader(\\n    train_dataset,\\n    batch_size=BATCH_SIZE,\\n    shuffle=True,      # Shuffle training data\\n    num_workers=NUM_WORKERS\\n)\\n\\ntest_loader = DataLoader(\\n    test_dataset,\\n    batch_size=BATCH_SIZE,\\n    shuffle=False,     # No need to shuffle test data\\n    num_workers=NUM_WORKERS\\n)\\n\\n# --- Example: Iterate through a batch ---\\nprint(\\\"\\\\nIterating through a batch from the DataLoader...\\\")\\n\\n# Get one batch\\nimages, labels = next(iter(train_loader))\\n\\nprint(f\\\"Batch of images shape: {images.shape}\\\") # Expected: [batch_size, channels, height, width] -> [64, 1, 28, 28]\\nprint(f\\\"Batch of labels shape: {labels.shape}\\\") # Expected: [batch_size]\\nprint(f\\\"Labels in batch: {labels}\\\")\\n\\n# Optional: Visualize a few images from the batch\\nprint(\\\"\\\\nDisplaying first 4 images from the batch:\\\")\\nfig = plt.figure(figsize=(8, 8))\\nfor i in range(4):\\n    ax = fig.add_subplot(2, 2, i + 1)\\n    ax.set_title(f\\\"Label: {train_dataset.classes[labels[i]]}\\\")\\n    ax.axis('off')\\n    # Undo normalization and permute dimensions for plotting (C, H, W) -> (H, W, C) or (H, W) for grayscale\\n    img_display = images[i] * 0.353 + 0.286 # Undo normalization\\n    img_display = img_display.squeeze() # Remove channel dimension if grayscale\\n    plt.imshow(img_display.numpy(), cmap='gray')\\nplt.tight_layout()\\nplt.show()\\n\\n\\nprint(\\\"\\\\nDataLoader setup complete. You can now use train_loader and test_loader.\\\")\\n```\\n\\n**Reasoning for DataLoader Usage:**\\n\\n*   **Instantiation:** You create instances of your custom `FashionMNISTFolderDataset` for training and testing, applying the desired transformations.\\n*   **`DataLoader(dataset, ...)`:** The `DataLoader` takes the dataset object as its primary argument.\\n*   **`batch_size`:** Specifies how many samples are grouped together in each batch returned by the loader.\\n*   **`shuffle=True`:** Important for training data to randomize the order of samples across epochs, helping the model generalize better. `shuffle=False` is typical for validation/testing.\\n*   **`num_workers`:** Controls how many subprocesses are used for data loading. `0` means the data loading is done in the main process. Using a small number (like 2 or 4) can speed up loading by fetching the next batch while the current one is being processed on the GPU, but setting it too high can consume excessive CPU/memory.\\n*   **Iteration:** You typically iterate through the `DataLoader` in your training loop (`for images, labels in train_loader:`). Each iteration yields a batch of image tensors and a batch of label tensors, ready to be passed to your model.\\n*   **`next(iter(train_loader))`:** A common way to get just *one* batch for inspection, as shown in the example.\\n\\n**Summary of the Full Process:**\\n\\n1.  **(One-time Setup)** Run the `save_fashion_mnist_to_folder()` function to download the original FashionMNIST data and save it as individual image files within a class-based folder structure.\\n2.  Define the `FashionMNISTFolderDataset` class, inheriting from `torch.utils.data.Dataset`. Implement `__init__`, `__len__`, and `__getitem__` to read from the created folder structure.\\n3.  Define any necessary `torchvision.transforms`.\\n4.  Instantiate the `FashionMNISTFolderDataset`, providing the root folder path, split (train/test), and transforms.\\n5.  Instantiate `torch.utils.data.DataLoader`, passing the dataset object, desired batch size, shuffle option, and number of workers.\\n6.  Use the `DataLoader` instances (e.g., `train_loader`, `test_loader`) in your training and evaluation loops.\\n\\nThis setup effectively demonstrates how to handle datasets that are stored as loose files in a directory structure, providing a flexible pattern applicable to many real-world image datasets.\",\n          \"Okay, let's create a Python function using TensorFlow to train a simple linear regression model on the California Housing dataset. We'll go through the steps: loading data, preparing it, defining the model, compiling it, and training it.\\n\\n**Step-by-step Reasoning and Code Generation:**\\n\\n1.  **Import necessary libraries:** We need TensorFlow for the model, `tensorflow_datasets` to load the dataset easily, and scikit-learn for data splitting and scaling (common preprocessing steps).\\n\\n    ```python\\n    import tensorflow as tf\\n    import tensorflow_datasets as tfds\\n    from sklearn.model_selection import train_test_split\\n    from sklearn.preprocessing import StandardScaler\\n    import numpy as np\\n    ```\\n    *   `tensorflow`: The core library.\\n    *   `tensorflow_datasets`: Provides convenient access to many standard datasets like California Housing.\\n    *   `train_test_split`: Essential for dividing our data into a set for training the model and a separate set for evaluating it. This prevents overfitting.\\n    *   `StandardScaler`: A standard preprocessing step for numerical data. It scales features to have zero mean and unit variance, which often helps optimization algorithms (like the one used in training) converge faster and perform better.\\n    *   `numpy`: Useful for handling numerical arrays, which the data will be converted into.\\n\\n2.  **Define the function:** We'll put all the logic inside a function for reusability.\\n\\n    ```python\\n    def train_linear_regression_california_housing(epochs=50, batch_size=32):\\n        # ... rest of the code will go here\\n        pass # Placeholder\\n    ```\\n    *   The function is named descriptively.\\n    *   We add parameters for `epochs` and `batch_size` as these are common hyperparameters for training. Default values are provided.\\n\\n3.  **Load the dataset:** We use `tensorflow_datasets` to load the California Housing dataset. We'll load the 'train' split initially and then manually split it further using scikit-learn, which is often more straightforward for applying preprocessing like scaling.\\n\\n    ```python\\n        # 1. Load the dataset\\n        print(\\\"Loading California Housing dataset...\\\")\\n        ds = tfds.load('california_housing', split='train', as_supervised=False)\\n        print(\\\"Dataset loaded.\\\")\\n    ```\\n    *   `tfds.load('california_housing', ...)`: Loads the dataset by name.\\n    *   `split='train'`: We load the official 'train' split provided by TFDS. Note that the California Housing dataset in TFDS only has a 'train' split, so we'll split this further ourselves.\\n    *   `as_supervised=False`: By default, `as_supervised=True` would return tuples of (features, label). Since the California Housing dataset has multiple features under a single key ('features') and the target ('median_house_value') is separate, `as_supervised=False` returns a dictionary for each example, which is easier to work with here.\\n\\n4.  **Prepare the data (Extract, Convert, Split, Scale):**\\n    *   Convert the `tf.data.Dataset` into NumPy arrays.\\n    *   Separate features (X) and target (y).\\n    *   Split into training and testing sets.\\n    *   Scale the features.\\n\\n    ```python\\n        # 2. Prepare the data\\n        print(\\\"Preparing data (Extracting, Splitting, Scaling)...\\\")\\n        # Convert dataset to numpy arrays\\n        data = list(ds.as_numpy_iterator())\\n        features = np.array([item['features'] for item in data])\\n        labels = np.array([item['median_house_value'] for item in data])\\n\\n        # Split data into training and testing sets\\n        # We'll use 80% for training, 20% for testing\\n        X_train, X_test, y_train, y_test = train_test_split(\\n            features, labels, test_size=0.2, random_state=42\\n        )\\n\\n        # Scale the features\\n        # Scaling is important for many optimization algorithms\\n        scaler = StandardScaler()\\n        X_train_scaled = scaler.fit_transform(X_train)\\n        X_test_scaled = scaler.transform(X_test)\\n\\n        # The target variable (house value) is also numerical,\\n        # and while not strictly necessary for basic linear regression correctness,\\n        # scaling the target can sometimes help training stability or interpretation\\n        # depending on the loss function and metrics used.\\n        # However, for standard MSE, scaling features is usually sufficient\\n        # and scaling the target requires inverse scaling for predictions.\\n        # Let's keep it simple and only scale features for this example.\\n        print(f\\\"Data shapes: X_train={X_train_scaled.shape}, y_train={y_train.shape}, X_test={X_test_scaled.shape}, y_test={y_test.shape}\\\")\\n        print(\\\"Data preparation complete.\\\")\\n\\n    ```\\n    *   `list(ds.as_numpy_iterator())`: Converts the `tf.data.Dataset` into a list of dictionaries, then `np.array([...])` converts the values from those dictionaries into NumPy arrays.\\n    *   `features = np.array([item['features'] for item in data])`: Extracts the feature arrays.\\n    *   `labels = np.array([item['median_house_value'] for item in data])`: Extracts the target variable.\\n    *   `train_test_split(...)`: Shuffles and splits the data. `test_size=0.2` means 20% goes to the test set. `random_state=42` ensures reproducibility.\\n    *   `StandardScaler()`: Creates a scaler object.\\n    *   `scaler.fit_transform(X_train)`: Calculates the mean and standard deviation *only* on the training data (`fit`) and then applies the scaling to the training data (`transform`).\\n    *   `scaler.transform(X_test)`: Applies the *same* scaling (using the mean/std from the training data) to the test data. It's crucial *not* to fit the scaler on the test data to avoid data leakage.\\n\\n5.  **Define the model:** A simple linear regression model can be represented by a single `Dense` layer with one unit and no activation function (or linear activation, which is the default).\\n\\n    ```python\\n        # 3. Define the model\\n        print(\\\"Defining the model...\\\")\\n        # A linear regression model is essentially a single neuron (dense layer with 1 unit)\\n        # with a linear activation function (which is the default).\\n        # The number of input features must match the input data shape.\\n        model = tf.keras.Sequential([\\n            tf.keras.layers.Dense(\\n                units=1,                  # One output unit for the single regression target\\n                input_shape=(X_train_scaled.shape[1],) # Input shape is the number of features\\n            )\\n        ])\\n        print(\\\"Model defined.\\\")\\n        model.summary()\\n    ```\\n    *   `tf.keras.Sequential([...])`: Creates a sequential model, which is a stack of layers.\\n    *   `tf.keras.layers.Dense(...)`: A fully connected layer.\\n    *   `units=1`: This layer has one neuron, which will produce a single output (our predicted house value).\\n    *   `input_shape=(X_train_scaled.shape[1],)`: Tells the first layer the expected shape of the input data. `X_train_scaled.shape[1]` gives the number of features. The comma is important to indicate it's a tuple representing the shape of *one* input sample (e.g., `(8,)` for 8 features).\\n    *   `model.summary()`: Prints a summary of the model's layers and parameters. For this model, the parameters will be `num_features * 1` (weights) + `1` (bias).\\n\\n6.  **Compile the model:** We need to specify the optimizer, the loss function, and any metrics to monitor.\\n\\n    ```python\\n        # 4. Compile the model\\n        print(\\\"Compiling the model...\\\")\\n        # For linear regression:\\n        # Optimizer: Adam is a common and effective choice. SGD or others could also work.\\n        # Loss: Mean Squared Error (MSE) is the standard loss function for regression.\\n        # Metrics: MSE and Mean Absolute Error (MAE) are useful for evaluation.\\n        model.compile(\\n            optimizer='adam', # Or tf.keras.optimizers.Adam()\\n            loss='mse',       # Mean Squared Error\\n            metrics=['mae', 'mse'] # Mean Absolute Error and Mean Squared Error\\n        )\\n        print(\\\"Model compiled.\\\")\\n    ```\\n    *   `model.compile(...)`: Configures the model for training.\\n    *   `optimizer='adam'`: Specifies the Adam optimization algorithm. This algorithm adapts the learning rate during training and often converges quickly.\\n    *   `loss='mse'`: Specifies Mean Squared Error as the loss function. The model will try to minimize this value during training. MSE is calculated as the average of the squared differences between the predicted and actual values.\\n    *   `metrics=['mae', 'mse']`: Specifies additional metrics to calculate and report during training and evaluation. MAE (Mean Absolute Error) is the average of the absolute differences. It's often easier to interpret than MSE as it's in the same units as the target variable. We include MSE again here to see its value directly during training.\\n\\n7.  **Train the model:** Use the `fit` method to train the model on the training data.\\n\\n    ```python\\n        # 5. Train the model\\n        print(f\\\"Training the model for {epochs} epochs with batch size {batch_size}...\\\")\\n        history = model.fit(\\n            X_train_scaled, y_train,\\n            validation_data=(X_test_scaled, y_test), # Monitor performance on the test set during training\\n            epochs=epochs,\\n            batch_size=batch_size,\\n            verbose=1 # Show training progress\\n        )\\n        print(\\\"Model training complete.\\\")\\n    ```\\n    *   `model.fit(...)`: Starts the training process.\\n    *   `X_train_scaled, y_train`: The input features and target values for training.\\n    *   `validation_data=(X_test_scaled, y_test)`: Provides data to evaluate the model on after each epoch. This helps monitor for overfitting (if validation loss starts increasing while training loss decreases).\\n    *   `epochs`: The number of times the model will iterate over the entire training dataset.\\n    *   `batch_size`: The number of samples processed before the model's weights are updated.\\n    *   `verbose=1`: Displays a progress bar and metrics for each epoch.\\n\\n8.  **Return results:** The function can return the trained model and/or the training history. The history object contains the loss and metric values recorded during training.\\n\\n    ```python\\n        # 6. Return the trained model and history\\n        return model, history\\n    ```\\n\\n9.  **Add execution block:** Include a main block to call the function and potentially print some results or evaluate the model.\\n\\n    ```python\\n    if __name__ == \\\"__main__\\\":\\n        # Set a random seed for reproducibility\\n        tf.random.set_seed(42)\\n        np.random.seed(42)\\n\\n        trained_model, training_history = train_linear_regression_california_housing(epochs=100, batch_size=64)\\n\\n        print(\\\"\\\\n--- Training Finished ---\\\")\\n        print(\\\"Trained Model Summary:\\\")\\n        trained_model.summary()\\n\\n        # Optional: Evaluate the model on the test set\\n        print(\\\"\\\\nEvaluating the model on the test set...\\\")\\n        # Need to reload/re-prepare test data for evaluation outside the function call\\n        # (or pass it back from the function, which is cleaner)\\n        # Let's modify the function to return the test data as well for evaluation\\n        # OR just use the history object which contains validation results.\\n        # History contains validation metrics per epoch.\\n        # To get final performance, we can evaluate the model directly.\\n        # Let's re-split/scale outside just for the final evaluation step demonstration.\\n\\n        # --- Re-prepare test data for final evaluation (demonstration) ---\\n        ds_eval = tfds.load('california_housing', split='train', as_supervised=False)\\n        data_eval = list(ds_eval.as_numpy_iterator())\\n        features_eval = np.array([item['features'] for item in data_eval])\\n        labels_eval = np.array([item['median_house_value'] for item in data_eval])\\n        # Use the same split and random_state as inside the function\\n        _, X_test_eval, _, y_test_eval = train_test_split(\\n            features_eval, labels_eval, test_size=0.2, random_state=42\\n        )\\n        # Use the *same* scaler fitted *only* on the training data (if scaler was returned)\\n        # Since the scaler wasn't returned, we need to refit it on training data again,\\n        # which is okay *only* for demonstrating post-training evaluation if we can't\\n        # reuse the scaler object directly. A better design might pass the scaler back.\\n        # For simplicity here, let's just fit a *new* scaler on the original *full* dataset\\n        # for evaluation features - this isn't ideal but works for demo if scaler isn't returned.\\n        # A *better* approach is to return the scaler from the function or evaluate within.\\n        # Let's stick to evaluating *within* the function before returning, or use history.\\n        # History has validation results, which is sufficient for this example.\\n        # Let's print the last validation metrics from history.\\n\\n        print(\\\"\\\\nValidation results from last epoch:\\\")\\n        # history.history is a dictionary containing lists of metric values per epoch\\n        last_epoch_metrics = {metric: values[-1] for metric, values in training_history.history.items()}\\n        print(last_epoch_metrics)\\n\\n        # Example prediction\\n        # Predict on the first few test samples\\n        print(\\\"\\\\nMaking predictions on the first 5 test samples:\\\")\\n        predictions = trained_model.predict(X_test_scaled[:5])\\n        print(\\\"Predicted values:\\\", predictions.flatten())\\n        print(\\\"Actual values:   \\\", y_test[:5])\\n\\n    ```\\n    *   `if __name__ == \\\"__main__\\\":`: Ensures this code runs only when the script is executed directly.\\n    *   `tf.random.set_seed(42)` and `np.random.seed(42)`: Sets seeds for reproducibility of TensorFlow operations and NumPy operations (like splitting).\\n    *   Calls the function.\\n    *   Prints the model summary again.\\n    *   Accesses the `history` object to print the final validation metrics.\\n    *   Demonstrates making predictions on a few samples from the scaled test set.\\n\\n10. **Assemble the final code:** Combine all the pieces into one script.\\n\\nThis detailed process breaks down the problem into manageable steps: data handling, model definition, configuration, training, and evaluation, explaining the purpose of each code segment along the way.\\n\\n```python\\nimport tensorflow as tf\\nimport tensorflow_datasets as tfds\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nimport numpy as np\\n\\ndef train_linear_regression_california_housing(epochs=100, batch_size=64):\\n    \\\"\\\"\\\"\\n    Loads, prepares, and trains a simple linear regression model\\n    on the California Housing dataset using TensorFlow/Keras.\\n\\n    Args:\\n        epochs (int): Number of epochs to train for.\\n        batch_size (int): Batch size for training.\\n\\n    Returns:\\n        tuple: A tuple containing the trained Keras model and the training history object.\\n    \\\"\\\"\\\"\\n\\n    # --- Step-by-step Implementation ---\\n\\n    # 1. Load the dataset\\n    # Reasoning: We need the data to train and evaluate the model.\\n    # tfds provides easy access to standard datasets.\\n    print(\\\"Loading California Housing dataset...\\\")\\n    # Load the 'train' split. as_supervised=False gives a dict for each example.\\n    ds = tfds.load('california_housing', split='train', as_supervised=False)\\n    print(\\\"Dataset loaded.\\\")\\n\\n    # 2. Prepare the data (Extract, Convert, Split, Scale)\\n    # Reasoning:\\n    # - We need features (X) and targets (y) separately.\\n    # - Keras .fit() method typically expects numpy arrays or tf.data.Dataset.\\n    # - Splitting into train/test is crucial to evaluate model performance on unseen data.\\n    # - Scaling features helps the optimizer converge faster.\\n    print(\\\"Preparing data (Extracting, Splitting, Scaling)...\\\")\\n    # Convert dataset to numpy arrays for easier manipulation with sklearn\\n    data = list(ds.as_numpy_iterator())\\n    features = np.array([item['features'] for item in data])\\n    labels = np.array([item['median_house_value'] for item in data])\\n\\n    # Split data into training and testing sets (e.g., 80% train, 20% test)\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        features, labels, test_size=0.2, random_state=42 # random_state for reproducibility\\n    )\\n\\n    # Scale the features using StandardScaler\\n    # Fit on training data, transform both training and testing data.\\n    scaler = StandardScaler()\\n    X_train_scaled = scaler.fit_transform(X_train)\\n    X_test_scaled = scaler.transform(X_test)\\n\\n    # Optional: Inspect shapes\\n    print(f\\\"Data shapes: X_train={X_train_scaled.shape}, y_train={y_train.shape}, X_test={X_test_scaled.shape}, y_test={y_test.shape}\\\")\\n    print(\\\"Data preparation complete.\\\")\\n\\n    # 3. Define the model\\n    # Reasoning:\\n    # - A simple linear regression model predicts y as a linear combination of X: y = w*X + b\\n    # - In Keras, a Dense layer with units=1 and linear activation (the default)\\n    #   performs exactly this calculation.\\n    # - Sequential model is used for a simple stack of layers.\\n    print(\\\"Defining the model (Simple Linear Regression with one Dense layer)...\\\")\\n    model = tf.keras.Sequential([\\n        # The first layer needs input_shape to know the number of features\\n        tf.keras.layers.Dense(\\n            units=1,                  # One output unit for the single regression target\\n            input_shape=(X_train_scaled.shape[1],) # Input shape is the number of features\\n        )\\n    ])\\n    print(\\\"Model defined.\\\")\\n    model.summary() # Print model architecture\\n\\n    # 4. Compile the model\\n    # Reasoning:\\n    # - Compilation configures the model for training.\\n    # - Optimizer: Algorithm to minimize the loss (e.g., Adam).\\n    # - Loss: Function to measure how far predictions are from actual values (MSE for regression).\\n    # - Metrics: Additional metrics to evaluate during training (MAE is often more interpretable than MSE).\\n    print(\\\"Compiling the model...\\\")\\n    model.compile(\\n        optimizer='adam',       # Adam optimizer is a good default\\n        loss='mse',             # Mean Squared Error, standard for regression\\n        metrics=['mae', 'mse']  # Mean Absolute Error and MSE to monitor\\n    )\\n    print(\\\"Model compiled.\\\")\\n\\n    # 5. Train the model\\n    # Reasoning:\\n    # - The .fit() method trains the model using the specified data and parameters.\\n    # - X_train_scaled, y_train: The training data.\\n    # - validation_data: Data to evaluate model performance *during* training (after each epoch).\\n    # - epochs: Number of passes over the entire training dataset.\\n    # - batch_size: Number of samples processed before a weight update.\\n    print(f\\\"Training the model for {epochs} epochs with batch size {batch_size}...\\\")\\n    history = model.fit(\\n        X_train_scaled, y_train,\\n        validation_data=(X_test_scaled, y_test), # Evaluate on test set after each epoch\\n        epochs=epochs,\\n        batch_size=batch_size,\\n        verbose=1 # Show training progress per epoch\\n    )\\n    print(\\\"Model training complete.\\\")\\n\\n    # 6. Return the trained model and history\\n    # Reasoning: The caller might want to use the model for predictions or analyze training progress.\\n    return model, history\\n\\n# --- Example Usage ---\\nif __name__ == \\\"__main__\\\":\\n    # Set seeds for reproducibility\\n    tf.random.set_seed(42)\\n    np.random.seed(42)\\n\\n    # Train the model by calling the function\\n    trained_model, training_history = train_linear_regression_california_housing(epochs=100, batch_size=64)\\n\\n    print(\\\"\\\\n--- Training Summary ---\\\")\\n    print(\\\"Trained Model Summary:\\\")\\n    trained_model.summary()\\n\\n    # Print final validation metrics from the training history\\n    print(\\\"\\\\nValidation results from the last epoch:\\\")\\n    # history.history is a dictionary containing lists of metric values per epoch\\n    last_epoch_metrics = {metric: values[-1] for metric, values in training_history.history.items()}\\n    print(last_epoch_metrics)\\n\\n    # --- Demonstrate Prediction ---\\n    # To make predictions, we need the test data and the scaler used during training.\\n    # A robust function would return the scaler, but for this simple example,\\n    # we'll just show the process assuming we have access to X_test_scaled.\\n    # In a real application, save the scaler or return it from the function.\\n\\n    # Let's reload/resplit the data just to get X_test and y_test again outside the function scope\\n    # (This is not ideal for general use, but demonstrates prediction flow)\\n    ds_eval = tfds.load('california_housing', split='train', as_supervised=False)\\n    data_eval = list(ds_eval.as_numpy_iterator())\\n    features_eval = np.array([item['features'] for item in data_eval])\\n    labels_eval = np.array([item['median_house_value'] for item in data_eval])\\n    _, X_test_raw, _, y_test_raw = train_test_split(\\n        features_eval, labels_eval, test_size=0.2, random_state=42 # Same split\\n    )\\n    # IMPORTANT: You MUST use the SAME scaler fitted on the training data!\\n    # Since we didn't return the scaler, we'd ideally reload it if saved, or refit on original training data here.\\n    # For demonstration, let's just create and fit a new scaler on the *full* data for prediction features.\\n    # ***WARNING: Fitting scaler on full data for evaluation/prediction is technically data leakage.\\n    # A proper flow returns the fitted scaler or saves/loads it.***\\n    # Re-creating the scaler fitted ONLY on original training data:\\n    temp_scaler = StandardScaler()\\n    temp_scaler.fit(train_test_split(features_eval, labels_eval, test_size=0.2, random_state=42)[0]) # Fit only on training part\\n\\n    X_test_scaled_for_pred = temp_scaler.transform(X_test_raw)\\n\\n\\n    print(\\\"\\\\nMaking predictions on the first 5 test samples:\\\")\\n    # Predict expects scaled input features\\n    predictions = trained_model.predict(X_test_scaled_for_pred[:5])\\n    print(\\\"Predicted values:\\\", predictions.flatten())\\n    print(\\\"Actual values:   \\\", y_test_raw[:5])\\n    # Note: Predictions are in the original scale of y because y was not scaled.\\n```\\n\\n**Explanation of Key Steps and Reasoning:**\\n\\n1.  **Import Libraries:** We gather the necessary tools from TensorFlow (for model building), TensorFlow Datasets (for easy data access), and Scikit-learn (for data splitting and scaling).\\n2.  **Load Dataset:** We use `tfds.load` to get the California Housing data. We load the 'train' split and keep it in a dictionary format (`as_supervised=False`) initially, as the features and target are separate keys.\\n3.  **Prepare Data:**\\n    *   We convert the TF dataset into NumPy arrays. This is convenient for using Scikit-learn's data preprocessing utilities.\\n    *   We separate the features (`X`) and the target (`y`). The goal of linear regression is to predict `y` from `X`.\\n    *   `train_test_split` divides the data into two subsets: one for training the model (`X_train`, `y_train`) and one for evaluating its performance (`X_test`, `y_test`). This prevents the model from simply memorizing the training data (overfitting). A `random_state` is used to ensure the split is the same every time the code runs.\\n    *   `StandardScaler` is applied to the features. Scaling brings all features to a similar range (mean 0, variance 1). This is important for gradient-based optimizers like Adam, as it can help them converge faster and more stably, especially when features have different scales. It's fitted *only* on the training data (`fit_transform`) to learn the scaling parameters, and then these parameters are applied to both training and test data (`transform`) to avoid data leakage from the test set into the training process.\\n4.  **Define Model:**\\n    *   We use `tf.keras.Sequential` because our model is a simple linear stack of layers.\\n    *   The model consists of a single `tf.keras.layers.Dense` layer.\\n    *   `units=1`: A `Dense` layer with one unit calculates a weighted sum of its inputs plus a bias term (`output = w1*x1 + w2*x2 + ... + wn*xn + b`). This is exactly the form of a simple linear regression equation.\\n    *   `input_shape=(X_train_scaled.shape[1],)`: This tells the layer how many input features to expect for each sample. `X_train_scaled.shape[1]` is the number of columns (features) in our scaled training data.\\n    *   The `activation` is by default 'linear', which is correct for linear regression (we don't want to apply a non-linear transformation to the output).\\n5.  **Compile Model:**\\n    *   `model.compile` prepares the model for the training process.\\n    *   `optimizer='adam'`: We choose the Adam optimizer. It's an efficient and widely used algorithm for updating the model's weights based on the training data and the calculated loss.\\n    *   `loss='mse'`: We select Mean Squared Error (MSE) as the loss function. This is the standard loss for regression problems. The training process aims to minimize the average of the squared differences between the model's predictions and the actual target values.\\n    *   `metrics=['mae', 'mse']`: We specify Mean Absolute Error (MAE) and MSE as metrics to monitor. Metrics are displayed during training but *not* used to optimize the model (only the loss function is used for optimization). MAE is often easier to interpret than MSE as it's in the same units as the target variable.\\n6.  **Train Model:**\\n    *   `model.fit` starts the training loop.\\n    *   `X_train_scaled` and `y_train` are the input and output data used to train the model.\\n    *   `validation_data=(X_test_scaled, y_test)` provides the test set to evaluate the model's performance after each training epoch. This helps monitor if the model is learning well or starting to overfit (validation loss increases).\\n    *   `epochs` is the number of times the training algorithm iterates through the entire training dataset.\\n    *   `batch_size` determines how many samples are processed at a time within each epoch before the model's weights are updated.\\n    *   `verbose=1` displays training progress.\\n7.  **Return Results:** The function returns the trained `model` object, which can be used for making predictions, and the `history` object, which contains the recorded loss and metric values per epoch for both training and validation sets.\\n\\nThis function provides a clear and well-structured way to perform a simple linear regression task using TensorFlow on a common dataset, following standard machine learning practices like data splitting and scaling.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"few_shot_gemini\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Okay, here is a complete Python script using PyTorch to train a Convolutional Neural Network (CNN) on the CIFAR-10 dataset.\\n\\nThis script covers:\\n1.  **Imports:** Necessary libraries.\\n2.  **Device Configuration:** Checks for CUDA availability.\\n3.  **Hyperparameters:** Sets learning rate, batch size, epochs, etc.\\n4.  **Data Loading:** Downloads and loads CIFAR-10 with appropriate transformations.\\n5.  **Model Definition:** Defines a simple CNN architecture.\\n6.  **Loss Function and Optimizer:** Sets up `CrossEntropyLoss` and `Adam` optimizer.\\n7.  **Training Loop:** Iterates through epochs, performs forward/backward passes, and updates weights.\\n8.  **Evaluation:** Evaluates the model on the test set after training.\\n\\n```python\\nimport torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\nimport torchvision\\nimport torchvision.transforms as transforms\\nfrom torch.utils.data import DataLoader\\nimport matplotlib.pyplot as plt # For optional plotting\\n\\n# --- 1. Device Configuration ---\\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\nprint(f'Using device: {device}')\\n\\n# --- 2. Hyperparameters ---\\nnum_epochs = 10\\nbatch_size = 100\\nlearning_rate = 0.001\\n\\n# CIFAR-10 has 10 classes (0-9)\\nnum_classes = 10\\n\\n# Input image dimensions (3 channels for RGB, 32x32 pixels)\\nin_channels = 3\\n\\n# --- 3. Data Loading ---\\n\\n# Transformations for the data\\n# CIFAR-10 images are 32x32.\\n# We convert images to PyTorch tensors and normalize them.\\n# Standard normalization values for CIFAR-10 are often used.\\ntransform = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize to [-1, 1] range\\n])\\n\\n# Load CIFAR-10 training dataset\\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\\n                                             download=True, transform=transform)\\n\\n# Load CIFAR-10 test dataset\\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\\n                                            download=True, transform=transform)\\n\\n# Create data loaders\\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) # No need to shuffle test data\\n\\n# --- 4. Model Definition ---\\n\\n# Simple CNN model\\nclass SimpleCNN(nn.Module):\\n    def __init__(self, in_channels, num_classes):\\n        super(SimpleCNN, self).__init__()\\n        # First convolutional layer\\n        # Input: 3x32x32\\n        # Output: 32 feature maps, 32x32 size (padding=1 preserves size for kernel=3)\\n        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1)\\n        self.relu1 = nn.ReLU()\\n        # First pooling layer\\n        # Input: 32x32x32\\n        # Output: 32 feature maps, 16x16 size (MaxPool2d halves dimensions)\\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\\n\\n        # Second convolutional layer\\n        # Input: 32x16x16\\n        # Output: 64 feature maps, 16x16 size\\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\\n        self.relu2 = nn.ReLU()\\n        # Second pooling layer\\n        # Input: 64x16x16\\n        # Output: 64 feature maps, 8x8 size\\n        # self.pool (reusing the same pooling layer definition)\\n\\n        # Third convolutional layer (optional, but good for slightly deeper networks)\\n        # Input: 64x8x8\\n        # Output: 128 feature maps, 8x8 size\\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\\n        self.relu3 = nn.ReLU()\\n        # Third pooling layer\\n        # Input: 128x8x8\\n        # Output: 128 feature maps, 4x4 size\\n        # self.pool (reusing)\\n\\n\\n        # Fully connected layers\\n        # Input size calculation: After 3 conv/relu/pool blocks (with kernel=3, padding=1 and pool=2),\\n        # the spatial dimensions go from 32 -> 16 -> 8 -> 4.\\n        # The last convolutional layer had 128 output channels.\\n        # Flattened size: 128 * 4 * 4 = 2048\\n        self.fc1 = nn.Linear(128 * 4 * 4, 512) # First fully connected layer\\n        self.relu4 = nn.ReLU()\\n        self.fc2 = nn.Linear(512, num_classes) # Output layer\\n\\n    def forward(self, x):\\n        # Conv 1 -> ReLU 1 -> Pool 1\\n        x = self.pool(self.relu1(self.conv1(x)))\\n        # Conv 2 -> ReLU 2 -> Pool 2\\n        x = self.pool(self.relu2(self.conv2(x)))\\n        # Conv 3 -> ReLU 3 -> Pool 3\\n        x = self.pool(self.relu3(self.conv3(x)))\\n\\n        # Flatten the tensor for the fully connected layers\\n        # -1 tells PyTorch to infer the dimension\\n        x = x.view(x.size(0), -1) # or use torch.flatten(x, 1)\\n\\n        # Fully connected layers\\n        x = self.relu4(self.fc1(x))\\n        x = self.fc2(x) # Output layer (logits)\\n        return x\\n\\n# Instantiate the model and move to device\\nmodel = SimpleCNN(in_channels, num_classes).to(device)\\n\\n# --- 5. Loss and Optimizer ---\\ncriterion = nn.CrossEntropyLoss() # Suitable for multi-class classification\\noptimizer = optim.Adam(model.parameters(), lr=learning_rate) # Adam optimizer\\n\\n# --- 7. Training Loop ---\\nprint(\\\"\\\\nStarting training...\\\")\\n\\n# Lists to store loss for plotting (optional)\\n# train_losses = []\\n# test_accuracies = []\\n\\ntotal_steps = len(train_loader)\\nfor epoch in range(num_epochs):\\n    model.train() # Set the model to training mode\\n    running_loss = 0.0\\n    for i, (images, labels) in enumerate(train_loader):\\n        # Move tensors to the configured device\\n        images = images.to(device)\\n        labels = labels.to(device)\\n\\n        # Forward pass\\n        outputs = model(images)\\n        loss = criterion(outputs, labels)\\n\\n        # Backward and optimize\\n        optimizer.zero_grad() # Clear previous gradients\\n        loss.backward()       # Compute gradient of the loss w.r.t. model parameters\\n        optimizer.step()      # Perform a single optimization step (parameter update)\\n\\n        running_loss += loss.item()\\n\\n        # Print training progress (optional)\\n        # if (i+1) % 100 == 0: # Print every 100 steps\\n        #     print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], Loss: {loss.item():.4f}')\\n\\n    avg_train_loss = running_loss / total_steps\\n    print(f'Epoch [{epoch+1}/{num_epochs}], Average Training Loss: {avg_train_loss:.4f}')\\n    # train_losses.append(avg_train_loss) # Store loss\\n\\n    # --- 8. Evaluation (after each epoch) ---\\n    # In evaluation mode, we don't need to track gradients\\n    model.eval()\\n    with torch.no_grad():\\n        correct = 0\\n        total = 0\\n        for images, labels in test_loader:\\n            images = images.to(device)\\n            labels = labels.to(device)\\n            outputs = model(images)\\n            # Get predictions from the maximum value\\n            _, predicted = torch.max(outputs.data, 1)\\n            total += labels.size(0)\\n            correct += (predicted == labels).sum().item()\\n\\n        accuracy = 100 * correct / total\\n        print(f'Test Accuracy of the model on the {total} test images: {accuracy:.2f} %')\\n        # test_accuracies.append(accuracy) # Store accuracy\\n\\nprint(\\\"\\\\nTraining finished.\\\")\\n\\n# Optional: Plotting training loss and test accuracy over epochs\\n# plt.figure(figsize=(10, 5))\\n# plt.subplot(1, 2, 1)\\n# plt.plot(range(1, num_epochs + 1), train_losses)\\n# plt.xlabel(\\\"Epoch\\\")\\n# plt.ylabel(\\\"Training Loss\\\")\\n# plt.title(\\\"Training Loss per Epoch\\\")\\n\\n# plt.subplot(1, 2, 2)\\n# plt.plot(range(1, num_epochs + 1), test_accuracies)\\n# plt.xlabel(\\\"Epoch\\\")\\n# plt.ylabel(\\\"Test Accuracy (%)\\\")\\n# plt.title(\\\"Test Accuracy per Epoch\\\")\\n\\n# plt.tight_layout()\\n# plt.show()\\n\\n# --- Optional: Save the model ---\\n# torch.save(model.state_dict(), 'cifar10_cnn_model.pth')\\n# print(\\\"Model saved to cifar10_cnn_model.pth\\\")\\n\\n```\\n\\n**Explanation:**\\n\\n1.  **Imports:** We import necessary modules from `torch`, `torch.nn`, `torch.optim`, and `torchvision`.\\n2.  **Device Configuration:** This block checks if a CUDA-enabled GPU is available and sets the `device` variable accordingly. It's crucial to move your model and data tensors to the correct device.\\n3.  **Hyperparameters:** Essential parameters like the number of training epochs, batch size, learning rate, and dataset-specific values like the number of classes and input channels are defined.\\n4.  **Data Loading:**\\n    *   `transforms.Compose` chains multiple transformations together. `ToTensor()` converts PIL Images or NumPy arrays to PyTorch tensors (scaling pixel values to \\\\[0, 1]). `Normalize` scales the pixel values to a range around zero (here, \\\\[-1, 1]) using the mean and standard deviation for each channel.\\n    *   `torchvision.datasets.CIFAR10` downloads (if not already present) and loads the CIFAR-10 dataset. `train=True` gets the training set, `train=False` gets the test set.\\n    *   `DataLoader` wraps the dataset to provide an iterable over batches. `shuffle=True` for the training loader is important for better training.\\n5.  **Model Definition (`SimpleCNN`):**\\n    *   This class inherits from `nn.Module`.\\n    *   The `__init__` method defines the layers:\\n        *   `nn.Conv2d`: Performs convolution. `in_channels` is the number of input feature maps (3 for RGB). `out_channels` is the number of feature maps produced by this layer. `kernel_size` is the filter size. `padding=1` with `kernel_size=3` and `stride=1` helps maintain the spatial dimensions after convolution.\\n        *   `nn.ReLU`: The Rectified Linear Unit activation function, applied after each convolutional layer.\\n        *   `nn.MaxPool2d`: Downsamples the spatial dimensions (height and width). `kernel_size=2` and `stride=2` is standard for halving the dimensions.\\n        *   `nn.Linear`: A fully connected layer. The input size is calculated based on the output dimensions and feature maps from the last pooling layer. `128 * 4 * 4` comes from 128 output channels of `conv3` and spatial dimensions of `4x4` after the last pooling layer.\\n    *   The `forward` method defines how data flows through the network: it applies the layers sequentially, flattens the tensor before the linear layers, and returns the raw output (logits).\\n6.  **Loss and Optimizer:**\\n    *   `nn.CrossEntropyLoss` is used because it combines the Softmax activation and the negative log-likelihood loss, which is suitable for multi-class classification.\\n    *   `optim.Adam` is a popular optimization algorithm used to update the model's weights based on the calculated gradients. We pass the model's parameters and the learning rate.\\n7.  **Training Loop:**\\n    *   The outer loop iterates through epochs.\\n    *   `model.train()` sets the model to training mode (enables features like dropout if used, though not in this simple model).\\n    *   The inner loop iterates through batches provided by the `train_loader`.\\n    *   Data and labels are moved to the specified `device`.\\n    *   A forward pass (`model(images)`) computes the predictions.\\n    *   The `criterion` calculates the loss between predictions and true labels.\\n    *   `optimizer.zero_grad()` clears gradients from the previous batch.\\n    *   `loss.backward()` computes gradients for all parameters w.r.t. the loss.\\n    *   `optimizer.step()` updates the model parameters using the gradients and the optimizer's rules.\\n8.  **Evaluation:**\\n    *   `model.eval()` sets the model to evaluation mode (disables features like dropout, ensures batch normalization uses global stats if present).\\n    *   `with torch.no_grad():` disables gradient calculation, which saves memory and speeds up computation during evaluation since we don't need to backpropagate.\\n    *   The loop iterates through the `test_loader`.\\n    *   Predictions are made. `torch.max(outputs.data, 1)` returns the maximum value and its index along dimension 1 (the class dimension). The index is the predicted class.\\n    *   `total` and `correct` counters are updated to calculate the overall accuracy.\\n    *   The test accuracy is printed after each epoch.\\n\\nThis script provides a solid foundation for training CNNs on image classification tasks like CIFAR-10. You can extend it by adding more complex layers (like Batch Normalization, Dropout), implementing learning rate scheduling, or saving the best model checkpoint.\",\n          \"Okay, you've provided examples of a custom dataset class loading from files/CSV and another custom dataset class loading synthetic data.\\n\\nFor the FashionMNIST dataset, PyTorch's `torchvision.datasets` module already provides a `Dataset` subclass specifically designed to load this dataset. It handles downloading the data (if needed) and parsing the files. So, the standard approach is to use this built-in class rather than writing a *new* custom class from scratch to parse the FashionMNIST files yourself.\\n\\nHere's how you use the existing `torchvision.datasets.FashionMNIST` class with a `DataLoader`:\\n\\n```python\\nimport torch\\nfrom torch.utils.data import Dataset, DataLoader # Dataset is implicitly used by FashionMNIST\\nimport torchvision\\nimport torchvision.transforms as transforms\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n\\n# --- Configuration ---\\nBATCH_SIZE = 64\\n# Directory to save/load the dataset files\\nDATA_DIR = './data'\\n\\n# --- Transformations ---\\n# FashionMNIST images are PIL images. We need to convert them to PyTorch tensors\\n# and normalize the pixel values to the range [0, 1]. ToTensor() does both.\\ntransform = transforms.Compose([\\n    transforms.ToTensor(),\\n    # Optional: Normalize the images.\\n    # FashionMNIST mean: 0.286, std: 0.353 (calculated over training set)\\n    # transforms.Normalize((0.286,), (0.353,))\\n])\\n\\n# --- Load the FashionMNIST Dataset ---\\n# This class IS the torch.utils.data.Dataset subclass for FashionMNIST\\n# It handles finding/downloading the data files and implements __len__ and __getitem__.\\ntry:\\n    train_dataset = torchvision.datasets.FashionMNIST(\\n        root=DATA_DIR,         # Directory to store data\\n        train=True,            # Load training data\\n        download=True,         # Download data if not available\\n        transform=transform    # Apply the defined transformation\\n    )\\n\\n    # You can also load the test set if needed\\n    # test_dataset = torchvision.datasets.FashionMNIST(\\n    #     root=DATA_DIR,\\n    #     train=False,           # Load test data\\n    #     download=True,\\n    #     transform=transform\\n    # )\\n\\n    print(f\\\"Number of training samples: {len(train_dataset)}\\\")\\n    # print(f\\\"Number of test samples: {len(test_dataset)}\\\")\\n\\nexcept Exception as e:\\n    print(f\\\"Error loading FashionMNIST dataset: {e}\\\")\\n    print(\\\"Please check your internet connection and disk space.\\\")\\n    exit() # Exit if data loading fails\\n\\n# --- Create DataLoader ---\\ntrain_dataloader = DataLoader(\\n    dataset=train_dataset,  # Your dataset object\\n    batch_size=BATCH_SIZE, # How many samples per batch\\n    shuffle=True,           # Shuffle data at the beginning of each epoch (good for training)\\n    num_workers=2           # Number of subprocesses to use for data loading (can speed things up)\\n)\\n\\n# --- Demonstrate Using the DataLoader ---\\nprint(\\\"\\\\nDemonstrating data loading with DataLoader:\\\")\\n\\n# Iterate through the first batch\\nfor images, labels in train_dataloader:\\n    print(f\\\"Batch of images shape: {images.shape}\\\") # Expected: [BATCH_SIZE, 1, 28, 28] (Batch, Channels, Height, Width)\\n    print(f\\\"Batch of labels shape: {labels.shape}\\\") # Expected: [BATCH_SIZE]\\n\\n    # Optional: Display the first image in the batch (requires matplotlib)\\n    if images.shape[0] > 0:\\n        # FashionMNIST is grayscale (1 channel)\\n        plt.imshow(images[0].squeeze(), cmap='gray')\\n        plt.title(f\\\"Example Image (Label: {labels[0].item()})\\\")\\n        plt.axis('off')\\n        plt.show()\\n\\n    # We'll just process one batch for demonstration\\n    break\\n\\nprint(\\\"\\\\nDataLoader setup complete. Ready to use in a training loop.\\\")\\n\\n# Example of a simple training loop structure (no actual training)\\n# model = ... # Define your PyTorch model\\n# criterion = ... # Define your loss function\\n# optimizer = ... # Define your optimizer\\n\\n# num_epochs = 5\\n# for epoch in range(num_epochs):\\n#     for i, (images, labels) in enumerate(train_dataloader):\\n#         # Move tensors to the configured device (e.g., GPU)\\n#         # images = images.to(device)\\n#         # labels = labels.to(device)\\n\\n#         # Forward pass\\n#         # outputs = model(images)\\n#         # loss = criterion(outputs, labels)\\n\\n#         # Backward and optimize\\n#         # optimizer.zero_grad()\\n#         # loss.backward()\\n#         # optimizer.step()\\n\\n#         # Print progress (optional)\\n#         # if (i+1) % 100 == 0:\\n#         #     print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\\n\\n```\\n\\n**Explanation:**\\n\\n1.  **`torchvision.datasets.FashionMNIST`:** This class is already a subclass of `torch.utils.data.Dataset`. When you instantiate it, you point it to a directory (`root`), specify whether you want the training or test split (`train=True`), tell it to download the data if it's not found (`download=True`), and provide any transformations (`transform`). It handles all the details of loading the image and label files.\\n2.  **`transforms.ToTensor()`:** FashionMNIST images are loaded as PIL Images by `torchvision.datasets`. Neural networks work with tensors. `ToTensor()` is a crucial transform that converts a PIL Image or NumPy array (`H x W x C`) into a PyTorch Tensor (`C x H x W`) and automatically scales the pixel values from [0, 255] (uint8) to [0.0, 1.0] (float32).\\n3.  **`DataLoader`:** You then wrap the `train_dataset` object (which is an instance of the `FashionMNIST` `Dataset` subclass) in a `DataLoader`. You specify the `batch_size`, whether to `shuffle` the data (important for training to prevent the model from learning the order), and `num_workers` (how many separate processes to use for data loading, which can speed up fetching batches).\\n4.  **Iteration:** The `DataLoader` becomes an iterable. You can loop through it (e.g., `for images, labels in train_dataloader:`) to get batches of data and labels that are ready to be fed into a PyTorch model.\\n\\nThis is the standard and efficient way to work with well-known datasets like FashionMNIST in PyTorch. You don't need to write a *new* `Dataset` class from scratch unless you are working with a custom dataset that `torchvision.datasets` doesn't cover.\",\n          \"Okay, here is the Python function using TensorFlow/Keras to create, compile, and train a simple linear regression model on the California Housing dataset, including a normalization layer and one dense layer.\\n\\n```python\\nimport numpy as np\\nimport tensorflow as tf\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\nfrom sklearn.datasets import fetch_california_housing\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler # Optional: alternative to Keras Normalization\\n\\ndef create_and_train_california_housing_model():\\n    \\\"\\\"\\\"\\n    Creates, compiles, and trains a simple linear regression model\\n    with a Normalization layer and one Dense layer on the California\\n    Housing dataset.\\n\\n    Returns:\\n        tuple: A tuple containing the trained Keras model and\\n               the training history object.\\n    \\\"\\\"\\\"\\n    print(\\\"Loading California Housing dataset...\\\")\\n    # Load the dataset\\n    # as_frame=True loads it into a pandas DataFrame\\n    housing = fetch_california_housing(as_frame=True)\\n    X, y = housing.data, housing.target\\n\\n    print(f\\\"Dataset loaded. Features shape: {X.shape}, Target shape: {y.shape}\\\")\\n\\n    # Split data into training and testing sets\\n    # Using a test set allows evaluating the final model performance\\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n    print(f\\\"Data split: Train size {X_train.shape[0]}, Test size {X_test.shape[0]}\\\")\\n\\n    # --- Keras Model Definition ---\\n\\n    # 1. Create a Normalization Layer\\n    # This layer will normalize the input features.\\n    # input_shape needs to be the number of features (8 for California Housing).\\n    # axis=-1 normalizes each feature independently across the batch dimension.\\n    normalizer = layers.Normalization(input_shape=[X_train.shape[1],], axis=-1)\\n\\n    # Adapt the normalizer to the training data\\n    # This calculates the mean and variance for normalization\\n    print(\\\"Adapting normalization layer to training data...\\\")\\n    normalizer.adapt(X_train)\\n    print(\\\"Normalization layer adapted.\\\")\\n\\n\\n    # 2. Create the Sequential Model\\n    # The model has two layers:\\n    # - The normalization layer (to scale features)\\n    # - A Dense layer with 1 unit (for linear regression output)\\n    model = keras.Sequential([\\n        normalizer,               # Normalize input features\\n        layers.Dense(units=1)     # Single dense layer for linear output\\n    ])\\n\\n    # Display the model summary\\n    model.summary()\\n\\n    # 3. Compile the Model\\n    # Define the optimizer and the loss function\\n    model.compile(\\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), # Adam optimizer\\n        loss='mean_squared_error'                              # MSE loss for regression\\n    )\\n    print(\\\"Model compiled with Adam optimizer and MSE loss.\\\")\\n\\n    # 4. Train the Model\\n    print(\\\"Starting model training...\\\")\\n    history = model.fit(\\n        X_train,            # Training features\\n        y_train,            # Training labels (target)\\n        epochs=100,         # Number of training epochs\\n        verbose=1,          # Show training progress\\n        # Use a validation split from the training data to monitor performance\\n        # during training without touching the separate test set.\\n        validation_split=0.2\\n    )\\n    print(\\\"Training finished.\\\")\\n\\n    # 5. Evaluate the Model on the Test Set (Optional but recommended)\\n    print(\\\"\\\\nEvaluating model on the test set...\\\")\\n    loss = model.evaluate(X_test, y_test, verbose=0)\\n    print(f\\\"Test Loss (Mean Squared Error): {loss:.4f}\\\")\\n\\n    # 6. Make Predictions (Optional)\\n    print(\\\"\\\\nMaking predictions on the first 5 test samples...\\\")\\n    predictions = model.predict(X_test[:5])\\n    print(\\\"Predictions:\\\")\\n    print(predictions)\\n    print(\\\"Actual values:\\\")\\n    print(y_test[:5].values.reshape(-1, 1)) # Reshape for comparison\\n\\n    return model, history\\n\\n# --- How to use the function ---\\nif __name__ == \\\"__main__\\\":\\n    trained_model, training_history = create_and_train_california_housing_model()\\n\\n    # You can access training history like this:\\n    # print(\\\"\\\\nTraining History Keys:\\\", training_history.history.keys())\\n\\n    # You can plot the training history (e.g., loss vs. epoch)\\n    # import matplotlib.pyplot as plt\\n    # plt.plot(training_history.history['loss'], label='loss')\\n    # plt.plot(training_history.history['val_loss'], label='val_loss')\\n    # plt.xlabel('Epoch')\\n    # plt.ylabel('Loss (MSE)')\\n    # plt.legend()\\n    # plt.grid(True)\\n    # plt.title('Training and Validation Loss')\\n    # plt.show()\\n```\\n\\n**Explanation:**\\n\\n1.  **Import necessary libraries:** TensorFlow, Keras layers, NumPy, and specific parts from scikit-learn for loading and splitting the dataset.\\n2.  **`create_and_train_california_housing_model()` function:** Encapsulates the entire process.\\n3.  **Load Data:** `fetch_california_housing()` loads the dataset. `as_frame=True` provides it as a Pandas DataFrame, which is convenient. We separate features (`X`) and target (`y`).\\n4.  **Split Data:** `train_test_split` divides the data into training and testing sets. It's crucial to evaluate the final model on data it hasn't seen during training.\\n5.  **Normalization Layer:** `layers.Normalization` is created. `input_shape` is set to `[X_train.shape[1],]` because the California Housing dataset has 8 features, and we are feeding all of them to the model. `axis=-1` ensures each feature is normalized independently. `normalizer.adapt(X_train)` calculates the necessary statistics (mean and variance) *only* from the training data.\\n6.  **Model Definition:** A `keras.Sequential` model is created. It contains two layers:\\n    *   The `normalizer` layer takes the raw input features and outputs their normalized versions.\\n    *   A `layers.Dense(units=1)` layer takes the normalized features and computes a single output value using a linear transformation (`output = sum(weights * inputs) + bias`). This single dense layer with one output unit *is* the core of the linear regression model.\\n7.  **Compile Model:**\\n    *   `optimizer='adam'` (or `tf.keras.optimizers.Adam(learning_rate=...)`) is a popular and usually effective optimizer.\\n    *   `loss='mean_squared_error'` is the standard loss function for linear regression problems (minimizing MSE is equivalent to maximizing likelihood under the assumption of Gaussian noise).\\n8.  **Train Model:** `model.fit()` performs the training.\\n    *   `X_train`, `y_train`: The data to train on.\\n    *   `epochs=100`: The model iterates through the training data 100 times.\\n    *   `verbose=1`: Prints progress during training.\\n    *   `validation_split=0.2`: Automatically holds back 20% of the *training data* to use as a validation set. The model is *not* trained on this portion, but the loss on this portion is calculated and reported at the end of each epoch, which helps monitor for overfitting.\\n9.  **Evaluate (Optional):** `model.evaluate()` calculates the loss on the separate `X_test`, `y_test` set. This gives a final, unbiased estimate of the model's performance on unseen data.\\n10. **Predict (Optional):** `model.predict()` generates predictions for new input data (here, the first 5 test samples).\\n\\nThis script effectively implements a simple linear regression model using the Keras API, including the recommended practice of normalizing input features.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["def extract_python_code(text):\n","    code_blocks = re.findall(r\"```(?:python)?(.*?)```\", text, re.DOTALL)\n","    code_blocks = [code.strip() for code in code_blocks]\n","    # print(len(code_blocks))\n","    code_blocks = '\\n'.join(code_blocks)\n","    return code_blocks"],"metadata":{"id":"SVvCaqPyu9Nx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["extract_python_code(df['cot_response_gemini'][7])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"id":"APUdMMf6vEcs","executionInfo":{"status":"ok","timestamp":1749057200917,"user_tz":420,"elapsed":15,"user":{"displayName":"Vishesh Agrawal","userId":"16926083185186864017"}},"outputId":"f3892bad-fff7-428c-a11c-4f965fc69666"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'xml\\n<dependency>\\n    <groupId>org.apache.hadoop</groupId>\\n    <artifactId>hadoop-client</artifactId>\\n    <version>3.3.1</version> <!-- Use your Hadoop version -->\\n    <scope>provided</scope>\\n</dependency>\\n<dependency>\\n    <groupId>org.apache.hadoop</groupId>\\n    <artifactId>hadoop-common</artifactId>\\n    <version>3.3.1</version> <!-- Use your Hadoop version -->\\n    <scope>provided</scope>\\n</dependency>\\njava\\npackage com.yourcompany.hadoop; // Use your own package name\\n\\nimport java.io.IOException;\\nimport java.util.StringTokenizer;\\n\\nimport org.apache.hadoop.io.IntWritable;\\nimport org.apache.hadoop.io.LongWritable;\\nimport org.apache.hadoop.io.Text;\\nimport org.apache.hadoop.mapreduce.Mapper;\\n\\npublic class WordCountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {\\n\\n    // Output value is always 1 for a single occurrence\\n    private final static IntWritable one = new IntWritable(1);\\n    // Reusable Text object for the word\\n    private Text word = new Text();\\n\\n    @Override\\n    public void map(LongWritable key, Text value, Context context)\\n            throws IOException, InterruptedException {\\n\\n        // 1. Get the line of text as a Java String\\n        String line = value.toString();\\n\\n        // 2. Tokenize the line into words\\n        // StringTokenizer is a simple way; for more robust parsing,\\n        // you might use split() with regex or other libraries.\\n        // Here, we split by whitespace characters.\\n        StringTokenizer tokenizer = new StringTokenizer(line);\\n\\n        // 3. Iterate through the tokens (words)\\n        while (tokenizer.hasMoreTokens()) {\\n            // 4. Get the next token\\n            String nextToken = tokenizer.nextToken();\\n\\n            // Optional: Clean up the word (e.g., remove punctuation, lowercase)\\n            // A simple approach is to convert to lowercase and remove non-alphanumeric\\n            String cleanWord = nextToken.toLowerCase().replaceAll(\"[^a-z0-9]\", \"\");\\n\\n            // 5. Set the Text object to the current word\\n            // Only process non-empty cleaned words\\n            if (!cleanWord.isEmpty()) {\\n                word.set(cleanWord);\\n\\n                // 6. Emit the word and a count of 1\\n                // The key is the word (Text), the value is 1 (IntWritable)\\n                context.write(word, one);\\n            }\\n        }\\n    }\\n}\\njava\\npackage com.yourcompany.hadoop; // Use your own package name\\n\\nimport java.io.IOException;\\n\\nimport org.apache.hadoop.io.IntWritable;\\nimport org.apache.hadoop.io.Text;\\nimport org.apache.hadoop.mapreduce.Reducer;\\n\\npublic class WordCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\\n\\n    // Reusable IntWritable object for the final count\\n    private IntWritable result = new IntWritable();\\n\\n    @Override\\n    public void reduce(Text key, Iterable<IntWritable> values, Context context)\\n            throws IOException, InterruptedException {\\n\\n        // 1. The key is the word itself\\n        // 2. The values is an iterable collection of all the \\'1\\'s emitted for this word\\n        int sum = 0;\\n\\n        // 3. Iterate through the list of values (all are IntWritable(1))\\n        for (IntWritable val : values) {\\n            // 4. Sum up the values\\n            sum += val.get();\\n        }\\n\\n        // 5. Set the final count in the result object\\n        result.set(sum);\\n\\n        // 6. Emit the word (key) and its total count (result)\\n        context.write(key, result);\\n    }\\n}\\njava\\npackage com.yourcompany.hadoop; // Use your own package name\\n\\nimport org.apache.hadoop.conf.Configuration;\\nimport org.apache.hadoop.conf.Configured;\\nimport org.apache.hadoop.fs.Path;\\nimport org.apache.hadoop.io.IntWritable;\\nimport org.apache.hadoop.io.Text;\\nimport org.apache.hadoop.mapreduce.Job;\\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\\nimport org.apache.hadoop.util.Tool;\\nimport org.apache.hadoop.util.ToolRunner;\\nimport org.apache.hadoop.fs.FileSystem;\\nimport java.net.URI;\\n\\npublic class WordCount extends Configured implements Tool {\\n\\n    @Override\\n    public int run(String[] args) throws Exception {\\n\\n        // 1. Get configuration object\\n        Configuration conf = this.getConf();\\n\\n        // 2. Create a Job object\\n        Job job = Job.getInstance(conf, \"Word Count\");\\n\\n        // 3. Specify the JAR file by class\\n        // This tells Hadoop where to find your Mapper and Reducer classes\\n        job.setJarByClass(WordCount.class);\\n\\n        // 4. Specify the Mapper class\\n        job.setMapperClass(WordCountMapper.class);\\n\\n        // 5. Specify the Combiner class (Optional, but good for performance)\\n        // The Combiner runs on the mapper side and performs local aggregation\\n        // It uses the same logic as the Reducer for Word Count\\n        job.setCombinerClass(WordCountReducer.class);\\n\\n        // 6. Specify the Reducer class\\n        job.setReducerClass(WordCountReducer.class);\\n\\n        // 7. Specify the output key and value types for the job (Reducer output)\\n        job.setOutputKeyClass(Text.class);\\n        job.setOutputValueClass(IntWritable.class);\\n\\n        // Optional: Specify the output key and value types for the Mapper (intermediate output)\\n        // This is often inferred, but can be explicit if desired or necessary\\n        // job.setMapOutputKeyClass(Text.class);\\n        // job.setMapOutputValueClass(IntWritable.class);\\n\\n\\n        // 8. Handle input and output paths\\n        if (args.length != 2) {\\n            System.err.println(\"Usage: WordCount <input path> <output path>\");\\n            System.exit(1); // Exit if arguments are incorrect\\n        }\\n\\n        Path inputPath = new Path(args[0]);\\n        Path outputPath = new Path(args[1]);\\n\\n        // Delete output directory if it already exists (useful for testing)\\n        FileSystem fs = FileSystem.get(URI.create(outputPath.toString()), conf);\\n        if (fs.exists(outputPath)) {\\n            fs.delete(outputPath, true); // delete recursively\\n        }\\n\\n        FileInputFormat.addInputPath(job, inputPath);\\n        FileOutputFormat.setOutputPath(job, outputPath);\\n\\n\\n        // 9. Submit the job and wait for it to complete\\n        // job.waitForCompletion(true) submits the job and returns true if successful, false otherwise\\n        return job.waitForCompletion(true) ? 0 : 1;\\n    }\\n\\n    // Main method to run the job using ToolRunner\\n    public static void main(String[] args) throws Exception {\\n        // ToolRunner efficiently runs Tool implementations, handling configuration\\n        int res = ToolRunner.run(new Configuration(), new WordCount(), args);\\n        System.exit(res);\\n    }\\n}\\nbash\\n    hdfs dfs -put your_text_file.txt /user/yourname/input/\\nbash\\n    hadoop jar your_wordcount.jar com.yourcompany.hadoop.WordCount /user/yourname/input /user/yourname/output_wordcount\\nbash\\n    hdfs dfs -ls /user/yourname/output_wordcount\\n    hdfs dfs -cat /user/yourname/output_wordcount/part-r-00000\\na\\t12345\\nthe\\t67890\\nword\\t567\\n...'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["extract_python_code(df['cot_response_gemini'][0])[5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"4z3IpUjq5O7B","executionInfo":{"status":"ok","timestamp":1749023066294,"user_tz":420,"elapsed":49,"user":{"displayName":"Vishesh Agrawal","userId":"16926083185186864017"}},"outputId":"5ff286a7-e425-4029-f518-99a37c563771"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'from sklearn.datasets import fetch_california_housing\\nfrom sklearn.model_selection import train_test_split\\nimport numpy as np\\nimport tensorflow as tf\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\n\\n# Load the dataset\\nhousing = fetch_california_housing()\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, test_size=0.2, random_state=42)\\n\\n# Normalize the features\\nmean = X_train.mean(axis=0)\\nstd = X_train.std(axis=0)\\nX_train = (X_train - mean) / std\\nX_test = (X_test - mean) / std\\n\\n# Define the linear regression model with one dense layer\\nmodel = keras.Sequential([\\n    layers.Dense(1, input_shape=(X_train.shape[1],))\\n])\\n\\n# Compile the model using Mean Squared Error loss and Adam optimizer\\nmodel.compile(optimizer=\\'adam\\',\\n              loss=\\'mse\\',\\n              metrics=[\\'mae\\'])\\n\\n# Train the model for a modest number of epochs\\nhistory = model.fit(X_train, y_train,\\n                    epochs=100,\\n                    batch_size=32,\\n                    validation_split=0.2,\\n                    verbose=1)\\n\\n# Evaluate the model on the test set\\ntest_loss, test_mae = model.evaluate(X_test, y_test)\\nprint(f\"Test MAE: {test_mae}\")'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import numpy as np\n","\n","def train_linear_regression_california_housing(epochs=50, batch_size=32):\n","        # ... rest of the code will go here\n","        pass # Placeholder\n","# 1. Load the dataset\n","        print(\"Loading California Housing dataset...\")\n","        ds = tfds.load('california_housing', split='train', as_supervised=False)\n","        print(\"Dataset loaded.\")\n","# 2. Prepare the data\n","        print(\"Preparing data (Extracting, Splitting, Scaling)...\")\n","        # Convert dataset to numpy arrays\n","        data = list(ds.as_numpy_iterator())\n","        features = np.array([item['features'] for item in data])\n","        labels = np.array([item['median_house_value'] for item in data])\n","\n","        # Split data into training and testing sets\n","        # We'll use 80% for training, 20% for testing\n","        X_train, X_test, y_train, y_test = train_test_split(\n","            features, labels, test_size=0.2, random_state=42\n","        )\n","\n","        # Scale the features\n","        # Scaling is important for many optimization algorithms\n","        scaler = StandardScaler()\n","        X_train_scaled = scaler.fit_transform(X_train)\n","        X_test_scaled = scaler.transform(X_test)\n","\n","        # The target variable (house value) is also numerical,\n","        # and while not strictly necessary for basic linear regression correctness,\n","        # scaling the target can sometimes help training stability or interpretation\n","        # depending on the loss function and metrics used.\n","        # However, for standard MSE, scaling features is usually sufficient\n","        # and scaling the target requires inverse scaling for predictions.\n","        # Let's keep it simple and only scale features for this example.\n","        print(f\"Data shapes: X_train={X_train_scaled.shape}, y_train={y_train.shape}, X_test={X_test_scaled.shape}, y_test={y_test.shape}\")\n","        print(\"Data preparation complete.\")\n","# 3. Define the model\n","        print(\"Defining the model...\")\n","        # A linear regression model is essentially a single neuron (dense layer with 1 unit)\n","        # with a linear activation function (which is the default).\n","        # The number of input features must match the input data shape.\n","        model = tf.keras.Sequential([\n","            tf.keras.layers.Dense(\n","                units=1,                  # One output unit for the single regression target\n","                input_shape=(X_train_scaled.shape[1],) # Input shape is the number of features\n","            )\n","        ])\n","        print(\"Model defined.\")\n","        model.summary()\n","# 4. Compile the model\n","        print(\"Compiling the model...\")\n","        # For linear regression:\n","        # Optimizer: Adam is a common and effective choice. SGD or others could also work.\n","        # Loss: Mean Squared Error (MSE) is the standard loss function for regression.\n","        # Metrics: MSE and Mean Absolute Error (MAE) are useful for evaluation.\n","        model.compile(\n","            optimizer='adam', # Or tf.keras.optimizers.Adam()\n","            loss='mse',       # Mean Squared Error\n","            metrics=['mae', 'mse'] # Mean Absolute Error and Mean Squared Error\n","        )\n","        print(\"Model compiled.\")\n","# 5. Train the model\n","        print(f\"Training the model for {epochs} epochs with batch size {batch_size}...\")\n","        history = model.fit(\n","            X_train_scaled, y_train,\n","            validation_data=(X_test_scaled, y_test), # Monitor performance on the test set during training\n","            epochs=epochs,\n","            batch_size=batch_size,\n","            verbose=1 # Show training progress\n","        )\n","        print(\"Model training complete.\")\n","# 6. Return the trained model and history\n","        return model, history\n","if __name__ == \"__main__\":\n","        # Set a random seed for reproducibility\n","        tf.random.set_seed(42)\n","        np.random.seed(42)\n","\n","        trained_model, training_history = train_linear_regression_california_housing(epochs=100, batch_size=64)\n","\n","        print(\"\\n--- Training Finished ---\")\n","        print(\"Trained Model Summary:\")\n","        trained_model.summary()\n","\n","        # Optional: Evaluate the model on the test set\n","        print(\"\\nEvaluating the model on the test set...\")\n","        # Need to reload/re-prepare test data for evaluation outside the function call\n","        # (or pass it back from the function, which is cleaner)\n","        # Let's modify the function to return the test data as well for evaluation\n","        # OR just use the history object which contains validation results.\n","        # History contains validation metrics per epoch.\n","        # To get final performance, we can evaluate the model directly.\n","        # Let's re-split/scale outside just for the final evaluation step demonstration.\n","\n","        # --- Re-prepare test data for final evaluation (demonstration) ---\n","        ds_eval = tfds.load('california_housing', split='train', as_supervised=False)\n","        data_eval = list(ds_eval.as_numpy_iterator())\n","        features_eval = np.array([item['features'] for item in data_eval])\n","        labels_eval = np.array([item['median_house_value'] for item in data_eval])\n","        # Use the same split and random_state as inside the function\n","        _, X_test_eval, _, y_test_eval = train_test_split(\n","            features_eval, labels_eval, test_size=0.2, random_state=42\n","        )\n","        # Use the *same* scaler fitted *only* on the training data (if scaler was returned)\n","        # Since the scaler wasn't returned, we need to refit it on training data again,\n","        # which is okay *only* for demonstrating post-training evaluation if we can't\n","        # reuse the scaler object directly. A better design might pass the scaler back.\n","        # For simplicity here, let's just fit a *new* scaler on the original *full* dataset\n","        # for evaluation features - this isn't ideal but works for demo if scaler isn't returned.\n","        # A *better* approach is to return the scaler from the function or evaluate within.\n","        # Let's stick to evaluating *within* the function before returning, or use history.\n","        # History has validation results, which is sufficient for this example.\n","        # Let's print the last validation metrics from history.\n","\n","        print(\"\\nValidation results from last epoch:\")\n","        # history.history is a dictionary containing lists of metric values per epoch\n","        last_epoch_metrics = {metric: values[-1] for metric, values in training_history.history.items()}\n","        print(last_epoch_metrics)\n","\n","        # Example prediction\n","        # Predict on the first few test samples\n","        print(\"\\nMaking predictions on the first 5 test samples:\")\n","        predictions = trained_model.predict(X_test_scaled[:5])\n","        print(\"Predicted values:\", predictions.flatten())\n","        print(\"Actual values:   \", y_test[:5])\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import numpy as np\n","\n","def train_linear_regression_california_housing(epochs=100, batch_size=64):\n","    \"\"\"\n","    Loads, prepares, and trains a simple linear regression model\n","    on the California Housing dataset using TensorFlow/Keras.\n","\n","    Args:\n","        epochs (int): Number of epochs to train for.\n","        batch_size (int): Batch size for training.\n","\n","    Returns:\n","        tuple: A tuple containing the trained Keras model and the training history object.\n","    \"\"\"\n","\n","    # --- Step-by-step Implementation ---\n","\n","    # 1. Load the dataset\n","    # Reasoning: We need the data to train and evaluate the model.\n","    # tfds provides easy access to standard datasets.\n","    print(\"Loading California Housing dataset...\")\n","    # Load the 'train' split. as_supervised=False gives a dict for each example.\n","    ds = tfds.load('california_housing', split='train', as_supervised=False)\n","    print(\"Dataset loaded.\")\n","\n","    # 2. Prepare the data (Extract, Convert, Split, Scale)\n","    # Reasoning:\n","    # - We need features (X) and targets (y) separately.\n","    # - Keras .fit() method typically expects numpy arrays or tf.data.Dataset.\n","    # - Splitting into train/test is crucial to evaluate model performance on unseen data.\n","    # - Scaling features helps the optimizer converge faster.\n","    print(\"Preparing data (Extracting, Splitting, Scaling)...\")\n","    # Convert dataset to numpy arrays for easier manipulation with sklearn\n","    data = list(ds.as_numpy_iterator())\n","    features = np.array([item['features'] for item in data])\n","    labels = np.array([item['median_house_value'] for item in data])\n","\n","    # Split data into training and testing sets (e.g., 80% train, 20% test)\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        features, labels, test_size=0.2, random_state=42 # random_state for reproducibility\n","    )\n","\n","    # Scale the features using StandardScaler\n","    # Fit on training data, transform both training and testing data.\n","    scaler = StandardScaler()\n","    X_train_scaled = scaler.fit_transform(X_train)\n","    X_test_scaled = scaler.transform(X_test)\n","\n","    # Optional: Inspect shapes\n","    print(f\"Data shapes: X_train={X_train_scaled.shape}, y_train={y_train.shape}, X_test={X_test_scaled.shape}, y_test={y_test.shape}\")\n","    print(\"Data preparation complete.\")\n","\n","    # 3. Define the model\n","    # Reasoning:\n","    # - A simple linear regression model predicts y as a linear combination of X: y = w*X + b\n","    # - In Keras, a Dense layer with units=1 and linear activation (the default)\n","    #   performs exactly this calculation.\n","    # - Sequential model is used for a simple stack of layers.\n","    print(\"Defining the model (Simple Linear Regression with one Dense layer)...\")\n","    model = tf.keras.Sequential([\n","        # The first layer needs input_shape to know the number of features\n","        tf.keras.layers.Dense(\n","            units=1,                  # One output unit for the single regression target\n","            input_shape=(X_train_scaled.shape[1],) # Input shape is the number of features\n","        )\n","    ])\n","    print(\"Model defined.\")\n","    model.summary() # Print model architecture\n","\n","    # 4. Compile the model\n","    # Reasoning:\n","    # - Compilation configures the model for training.\n","    # - Optimizer: Algorithm to minimize the loss (e.g., Adam).\n","    # - Loss: Function to measure how far predictions are from actual values (MSE for regression).\n","    # - Metrics: Additional metrics to evaluate during training (MAE is often more interpretable than MSE).\n","    print(\"Compiling the model...\")\n","    model.compile(\n","        optimizer='adam',       # Adam optimizer is a good default\n","        loss='mse',             # Mean Squared Error, standard for regression\n","        metrics=['mae', 'mse']  # Mean Absolute Error and MSE to monitor\n","    )\n","    print(\"Model compiled.\")\n","\n","    # 5. Train the model\n","    # Reasoning:\n","    # - The .fit() method trains the model using the specified data and parameters.\n","    # - X_train_scaled, y_train: The training data.\n","    # - validation_data: Data to evaluate model performance *during* training (after each epoch).\n","    # - epochs: Number of passes over the entire training dataset.\n","    # - batch_size: Number of samples processed before a weight update.\n","    print(f\"Training the model for {epochs} epochs with batch size {batch_size}...\")\n","    history = model.fit(\n","        X_train_scaled, y_train,\n","        validation_data=(X_test_scaled, y_test), # Evaluate on test set after each epoch\n","        epochs=epochs,\n","        batch_size=batch_size,\n","        verbose=1 # Show training progress per epoch\n","    )\n","    print(\"Model training complete.\")\n","\n","    # 6. Return the trained model and history\n","    # Reasoning: The caller might want to use the model for predictions or analyze training progress.\n","    return model, history\n","\n","# --- Example Usage ---\n","if __name__ == \"__main__\":\n","    # Set seeds for reproducibility\n","    tf.random.set_seed(42)\n","    np.random.seed(42)\n","\n","    # Train the model by calling the function\n","    trained_model, training_history = train_linear_regression_california_housing(epochs=100, batch_size=64)\n","\n","    print(\"\\n--- Training Summary ---\")\n","    print(\"Trained Model Summary:\")\n","    trained_model.summary()\n","\n","    # Print final validation metrics from the training history\n","    print(\"\\nValidation results from the last epoch:\")\n","    # history.history is a dictionary containing lists of metric values per epoch\n","    last_epoch_metrics = {metric: values[-1] for metric, values in training_history.history.items()}\n","    print(last_epoch_metrics)\n","\n","    # --- Demonstrate Prediction ---\n","    # To make predictions, we need the test data and the scaler used during training.\n","    # A robust function would return the scaler, but for this simple example,\n","    # we'll just show the process assuming we have access to X_test_scaled.\n","    # In a real application, save the scaler or return it from the function.\n","\n","    # Let's reload/resplit the data just to get X_test and y_test again outside the function scope\n","    # (This is not ideal for general use, but demonstrates prediction flow)\n","    ds_eval = tfds.load('california_housing', split='train', as_supervised=False)\n","    data_eval = list(ds_eval.as_numpy_iterator())\n","    features_eval = np.array([item['features'] for item in data_eval])\n","    labels_eval = np.array([item['median_house_value'] for item in data_eval])\n","    _, X_test_raw, _, y_test_raw = train_test_split(\n","        features_eval, labels_eval, test_size=0.2, random_state=42 # Same split\n","    )\n","    # IMPORTANT: You MUST use the SAME scaler fitted on the training data!\n","    # Since we didn't return the scaler, we'd ideally reload it if saved, or refit on original training data here.\n","    # For demonstration, let's just create and fit a new scaler on the *full* data for prediction features.\n","    # ***WARNING: Fitting scaler on full data for evaluation/prediction is technically data leakage.\n","    # A proper flow returns the fitted scaler or saves/loads it.***\n","    # Re-creating the scaler fitted ONLY on original training data:\n","    temp_scaler = StandardScaler()\n","    temp_scaler.fit(train_test_split(features_eval, labels_eval, test_size=0.2, random_state=42)[0]) # Fit only on training part\n","\n","    X_test_scaled_for_pred = temp_scaler.transform(X_test_raw)\n","\n","\n","    print(\"\\nMaking predictions on the first 5 test samples:\")\n","    # Predict expects scaled input features\n","    predictions = trained_model.predict(X_test_scaled_for_pred[:5])\n","    print(\"Predicted values:\", predictions.flatten())\n","    print(\"Actual values:   \", y_test_raw[:5])\n","    # Note: Predictions are in the original scale of y because y was not scaled."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"IzSfUMvy3-tZ","executionInfo":{"status":"error","timestamp":1749056297477,"user_tz":420,"elapsed":7480,"user":{"displayName":"Vishesh Agrawal","userId":"16926083185186864017"}},"outputId":"6db88738-2f9b-4d26-c2b2-5991d1f633fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading California Housing dataset...\n"]},{"output_type":"error","ename":"DatasetNotFoundError","evalue":"Dataset california_housing not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- ai2dcaption\n\t- aloha_mobile\n\t- amazon_us_reviews\n\t- anli\n\t- answer_equivalence\n\t- arc\n\t- asimov_dilemmas_auto_val\n\t- asimov_dilemmas_scifi_train\n\t- asimov_dilemmas_scifi_val\n\t- asimov_injury_val\n\t- asimov_multimodal_auto_val\n\t- asimov_multimodal_manual_val\n\t- asqa\n\t- asset\n\t- assin2\n\t- asu_table_top_converted_externally_to_rlds\n\t- austin_buds_dataset_converted_externally_to_rlds\n\t- austin_sailor_dataset_converted_externally_to_rlds\n\t- austin_sirius_dataset_converted_externally_to_rlds\n\t- bair_robot_pushing_small\n\t- bc_z\n\t- bccd\n\t- beans\n\t- bee_dataset\n\t- beir\n\t- berkeley_autolab_ur5\n\t- berkeley_cable_routing\n\t- berkeley_fanuc_manipulation\n\t- berkeley_gnm_cory_hall\n\t- berkeley_gnm_recon\n\t- berkeley_gnm_sac_son\n\t- berkeley_mvp_converted_externally_to_rlds\n\t- berkeley_rpt_converted_externally_to_rlds\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- ble_wind_field\n\t- blimp\n\t- booksum\n\t- bool_q\n\t- bot_adversarial_dialogue\n\t- bridge\n\t- bridge_data_msr\n\t- bucc\n\t- c4\n\t- c4_wsrs\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cardiotox\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar100_n\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- cifar10_h\n\t- cifar10_n\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cmu_franka_exploration_dataset_converted_externally_to_rlds\n\t- cmu_play_fusion\n\t- cmu_stretch\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- columbia_cairlab_pusht_real\n\t- common_voice\n\t- conll2002\n\t- conll2003\n\t- conq_hose_manipulation\n\t- controlled_noisy_web_labels\n\t- coqa\n\t- corr2cause\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- criteo\n\t- cs_restaurants\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_antmaze\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- databricks_dolly\n\t- davis\n\t- deep1b\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- diamonds\n\t- dices\n\t- div2k\n\t- dlr_edan_shared_control_converted_externally_to_rlds\n\t- dlr_sara_grid_clamp_converted_externally_to_rlds\n\t- dlr_sara_pour_converted_externally_to_rlds\n\t- dmlab\n\t- dobbe\n\t- doc_nli\n\t- dolma\n\t- dolphin_number_word\n\t- domainnet\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eth_agent_affordances\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- fmb\n\t- food101\n\t- forest_fires\n\t- fractal20220817_data\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glove100_angular\n\t- glue\n\t- goemotions\n\t- gov_report\n\t- gpt3\n\t- gref\n\t- groove\n\t- grounded_scan\n\t- gsm8k\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- hillstrom\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- i_naturalist2018\n\t- i_naturalist2021\n\t- iamlab_cmu_pickup_insert_converted_externally_to_rlds\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_fewshot\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_lt\n\t- imagenet_pi\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_sketch\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- imperialcollege_sawyer_wrist_cam\n\t- io_ai_tech\n\t- irc_disentanglement\n\t- iris\n\t- istella\n\t- jaco_play\n\t- kaist_nonprehensile_converted_externally_to_rlds\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- kuka\n\t- laion400m\n\t- lambada\n\t- lbpp\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- locomotion\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- maniskill_dataset_converted_externally_to_rlds\n\t- math_dataset\n\t- math_qa\n\t- mctaco\n\t- media_sum\n\t- mimic_play\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- mrqa\n\t- mslr_web\n\t- mt_opt\n\t- mtnt\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_instructions\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- nyu_door_opening_surprising_effectiveness\n\t- nyu_franka_play_dataset_converted_externally_to_rlds\n\t- nyu_rot_dataset_converted_externally_to_rlds\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- pass\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- penguins\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- placesfull\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- plex_robosuite\n\t- pneumonia_mnist\n\t- protein_net\n\t- q_re_cc\n\t- qa4mre\n\t- qasc\n\t- qm9\n\t- quac\n\t- quality\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- real_toxicity_prompts\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_atari_checkpoints\n\t- rlu_atari_checkpoints_ordered\n\t- rlu_control_suite\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- rlu_locomotion\n\t- rlu_rwrl\n\t- robo_set\n\t- robomimic_mg\n\t- robomimic_mh\n\t- robomimic_ph\n\t- robonet\n\t- robosuite_panda_pick_place_can\n\t- roboturk\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- sci_tail\n\t- scicite\n\t- scientific_papers\n\t- scrolls\n\t- segment_anything\n\t- sentiment140\n\t- shapes3d\n\t- sift1m\n\t- simpte\n\t- siscore\n\t- smallnorb\n\t- smart_buildings\n\t- smartwatch_gestures\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoc_robot\n\t- spoken_digit\n\t- squad\n\t- squad_question_generation\n\t- stanford_dogs\n\t- stanford_hydra_dataset_converted_externally_to_rlds\n\t- stanford_kuka_multimodal_dataset_converted_externally_to_rlds\n\t- stanford_mask_vit_converted_externally_to_rlds\n\t- stanford_online_products\n\t- stanford_robocook_converted_externally_to_rlds\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- taco_play\n\t- tao\n\t- tatoeba\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tidybot\n\t- tiny_shakespeare\n\t- titanic\n\t- tokyo_u_lsmo_converted_externally_to_rlds\n\t- toto\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- ucsd_kitchen_dataset_converted_externally_to_rlds\n\t- ucsd_pick_and_place_dataset_converted_externally_to_rlds\n\t- uiuc_d3field\n\t- unified_qa\n\t- universal_dependencies\n\t- unnatural_instructions\n\t- usc_cloth_sim_converted_externally_to_rlds\n\t- user_libri_audio\n\t- user_libri_text\n\t- utaustin_mutex\n\t- utokyo_pr2_opening_fridge_converted_externally_to_rlds\n\t- utokyo_pr2_tabletop_manipulation_converted_externally_to_rlds\n\t- utokyo_saytap_converted_externally_to_rlds\n\t- utokyo_xarm_bimanual_converted_externally_to_rlds\n\t- utokyo_xarm_pick_and_place_converted_externally_to_rlds\n\t- vctk\n\t- vima_converted_externally_to_rlds\n\t- viola\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- wake_vision\n\t- waymo_open_dataset\n\t- web_graph\n\t- web_nlg\n\t- web_questions\n\t- webvid\n\t- wider_face\n\t- wiki40b\n\t- wiki_auto\n\t- wiki_bio\n\t- wiki_dialog\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wit\n\t- wit_kaggle\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_pos\n\t- xtreme_s\n\t- xtreme_xnli\n\t- yahoo_ltrc\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nThe builder directory /root/tensorflow_datasets/california_housing doesn't contain any versions.\nNo builder could be found in the directory: /root/tensorflow_datasets for the builder: california_housing.\nNo registered data_dirs were found in:\n\t- /root/tensorflow_datasets\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-ebf893714dbd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_linear_regression_california_housing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Training Finished ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-ebf893714dbd>\u001b[0m in \u001b[0;36mtrain_linear_regression_california_housing\u001b[0;34m(epochs, batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 1. Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading California Housing dataset...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'california_housing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_supervised\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 2. Prepare the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_datasets/core/logging/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs, file_format)\u001b[0m\n\u001b[1;32m    658\u001b[0m       \u001b[0mSplit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mspecific\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mavailable\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mds_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m   \"\"\"  # fmt: skip\n\u001b[0;32m--> 660\u001b[0;31m   dbuilder = _fetch_builder(\n\u001b[0m\u001b[1;32m    661\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36m_fetch_builder\u001b[0;34m(name, data_dir, builder_kwargs, try_gcs, file_format)\u001b[0m\n\u001b[1;32m    493\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0mbuilder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_format'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_gcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtry_gcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbuilder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_datasets/core/logging/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mbuilder\u001b[0;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m   \u001b[0;31m# If neither the code nor the files are found, raise DatasetNotFoundError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mnot_found_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mbuilder\u001b[0;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;31m# First check whether we can find the corresponding dataset builder code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mregistered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Class not found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mbuilder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m       \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimported_builder_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m       \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetBuilder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_datasets/core/registered.py\u001b[0m in \u001b[0;36mimported_builder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Dataset {name} is an abstract class.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mDatasetNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Dataset {name} not found.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mDatasetNotFoundError\u001b[0m: Dataset california_housing not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- ai2dcaption\n\t- aloha_mobile\n\t- amazon_us_reviews\n\t- anli\n\t- answer_equivalence\n\t- arc\n\t- asimov_dilemmas_auto_val\n\t- asimov_dilemmas_scifi_train\n\t- asimov_dilemmas_scifi_val\n\t- asimov_injury_val\n\t- asimov_multimodal_auto_val\n\t- asimov_multimodal_manual_val\n\t- asqa\n\t- asset\n\t- assin2\n\t- asu_table_top_converted_externally_to_rlds\n\t- austin_buds_dataset_converted_externally_to_rlds\n\t- austin_sailor_dataset_converted_externally_to_rlds\n\t- austin_sirius_dataset_converted_externally_to_rlds\n\t- bair_robot_pushing_small\n\t- bc_z\n\t- bccd\n\t- beans\n\t- bee_dataset\n\t- beir\n\t- berkeley_autolab_ur5\n\t- berkeley_cable_routing\n\t- berkeley_fanuc_manipulation\n\t- berkeley_gnm_cory_hall\n\t- berkeley_gnm_recon\n\t- berkeley_gnm_sac_son\n\t- berkeley_mvp_converted_externally_to_rlds\n\t- berkeley_rpt_converted_externally_to_rlds\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- ble_wind_field\n\t- blimp\n\t- booksum\n\t- bool_q\n\t- bot_adversarial_dialogue\n\t- bridge\n\t- bridge_data_msr\n\t- bucc\n\t- c4\n\t- c4_wsrs\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cardiotox\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar100_n\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- cifar10_h\n\t- cifar10_n\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cmu_franka_exploration_dataset_converted_externally_to_rlds\n\t- cmu_play_fusion\n\t- cmu_stretch\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- columbia_cairlab_pusht_real\n\t- common_voice\n\t- conll2002\n\t- conll2003\n\t- conq_hose_manipulation\n\t- controlled_noisy_web_labels\n\t- coqa\n\t- corr2cause\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- criteo\n\t- cs_restaurants\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_antmaze\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- databricks_dolly\n\t- davis\n\t- deep1b\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- diamonds\n\t- dices\n\t- div2k\n\t- dlr_edan_shared_control_converted_externally_to_rlds\n\t- dlr_sara_grid_clamp_converted_externally_to_rlds\n\t- dlr_sara_pour_converted_externally_to_rlds\n\t- dmlab\n\t- dobbe\n\t- doc_nli\n\t- dolma\n\t- dolphin_number_word\n\t- domainnet\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eth_agent_affordances\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- fmb\n\t- food101\n\t- forest_fires\n\t- fractal20220817_data\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glove100_angular\n\t- glue\n\t- goemotions\n\t- gov_report\n\t- gpt3\n\t- gref\n\t- groove\n\t- grounded_scan\n\t- gsm8k\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- hillstrom\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- i_naturalist2018\n\t- i_naturalist2021\n\t- iamlab_cmu_pickup_insert_converted_externally_to_rlds\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_fewshot\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_lt\n\t- imagenet_pi\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_sketch\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- imperialcollege_sawyer_wrist_cam\n\t- io_ai_tech\n\t- irc_disentanglement\n\t- iris\n\t- istella\n\t- jaco_play\n\t- kaist_nonprehensile_converted_externally_to_rlds\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- kuka\n\t- laion400m\n\t- lambada\n\t- lbpp\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- locomotion\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- maniskill_dataset_converted_externally_to_rlds\n\t- math_dataset\n\t- math_qa\n\t- mctaco\n\t- media_sum\n\t- mimic_play\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- mrqa\n\t- mslr_web\n\t- mt_opt\n\t- mtnt\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_instructions\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- nyu_door_opening_surprising_effectiveness\n\t- nyu_franka_play_dataset_converted_externally_to_rlds\n\t- nyu_rot_dataset_converted_externally_to_rlds\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- pass\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- penguins\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- placesfull\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- plex_robosuite\n\t- pneumonia_mnist\n\t- protein_net\n\t- q_re_cc\n\t- qa4mre\n\t- qasc\n\t- qm9\n\t- quac\n\t- quality\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- real_toxicity_prompts\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_atari_checkpoints\n\t- rlu_atari_checkpoints_ordered\n\t- rlu_control_suite\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- rlu_locomotion\n\t- rlu_rwrl\n\t- robo_set\n\t- robomimic_mg\n\t- robomimic_mh\n\t- robomimic_ph\n\t- robonet\n\t- robosuite_panda_pick_place_can\n\t- roboturk\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- sci_tail\n\t- scicite\n\t- scientific_papers\n\t- scrolls\n\t- segment_anything\n\t- sentiment140\n\t- shapes3d\n\t- sift1m\n\t- simpte\n\t- siscore\n\t- smallnorb\n\t- smart_buildings\n\t- smartwatch_gestures\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoc_robot\n\t- spoken_digit\n\t- squad\n\t- squad_question_generation\n\t- stanford_dogs\n\t- stanford_hydra_dataset_converted_externally_to_rlds\n\t- stanford_kuka_multimodal_dataset_converted_externally_to_rlds\n\t- stanford_mask_vit_converted_externally_to_rlds\n\t- stanford_online_products\n\t- stanford_robocook_converted_externally_to_rlds\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- taco_play\n\t- tao\n\t- tatoeba\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tidybot\n\t- tiny_shakespeare\n\t- titanic\n\t- tokyo_u_lsmo_converted_externally_to_rlds\n\t- toto\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- ucsd_kitchen_dataset_converted_externally_to_rlds\n\t- ucsd_pick_and_place_dataset_converted_externally_to_rlds\n\t- uiuc_d3field\n\t- unified_qa\n\t- universal_dependencies\n\t- unnatural_instructions\n\t- usc_cloth_sim_converted_externally_to_rlds\n\t- user_libri_audio\n\t- user_libri_text\n\t- utaustin_mutex\n\t- utokyo_pr2_opening_fridge_converted_externally_to_rlds\n\t- utokyo_pr2_tabletop_manipulation_converted_externally_to_rlds\n\t- utokyo_saytap_converted_externally_to_rlds\n\t- utokyo_xarm_bimanual_converted_externally_to_rlds\n\t- utokyo_xarm_pick_and_place_converted_externally_to_rlds\n\t- vctk\n\t- vima_converted_externally_to_rlds\n\t- viola\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- wake_vision\n\t- waymo_open_dataset\n\t- web_graph\n\t- web_nlg\n\t- web_questions\n\t- webvid\n\t- wider_face\n\t- wiki40b\n\t- wiki_auto\n\t- wiki_bio\n\t- wiki_dialog\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wit\n\t- wit_kaggle\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_pos\n\t- xtreme_s\n\t- xtreme_xnli\n\t- yahoo_ltrc\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nThe builder directory /root/tensorflow_datasets/california_housing doesn't contain any versions.\nNo builder could be found in the directory: /root/tensorflow_datasets for the builder: california_housing.\nNo registered data_dirs were found in:\n\t- /root/tensorflow_datasets\n"]}]},{"cell_type":"code","source":["# 1. Import necessary libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os # To create directory for saving model\n","from tqdm import tqdm # For progress bar\n","\n","# 2. Define Hyperparameters\n","num_epochs = 1         # Number of training epochs\n","batch_size = 100        # Number of images per batch\n","learning_rate = 0.001   # Learning rate for the optimizer\n","data_path = './data'    # Directory to download the dataset\n","model_path = './models' # Directory to save the trained model\n","model_save_name = 'cifar10_cnn.pth' # Name for the saved model file\n","\n","# 3. Set up Device\n","# This checks if a CUDA-enabled GPU is available. If yes, it uses the GPU; otherwise, it uses the CPU.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')\n","\n","# 4. Load and Preprocess Data\n","\n","# Data augmentation and normalization for training\n","# We define a sequence of transformations to apply to the images.\n","# transforms.ToTensor(): Converts a PIL Image or NumPy array (H x W x C)\n","#                        to a PyTorch Tensor (C x H x W) in the range [0.0, 1.0].\n","# transforms.Normalize(mean, std): Normalizes a tensor image with mean and standard deviation.\n","# We use the standard mean and std for CIFAR-10 across its channels.\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4), # Pad and randomly crop to 32x32\n","    transforms.RandomHorizontalFlip(), # Randomly flip the image horizontally\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","# Normalization for testing (no augmentation)\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","# Load the CIFAR-10 training dataset\n","# root: directory where the dataset will be saved or loaded from.\n","# train=True: specifies the training set.\n","# download=True: downloads the dataset if it's not found in the root directory.\n","# transform: applies the specified transformations.\n","trainset = torchvision.datasets.CIFAR10(root=data_path, train=True,\n","                                        download=True, transform=transform_train)\n","\n","# Create a DataLoader for the training set\n","# DataLoader is an iterator that provides batches of data.\n","# dataset: the dataset to load data from.\n","# batch_size: how many samples per batch to load.\n","# shuffle=True: shuffles the data at the beginning of each epoch (important for training).\n","# num_workers: how many subprocesses to use for data loading (higher values can speed up loading).\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)\n","\n","# Load the CIFAR-10 test dataset\n","testset = torchvision.datasets.CIFAR10(root=data_path, train=False,\n","                                       download=True, transform=transform_test)\n","\n","# Create a DataLoader for the test set\n","# shuffle=False: shuffling is not necessary for testing/evaluation.\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=2)\n","\n","# Define the 10 class names for CIFAR-10\n","classes = ('plane', 'car', 'bird', 'cat', 'deer',\n","           'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","print(f'Training data size: {len(trainset)}')\n","print(f'Test data size: {len(testset)}')\n","\n","# Optional: Show a few images (for debugging/visualization)\n","# def imshow(img):\n","#     # Unnormalize the image\n","#     img = img / 2 + 0.5     # Assuming the normalization was done around mean 0.5, std 0.5 for simplicity here,\n","#                           # though we used CIFAR10 specific mean/std above.\n","#                           # For correct visualization with CIFAR10 norm:\n","#     mean = torch.tensor((0.4914, 0.4822, 0.4465)).reshape(3, 1, 1)\n","#     std = torch.tensor((0.2023, 0.1994, 0.2010)).reshape(3, 1, 1)\n","#     img = img * std + mean\n","#\n","#     npimg = img.numpy()\n","#     plt.imshow(np.transpose(npimg, (1, 2, 0))) # Convert from Tensor (C, H, W) to NumPy array (H, W, C)\n","#     plt.show()\n","\n","# Get some random training images\n","# dataiter = iter(trainloader)\n","# images, labels = next(dataiter)\n","# print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n","# imshow(torchvision.utils.make_grid(images))\n","\n","\n","# 5. Define the CNN Model\n","# We create a class MyCNN that inherits from nn.Module.\n","# This is the standard way to define models in PyTorch.\n","class MyCNN(nn.Module):\n","    def __init__(self):\n","        # Call the constructor of the parent class (nn.Module)\n","        super(MyCNN, self).__init__()\n","\n","        # Define the layers of the network\n","\n","        # Convolutional Layer 1\n","        # nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","        # Input image size: 3x32x32 (3 channels, 32x32 pixels)\n","        # Output size after conv1: (32 + 2*1 - 3)/1 + 1 = 32 -> 32x32x32\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n","        # Batch Normalization 1: Applied after convolution, before activation, helps stabilize training.\n","        self.bn1 = nn.BatchNorm2d(32)\n","        # ReLU Activation: Applies the rectified linear unit function element-wise (max(0, x)).\n","        self.relu = nn.ReLU()\n","        # Max Pooling Layer 1: Reduces spatial dimensions.\n","        # nn.MaxPool2d(kernel_size, stride)\n","        # Output size after pool1: 32/2 x 32/2 = 16x16 -> 32x16x16\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Convolutional Layer 2\n","        # Input size: 32x16x16\n","        # Output size after conv2: (64 + 2*1 - 3)/1 + 1 = 16 -> 64x16x16\n","        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        # Output size after pool: 16/2 x 16/2 = 8x8 -> 64x8x8\n","\n","        # Convolutional Layer 3\n","        # Input size: 64x8x8\n","        # Output size after conv3: (128 + 2*1 - 3)/1 + 1 = 8 -> 128x8x8\n","        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        # Output size after pool: 8/2 x 8/2 = 4x4 -> 128x4x4\n","\n","        # Fully Connected Layers (also called Dense layers)\n","        # Input size for the first fully connected layer: Flat output from the last pooling layer\n","        # The output tensor from the last pooling layer is 128 channels of size 4x4.\n","        # Flattened size: 128 * 4 * 4 = 2048\n","        self.fc1 = nn.Linear(in_features=128 * 4 * 4, out_features=512)\n","        # Dropout Layer: Randomly sets a fraction of input units to 0 at each update during training. Helps prevent overfitting.\n","        self.dropout = nn.Dropout(p=0.5) # 50% probability of dropping an activation\n","        self.fc2 = nn.Linear(in_features=512, out_features=10) # Output layer: 10 features for 10 classes\n","\n","    # Define the forward pass (how data flows through the network)\n","    def forward(self, x):\n","        # Apply Conv -> BN -> ReLU -> Pool\n","        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n","        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n","        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n","\n","        # Flatten the output from the convolutional layers for the fully connected layers\n","        # x.size(0) is the batch size\n","        x = x.view(-1, 128 * 4 * 4) # -1 lets PyTorch figure out the batch size\n","\n","        # Apply Fully Connected layers\n","        x = self.relu(self.fc1(x))\n","        x = self.dropout(x) # Apply dropout after the first FC layer\n","        x = self.fc2(x)\n","\n","        return x # The output layer doesn't typically have an activation for CrossEntropyLoss,\n","                 # as it includes LogSoftmax internally.\n","\n","# 6. Instantiate Model, Loss Function, and Optimizer\n","model = MyCNN().to(device) # Create an instance of the model and move it to the selected device (GPU/CPU)\n","\n","# Loss function: Cross-Entropy Loss is suitable for multi-class classification.\n","criterion = nn.CrossEntropyLoss()\n","\n","# Optimizer: Adam is an adaptive learning rate optimization algorithm.\n","# model.parameters(): Provides all the learnable parameters of the model.\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Optional: Learning Rate Scheduler\n","# Decays the learning rate by a factor of 0.1 every 30 epochs\n","# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n","\n","# 7. Define Training Loop\n","# This function trains the model for one epoch\n","def train_epoch(model, train_loader, criterion, optimizer, device):\n","    model.train() # Set the model to training mode (enables dropout and batch normalization updates)\n","    running_loss = 0.0\n","    # Wrap the DataLoader with tqdm for a progress bar\n","    for i, data in enumerate(tqdm(train_loader, desc='Training', leave=False)):\n","        # Get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        # Move data to the appropriate device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # Zero the parameter gradients\n","        # It's important to zero the gradients before each backpropagation step,\n","        # as gradients are accumulated by default in PyTorch.\n","        optimizer.zero_grad()\n","\n","        # Forward pass: Compute the predicted outputs by passing inputs through the model\n","        outputs = model(inputs)\n","        # Compute the loss: Compare the predicted outputs with the true labels\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass: Compute gradients of the loss with respect to model parameters\n","        loss.backward()\n","        # Optimizer step: Update the model parameters using the computed gradients\n","        optimizer.step()\n","\n","        # Print statistics\n","        running_loss += loss.item() # .item() gets the scalar value from a tensor\n","    return running_loss / len(train_loader) # Return average loss for the epoch\n","\n","# 8. Define Evaluation Function\n","# This function evaluates the model on a given data loader (usually the test set)\n","def evaluate(model, data_loader, device):\n","    model.eval() # Set the model to evaluation mode (disables dropout and batch normalization tracking/updates)\n","    correct = 0\n","    total = 0\n","    # Disable gradient calculations during evaluation\n","    # This reduces memory consumption and speeds up computation as we don't need gradients for evaluation.\n","    with torch.no_grad():\n","        for data in tqdm(data_loader, desc='Evaluating', leave=False):\n","            images, labels = data\n","            # Move data to the appropriate device\n","            images, labels = images.to(device), labels.to(device)\n","            # Forward pass: Get predictions\n","            outputs = model(images)\n","            # Get the predicted class with the highest score\n","            # torch.max returns (values, indices). We need the indices (the class predictions).\n","            _, predicted = torch.max(outputs.data, 1)\n","            # Update total number of images and correct predictions\n","            total += labels.size(0) # Add batch size to total count\n","            correct += (predicted == labels).sum().item() # Count correct predictions in the batch\n","\n","    accuracy = 100 * correct / total\n","    return accuracy\n","\n","# 9. Run Training and Evaluation\n","train_losses = []\n","test_accuracies = []\n","\n","# Ensure model save directory exists\n","os.makedirs(model_path, exist_ok=True)\n","best_accuracy = 0.0 # To keep track of the best test accuracy achieved\n","\n","print(\"Starting Training...\")\n","for epoch in range(num_epochs):\n","    print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n","\n","    # Train for one epoch\n","    avg_train_loss = train_epoch(model, trainloader, criterion, optimizer, device)\n","    train_losses.append(avg_train_loss)\n","\n","    # Evaluate on the test set\n","    test_accuracy = evaluate(model, testloader, device)\n","    test_accuracies.append(test_accuracy)\n","\n","    print(f'Epoch {epoch + 1} finished.')\n","    print(f'Train Loss: {avg_train_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n","\n","    # Optional: Save the model checkpoint if it's the best performing so far\n","    if test_accuracy > best_accuracy:\n","        best_accuracy = test_accuracy\n","        save_path = os.path.join(model_path, model_save_name)\n","        # Save the model's state dictionary\n","        # Saving state_dict is recommended as it's more flexible for loading later\n","        torch.save(model.state_dict(), save_path)\n","        print(f'Model saved to {save_path} with improved accuracy: {best_accuracy:.2f}%')\n","\n","    # Optional: Step the learning rate scheduler\n","    # if 'scheduler' in locals():\n","    #     scheduler.step()\n","\n","print('Finished Training')\n","\n","# 10. Plot Results (Optional)\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(range(1, num_epochs + 1), train_losses)\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Loss')\n","plt.title('Training Loss per Epoch')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(range(1, num_epochs + 1), test_accuracies, color='orange')\n","plt.xlabel('Epoch')\n","plt.ylabel('Test Accuracy (%)')\n","plt.title('Test Accuracy per Epoch')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Optional: Load the best model and evaluate one last time\n","try:\n","    loaded_model = MyCNN().to(device)\n","    load_path = os.path.join(model_path, model_save_name)\n","    loaded_model.load_state_dict(torch.load(load_path))\n","    print(f'\\nLoaded model from {load_path}')\n","    final_test_accuracy = evaluate(loaded_model, testloader, device)\n","    print(f'Final Test Accuracy (loaded model): {final_test_accuracy:.2f}%')\n","except FileNotFoundError:\n","    print(f\"\\nModel file not found at {load_path}. Skipping final evaluation of loaded model.\")\n","except Exception as e:\n","    print(f\"\\nError loading or evaluating model: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":750},"id":"ayl_V6If4a6b","executionInfo":{"status":"ok","timestamp":1749056589730,"user_tz":420,"elapsed":217121,"user":{"displayName":"Vishesh Agrawal","userId":"16926083185186864017"}},"outputId":"f1954bcb-f706-46cb-f386-ccd5e5332cd2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:01<00:00, 103MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training data size: 50000\n","Test data size: 10000\n","Starting Training...\n","\n","Epoch 1/1\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 1 finished.\n","Train Loss: 1.5651, Test Accuracy: 58.84%\n","Model saved to ./models/cifar10_cnn.pth with improved accuracy: 58.84%\n","Finished Training\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Loaded model from ./models/cifar10_cnn.pth\n"]},{"output_type":"stream","name":"stderr","text":["                                                             "]},{"output_type":"stream","name":"stdout","text":["Final Test Accuracy (loaded model): 58.84%\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression # We'll use Logistic Regression as a simple classifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score # To explicitly show the score calculation\n","\n","# --- Step 1: Generate a Random N-Class Classification Problem ---\n","print(\"Step 1: Generating synthetic dataset...\")\n","\n","# Parameters for the dataset\n","n_samples = 1000      # Total number of samples\n","n_features = 25       # Total number of features\n","n_informative = 20    # Number of informative features\n","n_redundant = 3       # Number of redundant features\n","n_classes = 5         # Number of classes\n","random_state = 42     # For reproducibility\n","\n","X, y = make_classification(\n","    n_samples=n_samples,\n","    n_features=n_features,\n","    n_informative=n_informative,\n","    n_redundant=n_redundant,\n","    n_repeated=0,\n","    n_classes=n_classes,\n","    n_clusters_per_class=1,\n","    weights=None,       # Uniform weights for classes\n","    flip_y=0.01,        # Some noise in labels\n","    class_sep=1.0,      # How distinct the classes are\n","    hypercube=True,\n","    shift=0.0,\n","    scale=1.0,\n","    random_state=random_state # Ensure the same dataset is generated each time\n",")\n","\n","print(f\"Dataset generated: X shape {X.shape}, y shape {y.shape}\")\n","print(f\"Number of unique classes: {len(np.unique(y))}\") # Verify the number of classes\n","\n","# --- Step 2: Split Data into Training and Testing Sets ---\n","print(\"\\nStep 2: Splitting data into training and testing sets...\")\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.25, random_state=random_state, stratify=y # stratify ensures class distribution is similar\n",")\n","\n","print(f\"Training data shape: {X_train.shape}\")\n","print(f\"Testing data shape: {X_test.shape}\")\n","\n","# --- Step 3: Define Preprocessing and Model Steps ---\n","print(\"\\nStep 3: Defining preprocessing (scaling) and model steps...\")\n","\n","# Preprocessing: StandardScaler\n","# This transformer calculates the mean and standard deviation on the data it is fitted on\n","# and then transforms the data by subtracting the mean and dividing by the standard deviation.\n","# This is exactly what we need to calculate mean/std on train and apply to both.\n","scaler = StandardScaler()\n","\n","# Model: Logistic Regression Classifier\n","# A simple linear model for multi-class classification.\n","# We use 'lbfgs' solver which works well with StandardScaler and multi_class='auto'.\n","# Increased max_iter to avoid potential convergence warnings after scaling.\n","classifier = LogisticRegression(multi_class='auto', solver='lbfgs', max_iter=1000, random_state=random_state)\n","\n","print(\"Preprocessing step defined: StandardScaler\")\n","print(\"Model step defined: LogisticRegression\")\n","\n","# --- Step 4: Create the Scikit-learn Pipeline ---\n","print(\"\\nStep 4: Creating the pipeline...\")\n","\n","# The pipeline chains the steps in order: first the scaler, then the classifier.\n","# The output of the first step (scaled data) becomes the input for the second step (classifier).\n","pipeline = Pipeline([\n","    ('scaler', scaler),         # First step: Apply the scaler\n","    ('classifier', classifier)  # Second step: Apply the classifier\n","])\n","\n","print(\"Pipeline created:\")\n","print(pipeline)\n","\n","# --- Step 5: Train the Pipeline (Fit on Training Data) ---\n","print(\"\\nStep 5: Training the pipeline on the training data...\")\n","\n","# When you call .fit() on the pipeline:\n","# 1. The 'scaler' step's .fit_transform(X_train, y_train) method is called.\n","#    - StandardScaler calculates the mean and standard deviation of X_train.\n","#    - It then transforms X_train using these calculated values.\n","# 2. The transformed X_train (let's call it X_train_scaled) is passed to the 'classifier' step.\n","# 3. The 'classifier' step's .fit(X_train_scaled, y_train) method is called.\n","#    - The Logistic Regression model is trained on the scaled training data.\n","# This ensures the scaler learns *only* from the training data, preventing data leakage.\n","pipeline.fit(X_train, y_train)\n","\n","print(\"Pipeline training complete.\")\n","\n","# You can optionally access the fitted components inside the pipeline\n","# print(\"\\nMean calculated by scaler during fit:\", pipeline.named_steps['scaler'].mean_)\n","# print(\"Std dev calculated by scaler during fit:\", pipeline.named_steps['scaler'].scale_)\n","\n","\n","# --- Step 6: Compute Score on the Test Set using the Pipeline ---\n","print(\"\\nStep 6: Evaluating the pipeline on the test data...\")\n","\n","# When you call .score() on the pipeline:\n","# 1. The 'scaler' step's .transform(X_test) method is called.\n","#    - StandardScaler uses the mean and standard deviation *learned during the .fit() on X_train*\n","#      to scale X_test. It does *not* recalculate mean/std from X_test.\n","# 2. The transformed X_test (X_test_scaled) is passed to the 'classifier' step.\n","# 3. The 'classifier' step's .score(X_test_scaled, y_test) method is called.\n","#    - The trained Logistic Regression model makes predictions on the scaled test data.\n","#    - The score (accuracy for classification by default) is computed by comparing predictions to y_test.\n","test_score = pipeline.score(X_test, y_test)\n","\n","print(f\"Pipeline test set score (Accuracy): {test_score:.4f}\")\n","\n","# Alternatively, predict and calculate accuracy explicitly\n","# y_pred = pipeline.predict(X_test)\n","# explicit_accuracy = accuracy_score(y_test, y_pred)\n","# print(f\"Explicitly calculated test set accuracy: {explicit_accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fyz-ecwL5jLI","executionInfo":{"status":"ok","timestamp":1749056641502,"user_tz":420,"elapsed":675,"user":{"displayName":"Vishesh Agrawal","userId":"16926083185186864017"}},"outputId":"af6c87f8-e0ad-4a45-9a21-fed52ff9b085"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: Generating synthetic dataset...\n","Dataset generated: X shape (1000, 25), y shape (1000,)\n","Number of unique classes: 5\n","\n","Step 2: Splitting data into training and testing sets...\n","Training data shape: (750, 25)\n","Testing data shape: (250, 25)\n","\n","Step 3: Defining preprocessing (scaling) and model steps...\n","Preprocessing step defined: StandardScaler\n","Model step defined: LogisticRegression\n","\n","Step 4: Creating the pipeline...\n","Pipeline created:\n","Pipeline(steps=[('scaler', StandardScaler()),\n","                ('classifier',\n","                 LogisticRegression(max_iter=1000, multi_class='auto',\n","                                    random_state=42))])\n","\n","Step 5: Training the pipeline on the training data...\n","Pipeline training complete.\n","\n","Step 6: Evaluating the pipeline on the test data...\n","Pipeline test set score (Accuracy): 0.7640\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import os\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","from datasets import load_dataset\n","import evaluate\n","import numpy as np\n","import torch\n","\n","# Define the model name and dataset name\n","MODEL_NAME = \"distilbert/distilbert-base-uncased\"\n","DATASET_NAME = \"imdb\"\n","# Define the output directory for saving checkpoints and results\n","OUTPUT_DIR = \"./distilbert_imdb_sentiment\"\n","\n","def train_distilbert_imdb(model_name: str = MODEL_NAME,\n","                          dataset_name: str = DATASET_NAME,\n","                          output_dir: str = OUTPUT_DIR,\n","                          num_train_epochs: int = 3,\n","                          per_device_train_batch_size: int = 16,\n","                          per_device_eval_batch_size: int = 16,\n","                          learning_rate: float = 2e-5,\n","                          weight_decay: float = 0.01,\n","                          logging_steps: int = 500,\n","                          eval_strategy: str = \"epoch\"):\n","    \"\"\"\n","    Trains a DistilBERT model on the IMDb dataset for binary sentiment classification.\n","\n","    Args:\n","        model_name (str): The name of the pre-trained model from Hugging Face Hub.\n","                          Defaults to 'distilbert/distilbert-base-uncased'.\n","        dataset_name (str): The name of the dataset from Hugging Face Hub.\n","                            Defaults to 'imdb'.\n","        output_dir (str): Directory to save model checkpoints and results.\n","        num_train_epochs (int): Number of training epochs.\n","        per_device_train_batch_size (int): Batch size per device for training.\n","        per_device_eval_batch_size (int): Batch size per device for evaluation.\n","        learning_rate (float): Learning rate for the optimizer.\n","        weight_decay (float): Weight decay for the optimizer.\n","        logging_steps (int): Number of steps between logging.\n","        eval_strategy (str): Evaluation strategy ('no', 'steps', 'epoch').\n","    \"\"\"\n","\n","    print(f\"--- Starting training for {model_name} on {dataset_name} ---\")\n","    print(f\"Output directory: {os.path.abspath(output_dir)}\")\n","\n","    # Step 1: Load the dataset\n","    # We load the train and test splits of the IMDb dataset from the Hugging Face datasets library.\n","    # The dataset structure for IMDb is typically {'text': ..., 'label': ...} where label is 0 for negative and 1 for positive.\n","    print(\"Loading dataset...\")\n","    dataset = load_dataset(dataset_name)\n","    print(\"Dataset loaded successfully.\")\n","    print(f\"Train dataset size: {len(dataset['train'])}\")\n","    print(f\"Test dataset size: {len(dataset['test'])}\")\n","    print(\"Example from dataset:\", dataset['train'][0])\n","\n","    # Step 2: Load the tokenizer\n","    # The tokenizer is responsible for converting text into numerical IDs that the model understands.\n","    # We load the tokenizer corresponding to the chosen pre-trained model.\n","    # use_fast=True provides faster tokenization if available for the model.\n","    print(f\"Loading tokenizer for {model_name}...\")\n","    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n","    print(\"Tokenizer loaded successfully.\")\n","\n","    # Step 3: Preprocess the data (Tokenization)\n","    # Models like BERT/DistilBERT require input in a specific format: sequences of token IDs.\n","    # This function takes a batch of examples, tokenizes the 'text' field, and returns the results.\n","    # 'truncation=True' ensures that sequences longer than the model's max length are cut off.\n","    # 'padding=True' pads shorter sequences to the maximum length within the batch (or to the model's max length if max_length is specified).\n","    # 'padding=True' defaults to 'longest' which pads to the longest sequence in the batch. This is efficient.\n","    # The 'label' column is automatically handled by the Trainer if it exists.\n","    def tokenize_function(examples):\n","        return tokenizer(examples[\"text\"], truncation=True, padding=True)\n","\n","    print(\"Tokenizing dataset...\")\n","    # We apply the tokenization function to the entire dataset using the map method.\n","    # batched=True allows the function to process multiple examples at once, which is much faster.\n","    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","    print(\"Dataset tokenization complete.\")\n","\n","    # Step 4: Load the model\n","    # We load the pre-trained DistilBERT model.\n","    # AutoModelForSequenceClassification adds a classification head on top of the base model.\n","    # num_labels=2 specifies that this is a binary classification task (positive/negative).\n","    # This function automatically downloads the pre-trained weights.\n","    print(f\"Loading model {model_name} for sequence classification...\")\n","    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n","    print(\"Model loaded successfully.\")\n","\n","    # Step 5: Define training arguments\n","    # TrainingArguments specifies all the parameters for the training process.\n","    # output_dir: Where to save checkpoints and the final model.\n","    # num_train_epochs: How many times to iterate over the training data.\n","    # per_device_*: Batch size for training and evaluation.\n","    # learning_rate: Step size for optimizer updates.\n","    # weight_decay: Regularization parameter.\n","    # evaluation_strategy: When to run evaluation (e.g., after every epoch).\n","    # logging_dir: Where to save logs (for TensorBoard).\n","    # logging_steps: How often to log training metrics.\n","    print(\"Defining training arguments...\")\n","    training_args = TrainingArguments(\n","        output_dir=output_dir,\n","        num_train_epochs=num_train_epochs,\n","        per_device_train_batch_size=per_device_train_batch_size,\n","        per_device_eval_batch_size=per_device_eval_batch_size,\n","        learning_rate=learning_rate,\n","        weight_decay=weight_decay,\n","        evaluation_strategy=eval_strategy, # Evaluate at the end of each epoch\n","        logging_dir=f\"{output_dir}/logs\",\n","        logging_steps=logging_steps,\n","        save_strategy=eval_strategy, # Save checkpoint at the end of each epoch\n","        load_best_model_at_end=True, # Load the best model based on evaluation metric at the end\n","        metric_for_best_model=\"accuracy\", # Metric to monitor for best model\n","        greater_is_better=True, # For accuracy, higher is better\n","        report_to=\"tensorboard\", # Report metrics to TensorBoard\n","        # auto_find_batch_size=True # Uncomment this if you want the trainer to find a good batch size\n","                                   # Potentially useful if you get CUDA out of memory errors\n","    )\n","    print(\"Training arguments defined.\")\n","    print(f\"Evaluation strategy: {training_args.evaluation_strategy}\")\n","\n","    # Step 6: Define metrics for evaluation\n","    # We need a function to compute metrics like accuracy, precision, recall, F1-score.\n","    # The evaluate library provides easy access to standard metrics.\n","    # This function will be called by the Trainer during evaluation.\n","    print(\"Loading evaluation metric...\")\n","    accuracy_metric = evaluate.load(\"accuracy\")\n","    # We could load others like precision, recall, f1 simultaneously if needed\n","    # precision_metric = evaluate.load(\"precision\")\n","    # recall_metric = evaluate.load(\"recall\")\n","    # f1_metric = evaluate.load(\"f1\")\n","\n","    def compute_metrics(eval_pred):\n","        # eval_pred is a tuple containing predictions and labels\n","        predictions, labels = eval_pred\n","        # For classification, the predictions are logits. We take the argmax to get the predicted class ID.\n","        predictions = np.argmax(predictions, axis=1)\n","        # compute() method calculates the metric score\n","        accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n","        # We can compute other metrics here as well\n","        # precision = precision_metric.compute(predictions=predictions, references=labels, average=\"binary\") # average=\"binary\" for binary classification\n","        # recall = recall_metric.compute(predictions=predictions, references=labels, average=\"binary\")\n","        # f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"binary\")\n","        # Return a dictionary of metrics\n","        return {\n","            \"accuracy\": accuracy[\"accuracy\"],\n","            # \"precision\": precision[\"precision\"],\n","            # \"recall\": recall[\"recall\"],\n","            # \"f1\": f1[\"f1\"],\n","        }\n","\n","    print(\"Compute metrics function defined.\")\n","\n","    # Step 7: Create and use the Trainer\n","    # The Trainer class simplifies the training loop significantly.\n","    # It handles optimizer, scheduler, device placement, logging, evaluation, saving, etc.\n","    # We pass the model, training arguments, tokenized datasets, tokenizer, and compute_metrics function.\n","    print(\"Initializing Trainer...\")\n","    trainer = Trainer(\n","        model=model,                              # The loaded model\n","        args=training_args,                       # The training arguments\n","        train_dataset=tokenized_dataset[\"train\"], # The training dataset\n","        eval_dataset=tokenized_dataset[\"test\"],   # The evaluation dataset\n","        tokenizer=tokenizer,                      # The tokenizer (used for padding/truncation within Trainer if needed)\n","        compute_metrics=compute_metrics           # The function to compute evaluation metrics\n","    )\n","    print(\"Trainer initialized.\")\n","\n","    # Check if GPU is available\n","    if torch.cuda.is_available():\n","        print(\"GPU available. Using GPU for training.\")\n","    else:\n","        print(\"GPU not available. Using CPU for training. Training will be slower.\")\n","\n","    # Start the training process\n","    print(\"Starting training...\")\n","    train_result = trainer.train()\n","    print(\"Training finished.\")\n","\n","    # Evaluate the model after training\n","    print(\"Evaluating the model on the test set...\")\n","    eval_results = trainer.evaluate()\n","    print(\"Evaluation results:\", eval_results)\n","\n","    # Save the final model and tokenizer\n","    print(f\"Saving final model and tokenizer to {output_dir}...\")\n","    trainer.save_model(output_dir)\n","    tokenizer.save_pretrained(output_dir)\n","    print(\"Model and tokenizer saved.\")\n","\n","    # Optional: Print some summary of the training\n","    metrics = train_result.metrics\n","    print(\"Training Metrics:\", metrics)\n","    trainer.log_metrics(\"train\", metrics)\n","    trainer.save_metrics(\"train\", metrics)\n","    trainer.save_state()\n","\n","    print(\"--- Training complete ---\")\n","    return trainer, eval_results\n","\n","# Example usage:\n","if __name__ == \"__main__\":\n","    # Ensure output directory exists\n","    os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","    # You can call the function with default arguments or customize them\n","    trainer, eval_results = train_distilbert_imdb(\n","        num_train_epochs=1, # Train for 3 epochs\n","        per_device_train_batch_size=16, # Smaller batch size if memory is an issue\n","        per_device_eval_batch_size=16,\n","        learning_rate=2e-5,\n","        output_dir=\"./distilbert_imdb_sentiment_run\" # Use a specific run directory\n","    )\n","\n","    print(\"\\nTraining and evaluation process completed.\")\n","    print(f\"Final evaluation results: {eval_results}\")\n","    print(f\"Model saved to: {os.path.abspath('./distilbert_imdb_sentiment_run')}\")\n","\n","    # Example of loading the trained model for inference:\n","    # from transformers import pipeline\n","    # # Need to map label IDs to names if you want text output\n","    # id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n","    # label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n","    # classifier = pipeline(\n","    #     \"sentiment-analysis\",\n","    #     model=\"./distilbert_imdb_sentiment_run\",\n","    #     tokenizer=\"./distilbert_imdb_sentiment_run\",\n","    #     id2label=id2label,\n","    #     device=0 if torch.cuda.is_available() else -1 # Use GPU if available\n","    # )\n","    # print(\"\\nExample inference:\")\n","    # result = classifier(\"This movie was absolutely fantastic and I loved every minute of it!\")\n","    # print(result)\n","    # result = classifier(\"This movie was terrible and boring.\")\n","    # print(result)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"6PSyo39K5q6l","executionInfo":{"status":"error","timestamp":1749056726506,"user_tz":420,"elapsed":11790,"user":{"displayName":"Vishesh Agrawal","userId":"16926083185186864017"}},"outputId":"4a113f9a-3bab-4680-bcaf-62e348647f34"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'evaluate'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-af3b9a7f2608>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evaluate'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["# Step 1: Import Libraries\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import os # To create directories for checkpoints\n","\n","# Print TensorFlow version to ensure it's installed\n","print(\"TensorFlow version:\", tf.__version__)\n","# Step 2: Load and Prepare Data\n","\n","# Load the Fashion MNIST dataset\n","fashion_mnist = keras.datasets.fashion_mnist\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","# Define class names (for later use, not strictly needed for training)\n","class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n","\n","# Data Preprocessing\n","\n","# Normalize pixel values to be between 0 and 1\n","# The images are 28x28 arrays with pixel values from 0 to 255\n","train_images = train_images / 255.0\n","test_images = test_images / 255.0\n","\n","# Add a channel dimension to the images\n","# CNNs typically expect input shape (height, width, channels)\n","# For grayscale, the channel is 1. (28, 28) -> (28, 28, 1)\n","train_images = train_images[..., tf.newaxis]\n","test_images = test_images[..., tf.newaxis]\n","\n","# --- Data Splitting for Validation ---\n","# Callbacks like EarlyStopping/ModelCheckpoint monitor a validation set.\n","# We'll split the original training data into training and validation sets.\n","# A common split is 80/20 or 90/10. Let's use 5000 images for validation.\n","num_validation_samples = 5000\n","\n","val_images = train_images[:num_validation_samples]\n","val_labels = train_labels[:num_validation_samples]\n","\n","train_images = train_images[num_validation_samples:]\n","train_labels = train_labels[num_validation_samples:]\n","\n","print(\"Training images shape:\", train_images.shape)\n","print(\"Training labels shape:\", train_labels.shape)\n","print(\"Validation images shape:\", val_images.shape)\n","print(\"Validation labels shape:\", val_labels.shape)\n","print(\"Test images shape:\", test_images.shape)\n","print(\"Test labels shape:\", test_labels.shape)\n","# Step 3: Build the Model\n","\n","# We'll use a simple Convolutional Neural Network (CNN) as it's effective for images.\n","model = keras.Sequential([\n","    # Convolutional Layer 1\n","    # Filters: Number of output filters (features). 32 is a common starting point.\n","    # Kernel Size: Dimensions of the convolution window (3x3 here).\n","    # Activation: ReLU (Rectified Linear Unit) introduces non-linearity.\n","    # Input Shape: Required for the first layer to know the input dimensions.\n","    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n","\n","    # Max Pooling Layer 1\n","    # Pool Size: Downsamples the input by taking the maximum value over a window (2x2 here).\n","    # Reduces spatial dimensions, helps with translation invariance.\n","    keras.layers.MaxPooling2D((2, 2)),\n","\n","    # Convolutional Layer 2\n","    # More filters to potentially learn more complex features.\n","    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","\n","    # Max Pooling Layer 2\n","    keras.layers.MaxPooling2D((2, 2)),\n","\n","    # Flatten Layer\n","    # Flattens the 2D feature maps into a 1D vector to feed into the dense layers.\n","    keras.layers.Flatten(),\n","\n","    # Dense (Fully Connected) Layer\n","    # Standard dense layer with ReLU activation.\n","    keras.layers.Dense(128, activation='relu'),\n","\n","    # Output Layer\n","    # 10 units because there are 10 classes in Fashion MNIST.\n","    # Softmax activation ensures the output is a probability distribution over the classes.\n","    keras.layers.Dense(10, activation='softmax')\n","])\n","\n","# Print the model summary\n","model.summary()\n","# Step 4: Compile the Model\n","\n","# Configure the model for training\n","model.compile(optimizer='adam', # Optimizer: How the model updates weights based on loss\n","              loss='sparse_categorical_crossentropy', # Loss function: Measures how accurate the model is during training\n","                                                       # Use sparse_categorical_crossentropy when labels are integers (0-9)\n","                                                       # Use categorical_crossentropy if labels are one-hot encoded\n","              metrics=['accuracy']) # Metrics: Used to monitor the training and testing steps (e.g., accuracy)\n","# Step 5: Define Callbacks\n","\n","# --- Early Stopping Callback ---\n","# Stop training when the monitored metric has stopped improving.\n","early_stopping_callback = keras.callbacks.EarlyStopping(\n","    monitor='val_loss', # Metric to monitor (validation loss)\n","    patience=5,         # Number of epochs with no improvement after which training will be stopped.\n","                        # If val_loss doesn't decrease for 5 consecutive epochs, stop.\n","    mode='min',         # 'min' means stop when the monitored quantity stops decreasing.\n","    verbose=1           # Print message when stopping\n",")\n","\n","# --- Model Checkpoint Callback ---\n","# Save the model (or weights) during training.\n","# We'll save the model with the best validation accuracy.\n","\n","# Create a directory to save checkpoints\n","checkpoint_dir = './training_checkpoints'\n","os.makedirs(checkpoint_dir, exist_ok=True) # Create directory if it doesn't exist\n","\n","# Define the checkpoint file path\n","# Use '{epoch:02d}-{val_loss:.2f}' to include epoch number and validation loss in the filename\n","checkpoint_filepath = os.path.join(checkpoint_dir, 'best_model_epoch_{epoch:02d}_val_loss_{val_loss:.2f}')\n","\n","\n","model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    monitor='val_loss',      # Metric to monitor for saving (validation loss)\n","    save_best_only=True,     # Only save the model when the monitored metric improves.\n","                             # This saves the model with the lowest validation loss found during training.\n","    mode='min',              # 'min' means save when the monitored quantity decreases.\n","    save_weights_only=False, # If False, saves the entire model (structure + weights).\n","                             # If True, only saves the weights. Saving the entire model is often easier.\n","    verbose=1                # Print message when saving\n",")\n","\n","# Create a list of callbacks to pass to model.fit()\n","callbacks_list = [early_stopping_callback, model_checkpoint_callback]\n","# Step 6: Train the Model\n","\n","# Define the number of epochs to train for.\n","# Since we have Early Stopping, we can set this to a reasonably large number.\n","# The model will stop training automatically when needed.\n","EPOCHS = 1 # Start with a value larger than patience, but not excessively large\n","\n","# Define the batch size\n","BATCH_SIZE = 32\n","\n","print(\"\\nStarting training...\")\n","history = model.fit(train_images, train_labels,\n","                    epochs=EPOCHS,\n","                    batch_size=BATCH_SIZE,\n","                    validation_data=(val_images, val_labels), # Provide validation data\n","                    callbacks=callbacks_list)                  # Pass the list of callbacks\n","\n","print(\"\\nTraining finished.\")\n","# Step 7: Evaluate the Model on the Test Set\n","\n","print(\"\\nEvaluating the model on the test set...\")\n","test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n","\n","print('\\nTest accuracy:', test_acc)\n","print('Test loss:', test_loss)\n","# Step 8: Load and Use the Best Model\n","\n","# Find the path to the best model saved by the checkpoint\n","# ModelCheckpoint saves files like 'best_model_epoch_XX_val_loss_Y.YY'\n","# We need to find the file with the lowest validation loss among those saved.\n","# Since save_best_only=True, there should ideally be only one such file at the end,\n","# corresponding to the minimum val_loss achieved.\n","# Let's list files and find the one that matches the pattern\n","\n","import glob\n","\n","list_of_files = glob.glob(os.path.join(checkpoint_dir, 'best_model_epoch_*'))\n","# Sort by modification time to get the latest file saved, assuming save_best_only\n","# is effectively overwriting (though with the epoch in the name, it creates new ones)\n","# A more robust way is to track the best val_loss ourselves or parse filenames.\n","# However, with save_best_only and unique filenames per epoch, sorting by time or just taking the list\n","# of files saved should give us the relevant checkpoint(s).\n","# Let's assume the file with the lowest loss *name* is the best one among those saved.\n","# A simpler way is to just load from the *latest* checkpoint if save_best_only\n","# was combined with a non-unique filename, but here filenames are unique.\n","# Let's load the first file found that matches the pattern, assuming save_best_only\n","# made sure this is the best one saved.\n","\n","# A better approach: explicitly define the best file path pattern if not using epoch numbers\n","# For simplicity with epoch numbers, let's just load one of the saved checkpoints.\n","# If save_best_only=True, any saved checkpoint should represent an improvement.\n","# The *last* saved file might not be the *best* because Early Stopping kicked in.\n","# The filename format includes the loss, we could parse that.\n","# Or, if save_best_only was used with a constant filename (e.g., 'best_model.h5'),\n","# that file would *be* the best one automatically.\n","# Let's modify the checkpoint filepath to be constant when saving the best.\n","\n","# New checkpoint filepath for the single best model file\n","best_checkpoint_filepath = os.path.join(checkpoint_dir, 'best_model.h5')\n","\n","# Redefine the ModelCheckpoint callback to save to a single file\n","model_checkpoint_callback_best = keras.callbacks.ModelCheckpoint(\n","    filepath=best_checkpoint_filepath,\n","    monitor='val_loss',      # Metric to monitor\n","    save_best_only=True,     # ONLY save the model when the monitored metric improves\n","    mode='min',              # Minimize validation loss\n","    save_weights_only=False, # Save the entire model\n","    verbose=1\n",")\n","\n","# Rerun training with the simplified checkpoint path (optional, just demonstrating)\n","# In a real scenario, you'd likely just use the simpler path from the start.\n","# Or load the best one from the epoch-based names saved earlier.\n","# For demonstration, let's show loading *a* saved model.\n","# Let's assume the last checkpoint saved *before* early stopping was the best.\n","# This is not guaranteed if save_best_only was used with epoch names and early stopping triggered.\n","# Let's just load one of the existing checkpoints saved in the first run.\n","\n","# Let's find the path of the checkpoint with the LOWEST validation loss from the first run\n","# This requires parsing the filenames.\n","import re\n","\n","best_loss_so_far = float('inf')\n","best_model_path = None\n","\n","for filepath in glob.glob(os.path.join(checkpoint_dir, 'best_model_epoch_*_val_loss_*.h5')):\n","    # Extract val_loss from filename using regex\n","    match = re.search(r'_val_loss_(\\d+\\.\\d+)', filepath)\n","    if match:\n","        current_loss = float(match.group(1))\n","        if current_loss < best_loss_so_far:\n","            best_loss_so_far = current_loss\n","            best_model_path = filepath\n","\n","print(f\"\\nIdentified best model path based on filename: {best_model_path}\")\n","\n","# Load the best model found during training\n","if best_model_path:\n","    print(f\"Loading model from: {best_model_path}\")\n","    loaded_model = keras.models.load_model(best_model_path)\n","\n","    # Evaluate the loaded model on the test set\n","    print(\"\\nEvaluating the LOADED best model on the test set...\")\n","    test_loss_loaded, test_acc_loaded = loaded_model.evaluate(test_images, test_labels, verbose=2)\n","\n","    print('\\nLoaded Model Test accuracy:', test_acc_loaded)\n","    print('Loaded Model Test loss:', test_loss_loaded)\n","else:\n","    print(\"No checkpoint files found.\")\n","\n","# Example prediction with the loaded model\n","if loaded_model:\n","    print(\"\\nMaking predictions with the loaded model...\")\n","    predictions = loaded_model.predict(test_images[:5]) # Predict on the first 5 test images\n","    print(\"Predictions shape:\", predictions.shape)\n","\n","    # Show the predicted class for the first 5 images\n","    predicted_classes = np.argmax(predictions, axis=1)\n","    print(\"Predicted classes (first 5):\", predicted_classes)\n","    print(\"True classes (first 5):\", test_labels[:5])\n","\n","    # Map predicted class indices to names\n","    predicted_class_names = [class_names[i] for i in predicted_classes]\n","    true_class_names = [class_names[i] for i in test_labels[:5]]\n","\n","    print(\"Predicted class names (first 5):\", predicted_class_names)\n","    print(\"True class names (first 5):\", true_class_names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"QH6drvPy57Pt","executionInfo":{"status":"error","timestamp":1749070274379,"user_tz":420,"elapsed":25188,"user":{"displayName":"Vishesh Agrawal","userId":"16926083185186864017"}},"outputId":"5805dd5d-3282-43c8-ed2c-a307f920ffbb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.18.0\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","Training images shape: (55000, 28, 28, 1)\n","Training labels shape: (55000,)\n","Validation images shape: (5000, 28, 28, 1)\n","Validation labels shape: (5000,)\n","Test images shape: (10000, 28, 28, 1)\n","Test labels shape: (10000,)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m204,928\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m225,034\u001b[0m (879.04 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,034</span> (879.04 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m225,034\u001b[0m (879.04 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,034</span> (879.04 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"error","ename":"ValueError","evalue":"The filepath provided must end in `.keras` (Keras model format). Received: filepath=./training_checkpoints/best_model_epoch_{epoch:02d}_val_loss_{val_loss:.2f}","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a2279903c3f7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# Metric to monitor for saving (validation loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             ):\n\u001b[0;32m--> 194\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    195\u001b[0m                     \u001b[0;34m\"The filepath provided must end in `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                     \u001b[0;34m\"(Keras model format). Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The filepath provided must end in `.keras` (Keras model format). Received: filepath=./training_checkpoints/best_model_epoch_{epoch:02d}_val_loss_{val_loss:.2f}"]}]},{"cell_type":"code","source":["# fashion_mnist_folder/\n","# ├── train/\n","# │   ├── T-shirt_top/\n","# │   │   ├── img_00001.png\n","# │   │   ├── img_00002.png\n","# │   │   └── ...\n","# │   ├── Trouser/\n","# │   │   ├── img_01001.png\n","# │   │   └── ...\n","# │   └── ... (other class folders)\n","# └── test/\n","#     ├── T-shirt_top/\n","#     │   ├── img_60001.png\n","#     │   └── ...\n","#     └── ... (other class folders)\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","from PIL import Image\n","import shutil\n","\n","# --- Pre-processing: Save FashionMNIST to Folder Structure ---\n","# This part downloads the data and organizes it into folders.\n","# You only need to run this once.\n","\n","def save_fashion_mnist_to_folder(root_output_dir='./fashion_mnist_folder'):\n","    \"\"\"\n","    Downloads FashionMNIST and saves images into a folder structure\n","    like root_output_dir/split/class_name/image.png\n","    \"\"\"\n","    print(f\"Saving FashionMNIST to folders in {root_output_dir}...\")\n","\n","    # Define class names for FashionMNIST\n","    classes = [\n","        'T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle_boot'\n","    ]\n","\n","    # Ensure the root output directory is clean or created\n","    if os.path.exists(root_output_dir):\n","        print(f\"Removing existing directory: {root_output_dir}\")\n","        shutil.rmtree(root_output_dir)\n","    os.makedirs(root_output_dir)\n","\n","    # Download and process training data\n","    train_dataset_original = torchvision.datasets.FashionMNIST(\n","        root='./data', train=True, download=True\n","    )\n","    save_split(train_dataset_original, 'train', root_output_dir, classes)\n","\n","    # Download and process test data\n","    test_dataset_original = torchvision.datasets.FashionMNIST(\n","        root='./data', train=False, download=True\n","    )\n","    save_split(test_dataset_original, 'test', root_output_dir, classes)\n","\n","    print(\"FashionMNIST data saved successfully.\")\n","\n","def save_split(dataset, split_name, root_output_dir, classes):\n","    \"\"\"Saves images from a single split (train/test) to folders.\"\"\"\n","    split_dir = os.path.join(root_output_dir, split_name)\n","    print(f\"Processing {split_name} split...\")\n","\n","    for class_name in classes:\n","        os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\n","\n","    for i, (img, label) in enumerate(dataset):\n","        class_name = classes[label]\n","        # FashionMNIST images are 28x28 grayscale PIL Images\n","        img_path = os.path.join(split_dir, class_name, f'img_{i:05d}.png')\n","        img.save(img_path) # PIL Image save\n","\n","# --- Run the pre-processing step ---\n","# Uncomment the line below to generate the folder structure.\n","# save_fashion_mnist_to_folder()\n","# print(\"Please run the save_fashion_mnist_to_folder() function to create the data structure.\")\n","import torch\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","import os\n","from PIL import Image\n","\n","# --- Custom Dataset Class ---\n","\n","class FashionMNISTFolderDataset(Dataset):\n","    \"\"\"\n","    Custom Dataset to load FashionMNIST images from a folder structure\n","    like root_dir/split/class_name/image.png\n","    \"\"\"\n","    def __init__(self, root_dir, split='train', transform=None):\n","        \"\"\"\n","        Args:\n","            root_dir (string): Directory with all the split folders (e.g. 'fashion_mnist_folder/').\n","            split (string): 'train' or 'test' indicating the split to load.\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","        self.root_dir = root_dir\n","        self.split = split\n","        self.transform = transform\n","        self.split_dir = os.path.join(root_dir, split)\n","\n","        if not os.path.exists(self.split_dir):\n","            raise FileNotFoundError(f\"Split directory not found: {self.split_dir}\")\n","\n","        # Store class names and create mapping from class name to index\n","        # FashionMNIST classes (sorted alphabetically would match the folder structure)\n","        self.classes = sorted(entry.name for entry in os.scandir(self.split_dir) if entry.is_dir())\n","        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n","\n","        if not self.classes:\n","             raise RuntimeError(f\"No class directories found in {self.split_dir}\")\n","\n","\n","        # Build the list of (image_path, label) pairs\n","        self.samples = []\n","        for class_name in self.classes:\n","            class_dir = os.path.join(self.split_dir, class_name)\n","            if not os.path.isdir(class_dir):\n","                continue # Skip if it's not actually a directory\n","\n","            label = self.class_to_idx[class_name]\n","\n","            for img_file in os.listdir(class_dir):\n","                # Basic check for image files (can be expanded)\n","                if img_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n","                    img_path = os.path.join(class_dir, img_file)\n","                    self.samples.append((img_path, label))\n","\n","        if not self.samples:\n","            raise RuntimeError(f\"No images found in {self.split_dir}. Make sure images are saved in class subfolders.\")\n","\n","        print(f\"Found {len(self.samples)} images in the '{split}' split.\")\n","        print(f\"Classes: {self.classes}\")\n","\n","\n","    def __len__(self):\n","        \"\"\"Returns the total number of samples.\"\"\"\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"Loads and returns a sample from the dataset at the given index.\"\"\"\n","        if not (0 <= idx < len(self)):\n","            raise IndexError(f\"Index {idx} is out of bounds for dataset of size {len(self)}\")\n","\n","        img_path, label = self.samples[idx]\n","\n","        # Load image using Pillow (PIL)\n","        # FashionMNIST is grayscale, so convert to 'L'\n","        try:\n","            img = Image.open(img_path).convert('L')\n","        except Exception as e:\n","            print(f\"Error loading image {img_path}: {e}\")\n","            # Return a dummy or handle error appropriately, e.g., skip sample\n","            # For simplicity here, we'll raise, but a real system might skip\n","            raise\n","\n","        # Apply transforms\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        return img, label # Return the image tensor and the label\n","import torch\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt # Optional: for visualization\n","import numpy as np # Optional: for visualization\n","\n","# --- Usage with DataLoader ---\n","\n","# Define the directory where data was saved (modify if you changed it)\n","DATA_FOLDER_ROOT = './fashion_mnist_folder'\n","\n","# Define transformations\n","# Common transforms for image data:\n","# 1. ToTensor: Converts PIL Image (H x W) to PyTorch Tensor (C x H x W)\n","#    and scales pixel values from [0, 255] to [0.0, 1.0].\n","# 2. Normalize: Standardizes pixel values using mean and standard deviation.\n","#    FashionMNIST mean and std for grayscale: mean=0.286, std=0.353 (approx)\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.286,), (0.353,)) # Mean and Std for grayscale FashionMNIST\n","])\n","\n","# --- Instantiate the Dataset ---\n","# Make sure you have run save_fashion_mnist_to_folder() at least once\n","# to create the ./fashion_mnist_folder directory.\n","try:\n","    train_dataset = FashionMNISTFolderDataset(\n","        root_dir=DATA_FOLDER_ROOT,\n","        split='train',\n","        transform=transform\n","    )\n","\n","    test_dataset = FashionMNISTFolderDataset(\n","        root_dir=DATA_FOLDER_ROOT,\n","        split='test',\n","        transform=transform\n","    )\n","\n","except FileNotFoundError as e:\n","    print(f\"Data folder not found: {e}\")\n","    print(\"Please run the save_fashion_mnist_to_folder() function first.\")\n","    exit() # Exit if data isn't ready\n","\n","# --- Instantiate the DataLoader ---\n","BATCH_SIZE = 64\n","NUM_WORKERS = 2 # Number of subprocesses for data loading (set to 0 for debugging)\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,      # Shuffle training data\n","    num_workers=NUM_WORKERS\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,     # No need to shuffle test data\n","    num_workers=NUM_WORKERS\n",")\n","\n","# --- Example: Iterate through a batch ---\n","print(\"\\nIterating through a batch from the DataLoader...\")\n","\n","# Get one batch\n","images, labels = next(iter(train_loader))\n","\n","print(f\"Batch of images shape: {images.shape}\") # Expected: [batch_size, channels, height, width] -> [64, 1, 28, 28]\n","print(f\"Batch of labels shape: {labels.shape}\") # Expected: [batch_size]\n","print(f\"Labels in batch: {labels}\")\n","\n","# Optional: Visualize a few images from the batch\n","print(\"\\nDisplaying first 4 images from the batch:\")\n","fig = plt.figure(figsize=(8, 8))\n","for i in range(4):\n","    ax = fig.add_subplot(2, 2, i + 1)\n","    ax.set_title(f\"Label: {train_dataset.classes[labels[i]]}\")\n","    ax.axis('off')\n","    # Undo normalization and permute dimensions for plotting (C, H, W) -> (H, W, C) or (H, W) for grayscale\n","    img_display = images[i] * 0.353 + 0.286 # Undo normalization\n","    img_display = img_display.squeeze() # Remove channel dimension if grayscale\n","    plt.imshow(img_display.numpy(), cmap='gray')\n","plt.tight_layout()\n","plt.show()\n","\n","\n","print(\"\\nDataLoader setup complete. You can now use train_loader and test_loader.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"Er4fsZOu6wOt","executionInfo":{"status":"error","timestamp":1749057133650,"user_tz":420,"elapsed":8143,"user":{"displayName":"Vishesh Agrawal","userId":"16926083185186864017"}},"outputId":"59a742c2-0e4e-4560-a31b-9585e03f05d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data folder not found: Split directory not found: ./fashion_mnist_folder/train\n","Please run the save_fashion_mnist_to_folder() function first.\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'train_dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-97668bf30653>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m train_loader = DataLoader(\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# Shuffle training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"]}]},{"cell_type":"code","source":["# Step 1: Import necessary libraries\n","# We need modules for loading the dataset, PCA, splitting data, KNN, and evaluating the model.\n","from sklearn.datasets import load_iris\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","import numpy as np # Often useful, though not strictly needed for this basic script\n","\n","print(\"Step 1: Imported necessary libraries.\")\n","\n","# Step 2: Load the Iris dataset\n","# scikit-learn provides a convenient function to load this classic dataset.\n","# The dataset is returned as a Bunch object, containing data (features) and target (labels).\n","iris = load_iris()\n","X = iris.data  # Features (sepal length, sepal width, petal length, petal width)\n","y = iris.target # Target labels (0: setosa, 1: versicolor, 2: virginica)\n","\n","print(f\"Step 2: Loaded Iris dataset. Original feature shape: {X.shape}\")\n","print(f\"Number of samples: {X.shape[0]}\")\n","print(f\"Number of original features: {X.shape[1]}\")\n","\n","\n","# Step 3: Split the data into training and testing sets\n","# It's crucial to split the data *before* applying any transformations like PCA or scaling\n","# to prevent data leakage from the test set into the training process.\n","# train_test_split shuffles the data by default before splitting.\n","# We use random_state for reproducibility so that the split is the same every time the script runs.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n","\n","print(f\"Step 3: Split data into training (75%) and testing (25%) sets.\")\n","print(f\"Training feature shape: {X_train.shape}\")\n","print(f\"Testing feature shape: {X_test.shape}\")\n","\n","# Step 4: Apply PCA for dimensionality reduction\n","# We instantiate a PCA object, specifying the desired number of components.\n","# The Iris dataset has 4 features. A common choice for visualization is 2 components,\n","# which we'll use here. You could choose more components (up to the original number of features)\n","# or choose a number based on explained variance ratio.\n","pca = PCA(n_components=2)\n","\n","# Fit PCA *only* on the training data. This step calculates the principal components\n","# based on the training data's variance.\n","pca.fit(X_train)\n","\n","# Transform both the training and testing data using the fitted PCA model.\n","# This projects the original data onto the lower-dimensional principal components.\n","X_train_pca = pca.transform(X_train)\n","X_test_pca = pca.transform(X_test)\n","\n","print(f\"Step 4: Applied PCA to reduce dimensionality to 2 components.\")\n","print(f\"PCA-transformed training shape: {X_train_pca.shape}\")\n","print(f\"PCA-transformed testing shape: {X_test_pca.shape}\")\n","# Optional: Print explained variance ratio\n","print(f\"Explained variance ratio by components: {pca.explained_variance_ratio_}\")\n","print(f\"Total explained variance: {np.sum(pca.explained_variance_ratio_):.4f}\")\n","\n","\n","# Step 5: Fit a K-Nearest Neighbors (KNN) classifier\n","# We instantiate the KNeighborsClassifier. 'n_neighbors' is the 'k' value -\n","# the number of nearest neighbors to consider for classification. A common default is 5.\n","knn = KNeighborsClassifier(n_neighbors=5)\n","\n","# Train the KNN model using the PCA-transformed training data and the corresponding labels.\n","knn.fit(X_train_pca, y_train)\n","\n","print(f\"Step 5: Trained a KNN classifier with n_neighbors={knn.n_neighbors} on the PCA-transformed training data.\")\n","\n","# Step 6: Evaluate the model on the PCA-transformed test data\n","# Make predictions on the unseen, PCA-transformed test data.\n","y_pred = knn.predict(X_test_pca)\n","\n","# Calculate the accuracy by comparing the predicted labels to the actual test labels.\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","print(f\"Step 6: Evaluated the KNN model on the PCA-transformed test data.\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","\n","# --- Summary and optional further steps ---\n","print(\"\\n--- Summary ---\")\n","print(\"Script completed successfully.\")\n","print(f\"Original data shape: {X.shape}\")\n","print(f\"Reduced data shape after PCA: {X_train_pca.shape}\")\n","print(f\"KNN Model trained on PCA-reduced data.\")\n","print(f\"Accuracy on test set: {accuracy:.4f}\")\n","\n","# Optional: You could visualize the PCA-reduced data and decision boundary if needed\n","# import matplotlib.pyplot as plt\n","# # (Code for visualization would go here, plotting X_test_pca and coloring by y_test or y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w_Dq4EBk7jvc","executionInfo":{"status":"ok","timestamp":1749057172042,"user_tz":420,"elapsed":7494,"user":{"displayName":"Vishesh Agrawal","userId":"16926083185186864017"}},"outputId":"d15e444b-0897-421f-d336-591a56c292ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: Imported necessary libraries.\n","Step 2: Loaded Iris dataset. Original feature shape: (150, 4)\n","Number of samples: 150\n","Number of original features: 4\n","Step 3: Split data into training (75%) and testing (25%) sets.\n","Training feature shape: (112, 4)\n","Testing feature shape: (38, 4)\n","Step 4: Applied PCA to reduce dimensionality to 2 components.\n","PCA-transformed training shape: (112, 2)\n","PCA-transformed testing shape: (38, 2)\n","Explained variance ratio by components: [0.91835496 0.05714723]\n","Total explained variance: 0.9755\n","Step 5: Trained a KNN classifier with n_neighbors=5 on the PCA-transformed training data.\n","Step 6: Evaluated the KNN model on the PCA-transformed test data.\n","Accuracy: 1.0000\n","\n","--- Summary ---\n","Script completed successfully.\n","Original data shape: (150, 4)\n","Reduced data shape after PCA: (112, 2)\n","KNN Model trained on PCA-reduced data.\n","Accuracy on test set: 1.0000\n"]}]},{"cell_type":"code","source":["# xml\n","# <dependency>\n","#     <groupId>org.apache.hadoop</groupId>\n","#     <artifactId>hadoop-client</artifactId>\n","#     <version>3.3.1</version> <!-- Use your Hadoop version -->\n","#     <scope>provided</scope>\n","# </dependency>\n","# <dependency>\n","#     <groupId>org.apache.hadoop</groupId>\n","#     <artifactId>hadoop-common</artifactId>\n","#     <version>3.3.1</version> <!-- Use your Hadoop version -->\n","#     <scope>provided</scope>\n","# </dependency>\n","# java\n","# package com.yourcompany.hadoop; // Use your own package name\n","\n","import java.io.IOException;\n","import java.util.StringTokenizer;\n","\n","import org.apache.hadoop.io.IntWritable;\n","import org.apache.hadoop.io.LongWritable;\n","import org.apache.hadoop.io.Text;\n","import org.apache.hadoop.mapreduce.Mapper;\n","\n","public class WordCountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {\n","\n","    // Output value is always 1 for a single occurrence\n","    private final static IntWritable one = new IntWritable(1);\n","    // Reusable Text object for the word\n","    private Text word = new Text();\n","\n","    @Override\n","    public void map(LongWritable key, Text value, Context context)\n","            throws IOException, InterruptedException {\n","\n","        // 1. Get the line of text as a Java String\n","        String line = value.toString();\n","\n","        // 2. Tokenize the line into words\n","        // StringTokenizer is a simple way; for more robust parsing,\n","        // you might use split() with regex or other libraries.\n","        // Here, we split by whitespace characters.\n","        StringTokenizer tokenizer = new StringTokenizer(line);\n","\n","        // 3. Iterate through the tokens (words)\n","        while (tokenizer.hasMoreTokens()) {\n","            // 4. Get the next token\n","            String nextToken = tokenizer.nextToken();\n","\n","            // Optional: Clean up the word (e.g., remove punctuation, lowercase)\n","            // A simple approach is to convert to lowercase and remove non-alphanumeric\n","            String cleanWord = nextToken.toLowerCase().replaceAll(\"[^a-z0-9]\", \"\");\n","\n","            // 5. Set the Text object to the current word\n","            // Only process non-empty cleaned words\n","            if (!cleanWord.isEmpty()) {\n","                word.set(cleanWord);\n","\n","                // 6. Emit the word and a count of 1\n","                // The key is the word (Text), the value is 1 (IntWritable)\n","                context.write(word, one);\n","            }\n","        }\n","    }\n","}\n","java\n","package com.yourcompany.hadoop; // Use your own package name\n","\n","import java.io.IOException;\n","\n","import org.apache.hadoop.io.IntWritable;\n","import org.apache.hadoop.io.Text;\n","import org.apache.hadoop.mapreduce.Reducer;\n","\n","public class WordCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\n","\n","    // Reusable IntWritable object for the final count\n","    private IntWritable result = new IntWritable();\n","\n","    @Override\n","    public void reduce(Text key, Iterable<IntWritable> values, Context context)\n","            throws IOException, InterruptedException {\n","\n","        // 1. The key is the word itself\n","        // 2. The values is an iterable collection of all the '1's emitted for this word\n","        int sum = 0;\n","\n","        // 3. Iterate through the list of values (all are IntWritable(1))\n","        for (IntWritable val : values) {\n","            // 4. Sum up the values\n","            sum += val.get();\n","        }\n","\n","        // 5. Set the final count in the result object\n","        result.set(sum);\n","\n","        // 6. Emit the word (key) and its total count (result)\n","        context.write(key, result);\n","    }\n","}\n","java\n","package com.yourcompany.hadoop; // Use your own package name\n","\n","import org.apache.hadoop.conf.Configuration;\n","import org.apache.hadoop.conf.Configured;\n","import org.apache.hadoop.fs.Path;\n","import org.apache.hadoop.io.IntWritable;\n","import org.apache.hadoop.io.Text;\n","import org.apache.hadoop.mapreduce.Job;\n","import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n","import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n","import org.apache.hadoop.util.Tool;\n","import org.apache.hadoop.util.ToolRunner;\n","import org.apache.hadoop.fs.FileSystem;\n","import java.net.URI;\n","\n","public class WordCount extends Configured implements Tool {\n","\n","    @Override\n","    public int run(String[] args) throws Exception {\n","\n","        // 1. Get configuration object\n","        Configuration conf = this.getConf();\n","\n","        // 2. Create a Job object\n","        Job job = Job.getInstance(conf, \"Word Count\");\n","\n","        // 3. Specify the JAR file by class\n","        // This tells Hadoop where to find your Mapper and Reducer classes\n","        job.setJarByClass(WordCount.class);\n","\n","        // 4. Specify the Mapper class\n","        job.setMapperClass(WordCountMapper.class);\n","\n","        // 5. Specify the Combiner class (Optional, but good for performance)\n","        // The Combiner runs on the mapper side and performs local aggregation\n","        // It uses the same logic as the Reducer for Word Count\n","        job.setCombinerClass(WordCountReducer.class);\n","\n","        // 6. Specify the Reducer class\n","        job.setReducerClass(WordCountReducer.class);\n","\n","        // 7. Specify the output key and value types for the job (Reducer output)\n","        job.setOutputKeyClass(Text.class);\n","        job.setOutputValueClass(IntWritable.class);\n","\n","        // Optional: Specify the output key and value types for the Mapper (intermediate output)\n","        // This is often inferred, but can be explicit if desired or necessary\n","        // job.setMapOutputKeyClass(Text.class);\n","        // job.setMapOutputValueClass(IntWritable.class);\n","\n","\n","        // 8. Handle input and output paths\n","        if (args.length != 2) {\n","            System.err.println(\"Usage: WordCount <input path> <output path>\");\n","            System.exit(1); // Exit if arguments are incorrect\n","        }\n","\n","        Path inputPath = new Path(args[0]);\n","        Path outputPath = new Path(args[1]);\n","\n","        // Delete output directory if it already exists (useful for testing)\n","        FileSystem fs = FileSystem.get(URI.create(outputPath.toString()), conf);\n","        if (fs.exists(outputPath)) {\n","            fs.delete(outputPath, true); // delete recursively\n","        }\n","\n","        FileInputFormat.addInputPath(job, inputPath);\n","        FileOutputFormat.setOutputPath(job, outputPath);\n","\n","\n","        // 9. Submit the job and wait for it to complete\n","        // job.waitForCompletion(true) submits the job and returns true if successful, false otherwise\n","        return job.waitForCompletion(true) ? 0 : 1;\n","    }\n","\n","    // Main method to run the job using ToolRunner\n","    public static void main(String[] args) throws Exception {\n","        // ToolRunner efficiently runs Tool implementations, handling configuration\n","        int res = ToolRunner.run(new Configuration(), new WordCount(), args);\n","        System.exit(res);\n","    }\n","}\n","# bash\n","#     hdfs dfs -put your_text_file.txt /user/yourname/input/\n","# bash\n","#     hadoop jar your_wordcount.jar com.yourcompany.hadoop.WordCount /user/yourname/input /user/yourname/output_wordcount\n","# bash\n","#     hdfs dfs -ls /user/yourname/output_wordcount\n","#     hdfs dfs -cat /user/yourname/output_wordcount/part-r-00000\n","# a\t12345\n","# the\t67890\n","# word\t567\n","# ..."],"metadata":{"id":"MAGIared7w52"},"execution_count":null,"outputs":[]}]}