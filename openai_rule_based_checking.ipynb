{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMidAkk2ErfalRfTqwPwCJf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"US5EpU-1pwOQ","executionInfo":{"status":"ok","timestamp":1748916348465,"user_tz":420,"elapsed":22232,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"587d87e5-e4eb-40e3-da22-a53756e4ca90"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"C9AFRvCGY-Sm","executionInfo":{"status":"ok","timestamp":1748916350417,"user_tz":420,"elapsed":1942,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}}},"outputs":[],"source":["import os\n","from openai import OpenAI\n","import pandas as pd\n","import time\n","import openai"]},{"cell_type":"code","source":["df= pd.read_csv(\"/content/drive/MyDrive/Stanford NLP/dataset.csv\")\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":804},"id":"njSsAU8Dw3YL","executionInfo":{"status":"ok","timestamp":1748916360697,"user_tz":420,"elapsed":10278,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"9a1a214c-74e2-42ce-b39c-8176865c3ab4"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Task  \\\n","0  Write a Python function using TensorFlow to cr...   \n","1  Write a Python script using PyTorch to train a...   \n","2  Create a scikit-learn pipeline that generates ...   \n","3  Write a Python function that uses Hugging Face...   \n","4  Build a TensorFlow model for image classificat...   \n","5  Write a PyTorch class that subclasses torch.ut...   \n","6  Write a Python script that loads the Iris data...   \n","7  Write a Java program using the Hadoop MapReduc...   \n","\n","                                                Code  \\\n","0  import tensorflow as tf\\nfrom tensorflow impor...   \n","1  import torch\\nimport torch.nn as nn\\nimport to...   \n","2  from sklearn.datasets import make_classificati...   \n","3  from transformers import AutoTokenizer\\nfrom t...   \n","4  import tensorflow as tf\\nimport numpy as np\\n\\...   \n","5  from torch.utils.data import Dataset\\nfrom tor...   \n","6  \\nfrom sklearn import datasets\\nfrom sklearn.d...   \n","7  Mapper Code\\nimport java.io.IOException;      ...   \n","\n","                                             API doc  \\\n","0  import tensorflow as tf\\nfrom tensorflow impor...   \n","1  import torch.nn as nn\\nimport torch.optim as o...   \n","2  from sklearn.datasets import make_classificati...   \n","3  from transformers import AutoTokenizer\\nfrom t...   \n","4  import tensorflow as tf\\nimport numpy as np\\nt...   \n","5  from torch.utils.data import Dataset\\nfrom tor...   \n","6  \\nfrom sklearn import datasets\\nfrom sklearn.d...   \n","7                                                NaN   \n","\n","                                         Few shot t1  \\\n","0  Create a python script that uses tensorflow to...   \n","1  Write a Python script using PyTorch to train a...   \n","2  Create a scikit learn pipeline that builds sta...   \n","3  In this example we learn to identify past vs p...   \n","4  Build an image recognition tensorflow model to...   \n","5  Write a PyTorch class that creates custom data...   \n","6  Write a Python script that loads the UCI handw...   \n","7  Write a Java program using the Hadoop MapReduc...   \n","\n","                                         Few shot c1  \\\n","0  \\nimport numpy as np\\nimport tensorflow as tf\\...   \n","1  import numpy as np\\nimport pandas as pd\\nimpor...   \n","2  from sklearn.pipeline import Pipeline\\nfrom sk...   \n","3  \\nfrom typing import Callable, Dict, Sequence,...   \n","4  import matplotlib.pyplot as plt \\nimport numpy...   \n","5  \\nimport os\\nimport pandas as pd\\nfrom torchvi...   \n","6  import matplotlib.pyplot as plt\\nimport numpy ...   \n","7  import java.io.IOException;\\nimport java.util....   \n","\n","                                         Few shot t2  \\\n","0  Write a Python function using TensorFlow to cr...   \n","1  Write a Python script using PyTorch to train a...   \n","2  Create a scikit learn pipeline that builds sta...   \n","3  Write a python function that uses hugging face...   \n","4  Create an image classification model using ten...   \n","5  Write a PyTorch class that subclasses torch.ut...   \n","6  Write a Python script that uses the dataset gi...   \n","7  Write a Java program using the Hadoop MapReduc...   \n","\n","                                         Few shot c2 Unnamed: 7  \n","0  pip install -q seaborn\\n\\nimport matplotlib.py...        NaN  \n","1  from torch.nn import Module\\nfrom torch.nn imp...         \\n  \n","2  from sklearn.pipeline import Pipeline\\nfrom sk...        NaN  \n","3  \\nimport gradio as gr\\nfrom transformers impor...        NaN  \n","4  import tensorflow as tf   \\n\\n# Display the ve...        NaN  \n","5  import torch\\nfrom torch.utils.data import Dat...        NaN  \n","6  import numpy as np\\nimport pandas as pd\\nfrom ...        NaN  \n","7  package hadoop; \\n\\nimport java.util.*; \\n\\nim...         \\n  "],"text/html":["\n","  <div id=\"df-dde622bd-3165-47e7-83e5-810d3b9bc2c1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Task</th>\n","      <th>Code</th>\n","      <th>API doc</th>\n","      <th>Few shot t1</th>\n","      <th>Few shot c1</th>\n","      <th>Few shot t2</th>\n","      <th>Few shot c2</th>\n","      <th>Unnamed: 7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Write a Python function using TensorFlow to cr...</td>\n","      <td>import tensorflow as tf\\nfrom tensorflow impor...</td>\n","      <td>import tensorflow as tf\\nfrom tensorflow impor...</td>\n","      <td>Create a python script that uses tensorflow to...</td>\n","      <td>\\nimport numpy as np\\nimport tensorflow as tf\\...</td>\n","      <td>Write a Python function using TensorFlow to cr...</td>\n","      <td>pip install -q seaborn\\n\\nimport matplotlib.py...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Write a Python script using PyTorch to train a...</td>\n","      <td>import torch\\nimport torch.nn as nn\\nimport to...</td>\n","      <td>import torch.nn as nn\\nimport torch.optim as o...</td>\n","      <td>Write a Python script using PyTorch to train a...</td>\n","      <td>import numpy as np\\nimport pandas as pd\\nimpor...</td>\n","      <td>Write a Python script using PyTorch to train a...</td>\n","      <td>from torch.nn import Module\\nfrom torch.nn imp...</td>\n","      <td>\\n</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Create a scikit-learn pipeline that generates ...</td>\n","      <td>from sklearn.datasets import make_classificati...</td>\n","      <td>from sklearn.datasets import make_classificati...</td>\n","      <td>Create a scikit learn pipeline that builds sta...</td>\n","      <td>from sklearn.pipeline import Pipeline\\nfrom sk...</td>\n","      <td>Create a scikit learn pipeline that builds sta...</td>\n","      <td>from sklearn.pipeline import Pipeline\\nfrom sk...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Write a Python function that uses Hugging Face...</td>\n","      <td>from transformers import AutoTokenizer\\nfrom t...</td>\n","      <td>from transformers import AutoTokenizer\\nfrom t...</td>\n","      <td>In this example we learn to identify past vs p...</td>\n","      <td>\\nfrom typing import Callable, Dict, Sequence,...</td>\n","      <td>Write a python function that uses hugging face...</td>\n","      <td>\\nimport gradio as gr\\nfrom transformers impor...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Build a TensorFlow model for image classificat...</td>\n","      <td>import tensorflow as tf\\nimport numpy as np\\n\\...</td>\n","      <td>import tensorflow as tf\\nimport numpy as np\\nt...</td>\n","      <td>Build an image recognition tensorflow model to...</td>\n","      <td>import matplotlib.pyplot as plt \\nimport numpy...</td>\n","      <td>Create an image classification model using ten...</td>\n","      <td>import tensorflow as tf   \\n\\n# Display the ve...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Write a PyTorch class that subclasses torch.ut...</td>\n","      <td>from torch.utils.data import Dataset\\nfrom tor...</td>\n","      <td>from torch.utils.data import Dataset\\nfrom tor...</td>\n","      <td>Write a PyTorch class that creates custom data...</td>\n","      <td>\\nimport os\\nimport pandas as pd\\nfrom torchvi...</td>\n","      <td>Write a PyTorch class that subclasses torch.ut...</td>\n","      <td>import torch\\nfrom torch.utils.data import Dat...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Write a Python script that loads the Iris data...</td>\n","      <td>\\nfrom sklearn import datasets\\nfrom sklearn.d...</td>\n","      <td>\\nfrom sklearn import datasets\\nfrom sklearn.d...</td>\n","      <td>Write a Python script that loads the UCI handw...</td>\n","      <td>import matplotlib.pyplot as plt\\nimport numpy ...</td>\n","      <td>Write a Python script that uses the dataset gi...</td>\n","      <td>import numpy as np\\nimport pandas as pd\\nfrom ...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Write a Java program using the Hadoop MapReduc...</td>\n","      <td>Mapper Code\\nimport java.io.IOException;      ...</td>\n","      <td>NaN</td>\n","      <td>Write a Java program using the Hadoop MapReduc...</td>\n","      <td>import java.io.IOException;\\nimport java.util....</td>\n","      <td>Write a Java program using the Hadoop MapReduc...</td>\n","      <td>package hadoop; \\n\\nimport java.util.*; \\n\\nim...</td>\n","      <td>\\n</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dde622bd-3165-47e7-83e5-810d3b9bc2c1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-dde622bd-3165-47e7-83e5-810d3b9bc2c1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-dde622bd-3165-47e7-83e5-810d3b9bc2c1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-58cadcd2-1e18-4fea-9c7c-cfbb06c04db9\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58cadcd2-1e18-4fea-9c7c-cfbb06c04db9')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-58cadcd2-1e18-4fea-9c7c-cfbb06c04db9 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_12107020-0aa1-416d-8601-ab9ac5c78aa6\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_12107020-0aa1-416d-8601-ab9ac5c78aa6 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Task\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Write a Python script using PyTorch to train a convolutional neural network (CNN) on the Cifar 10 dataset. Include data loading, model definition, training loop, and evaluation\",\n          \"Write a PyTorch class that subclasses torch.utils.data.Dataset to load image files and labels from a folder. Use this class with a DataLoader for batching. Use FashionMNIST dataset.\",\n          \"Write a Python function using TensorFlow to create and compile a simple linear regression model with one dense layer. Train it on the classic California housing dataset.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"import torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\nimport torchvision\\nimport torchvision.transforms as transforms\\nimport torch.nn.functional as F\\n\\ntransform = transforms.Compose(\\n    [transforms.ToTensor(),\\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\\n\\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\\n                                        download=True, transform=transform)\\n                                        \\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\\n                                          shuffle=True, num_workers=2)\\n\\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\\n                                       download=True, transform=transform)\\n                                       \\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\\n                                         shuffle=False, num_workers=2)\\n\\nclasses = ('plane', 'car', 'bird', 'cat',\\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\\n\\nclass Net(nn.Module):\\n    def __init__(self):\\n        super(Net, self).__init__()\\n        self.conv1 = nn.Conv2d(3, 6, 5)\\n        self.pool = nn.MaxPool2d(2, 2)\\n        self.conv2 = nn.Conv2d(6, 16, 5)\\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\\n        self.fc2 = nn.Linear(120, 84)\\n        self.fc3 = nn.Linear(84, 10)\\n\\n    def forward(self, x):\\n        x = self.pool(F.relu(self.conv1(x)))\\n        x = self.pool(F.relu(self.conv2(x)))\\n        x = x.view(-1, 16 * 5 * 5)\\n        x = F.relu(self.fc1(x))\\n        x = F.relu(self.fc2(x))\\n        x = self.fc3(x)\\n        return x\\n\\nnet = Net()\\n\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\\n\\nfor epoch in range(2):  \\n\\n    running_loss = 0.0\\n    for i, data in enumerate(trainloader, 0):\\n        inputs, labels = data\\n\\n        optimizer.zero_grad()\\n\\n        outputs = net(inputs)\\n        loss = criterion(outputs, labels)\\n        loss.backward()\\n        optimizer.step()\\n\\n        running_loss += loss.item()\\n        if i % 2000 == 1999: \\n            print('[%d, %5d] loss: %.3f' %\\n                  (epoch + 1, i + 1, running_loss / 2000))\\n            running_loss = 0.0\\n\\ncorrect = 0\\ntotal = 0\\nwith torch.no_grad():\\n    for data in testloader:\\n        images, labels = data\\n        outputs = net(images)\\n        _, predicted = torch.max(outputs.data, 1)\\n        total += labels.size(0)\\n        correct += (predicted == labels).sum().item()\\n\\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\\n    100 * correct / total))\",\n          \"from torch.utils.data import Dataset\\nfrom torchvision import datasets\\nfrom torchvision.transforms import ToTensor\\nfrom torch.utils.data import DataLoader\\n\\n\\ntraining_data = datasets.FashionMNIST(\\n    root=\\\"data\\\",\\n    train=True,\\n    download=True,\\n    transform=ToTensor()\\n)\\n\\ntest_data = datasets.FashionMNIST(\\n    root=\\\"data\\\",\\n    train=False,\\n    download=True,\\n    transform=ToTensor()\\n)\\n\\ntrain_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\\ntest_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\",\n          \"import tensorflow as tf\\nfrom tensorflow import keras\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Input, Concatenate\\n\\nfrom sklearn.datasets import fetch_california_housing\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nimport matplotlib.pyplot as plt\\n\\nimport numpy as np\\nimport pandas as pd\\nhousing = fetch_california_housing()\\nXtrain, Xtest, ytrain, ytest = train_test_split(housing.data, housing.target, test_size = .2)\\nXtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=.2)\\n\\nmodel = Sequential([\\n    Dense(30, activation = 'relu', input_shape= Xtrain.shape[1:]),\\n    Dense(1)\\n])\\n\\nmodel.compile(loss='mean_squared_error', optimizer='adam')\\n\\n\\nhistory = model.fit(Xtrain, ytrain, validation_data=(Xval, yval), epochs=20)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"API doc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"import tensorflow as tf\\nfrom tensorflow import keras\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Input, Concatenate\\n\\nfrom sklearn.datasets import fetch_california_housing\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nimport matplotlib.pyplot as plt\\n\\nimport numpy as np\\nimport pandas as pd\\n\",\n          \"import torch.nn as nn\\nimport torch.optim as optim\\nimport torchvision\\nimport torchvision.transforms as transforms\\nimport torch.nn.functional as F\\ntransforms.Compose\\ntorchvision.datasets.CIFAR10\\ntorch.utils.data.DataLoader\\nnn.Conv2d\\nnn.MaxPool2d\\nnn.Linear\\nF.relu\\nnn.CrossEntropyLoss\\noptim.SGD\\n\",\n          \"from torch.utils.data import Dataset\\nfrom torchvision import datasets\\nfrom torchvision.transforms import ToTensor\\nfrom torch.utils.data import DataLoader\\ndatasets.FashionMNIST\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Few shot t1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Write a Python script using PyTorch to train a convolutional neural network (CNN) on the MNIST dataset. Include data loading, model definition, training loop, and evaluation\",\n          \"Write a PyTorch class that creates custom dataset. It takes in input of img dir and annotations csv file.\",\n          \"Create a python script that uses tensorflow to model a linear regression problem using randomly genenrated 50 datat points. You need to train the model and also get the predictions.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Few shot c1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n\\nimport torch\\nfrom torch import optim\\nfrom torch import nn\\nfrom torch.utils.data import DataLoader\\nfrom tqdm import tqdm\\n\\n# !pip install torchvision\\nimport torchvision\\n\\nimport torch.nn.functional as F\\nimport torchvision.datasets as datasets\\nimport torchvision.transforms as transforms\\n\\n# !pip install torchmetrics\\nimport torchmetrics\\n\\nbatch_size = 60\\n\\ntrain_dataset = datasets.MNIST(root=\\\"dataset/\\\", download=True, train=True, transform=transforms.ToTensor())\\n\\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\\n\\ntest_dataset = datasets.MNIST(root=\\\"dataset/\\\", download=True, train=False, transform=transforms.ToTensor())\\n\\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\\n\\nclass CNN(nn.Module):\\n   def __init__(self, in_channels, num_classes):\\n\\n       \\\"\\\"\\\"\\n       Building blocks of convolutional neural network.\\n\\n       Parameters:\\n           * in_channels: Number of channels in the input image (for grayscale images, 1)\\n           * num_classes: Number of classes to predict. In our problem, 10 (i.e digits from  0 to 9).\\n       \\\"\\\"\\\"\\n       super(CNN, self).__init__()\\n\\n       # 1st convolutional layer\\n       self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=3, padding=1)\\n       # Max pooling layer\\n       self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\\n       # 2nd convolutional layer\\n       self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\\n       # Fully connected layer\\n       self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\\n\\n   def forward(self, x):\\n       \\\"\\\"\\\"\\n       Define the forward pass of the neural network.\\n\\n       Parameters:\\n           x: Input tensor.\\n\\n       Returns:\\n           torch.Tensor\\n               The output tensor after passing through the network.\\n       \\\"\\\"\\\"\\n       x = F.relu(self.conv1(x))  # Apply first convolution and ReLU activation\\n       x = self.pool(x)           # Apply max pooling\\n       x = F.relu(self.conv2(x))  # Apply second convolution and ReLU activation\\n       x = self.pool(x)           # Apply max pooling\\n       x = x.reshape(x.shape[0], -1)  # Flatten the tensor\\n       x = self.fc1(x)            # Apply fully connected layer\\n       return x\\n       x = x.reshape(x.shape[0], -1)  # Flatten the tensor\\n       x = self.fc1(x)            # Apply fully connected layer\\n       return x\\n\\n# Define the loss function\\ncriterion = nn.CrossEntropyLoss()\\n\\n# Define the optimizer\\noptimizer = optim.Adam(model.parameters(), lr=0.001)\\n\\nnum_epochs=10\\nfor epoch in range(num_epochs):\\n # Iterate over training batches\\n   print(f\\\"Epoch [{epoch + 1}/{num_epochs}]\\\")\\n\\n   for batch_index, (data, targets) in enumerate(tqdm(dataloader_train)):\\n       data = data.to(device)\\n       targets = targets.to(device)\\n       scores = model(data)\\n       loss = criterion(scores, targets)\\n       optimizer.zero_grad()\\n       loss.backward()\\n       optimizer.step()\\n# Set up of multiclass accuracy metric\\nacc = Accuracy(task=\\\"multiclass\\\",num_classes=10)\\n\\n# Iterate over the dataset batches\\nmodel.eval()\\nwith torch.no_grad():\\n   for images, labels in dataloader_test:\\n       # Get predicted probabilities for test data batch\\n       outputs = model(images)\\n       _, preds = torch.max(outputs, 1)\\n       acc(preds, labels)\\n       precision(preds, labels)\\n       recall(preds, labels)\\n\\n#Compute total test accuracy\\ntest_accuracy = acc.compute()\\nprint(f\\\"Test accuracy: {test_accuracy}\\\")\\n\",\n          \"\\nimport os\\nimport pandas as pd\\nfrom torchvision.io import read_image\\n\\nclass CustomImageDataset(Dataset):\\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\\n        self.img_labels = pd.read_csv(annotations_file)\\n        self.img_dir = img_dir\\n        self.transform = transform\\n        self.target_transform = target_transform\\n\\n    def __len__(self):\\n        return len(self.img_labels)\\n\\n    def __getitem__(self, idx):\\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\\n        image = read_image(img_path)\\n        label = self.img_labels.iloc[idx, 1]\\n        if self.transform:\\n            image = self.transform(image)\\n        if self.target_transform:\\n            label = self.target_transform(label)\\n        return image, label\\n\",\n          \"\\nimport numpy as np\\nimport tensorflow as tf\\nimport matplotlib.pyplot as plt\\n\\nnp.random.seed(101)\\n\\n# Generating random linear data\\n# There will be 50 data points ranging from 0 to 50\\nx = np.linspace(0, 50, 50)\\ny = np.linspace(0, 50, 50)\\n\\n# Adding noise to the random linear data\\nx += np.random.uniform(-4, 4, 50)\\ny += np.random.uniform(-4, 4, 50)\\n\\nn = len(x) # Number of data points\\n\\n# Plot of Training Data\\nplt.scatter(x, y)\\nplt.xlabel('x')\\nplt.ylabel('y')\\nplt.title(\\\"Training Data\\\")\\nplt.show()\\n\\nX = tf.placeholder(\\\"float\\\")\\nY = tf.placeholder(\\\"float\\\")\\n\\nW = tf.Variable(np.random.randn(), name = \\\"W\\\")\\nb = tf.Variable(np.random.randn(), name = \\\"b\\\")\\n\\nlearning_rate = 0.01\\ntraining_epochs = 1000\\n# Hypothesis\\ny_pred = tf.add(tf.multiply(X, W), b)\\n\\n# Mean Squared Error Cost Function\\ncost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n)\\n\\n# Gradient Descent Optimizer\\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\\n\\n# Global Variables Initializer\\ninit = tf.global_variables_initializer()\\n\\n# Starting the Tensorflow Session\\nwith tf.Session() as sess:\\n    \\n    # Initializing the Variables\\n    sess.run(init)\\n    \\n    # Iterating through all the epochs\\n    for epoch in range(training_epochs):\\n        \\n        # Feeding each data point into the optimizer using Feed Dictionary\\n        for (_x, _y) in zip(x, y):\\n            sess.run(optimizer, feed_dict = {X : _x, Y : _y})\\n        \\n        # Displaying the result after every 50 epochs\\n        if (epoch + 1) % 50 == 0:\\n            # Calculating the cost a every epoch\\n            c = sess.run(cost, feed_dict = {X : x, Y : y})\\n            print(\\\"Epoch\\\", (epoch + 1), \\\": cost =\\\", c, \\\"W =\\\", sess.run(W), \\\"b =\\\", sess.run(b))\\n    \\n    # Storing necessary values to be used outside the Session\\n    training_cost = sess.run(cost, feed_dict ={X: x, Y: y})\\n    weight = sess.run(W)\\n    bias = sess.run(b)\\n\\n# Calculating the predictions\\npredictions = weight * x + bias\\nprint(\\\"Training cost =\\\", training_cost, \\\"Weight =\\\", weight, \\\"bias =\\\", bias, '\\\\n')\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Few shot t2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Write a Python script using PyTorch to train a convolutional neural network (CNN) on the KMNIST dataset. Include data loading, model definition, training loop, and evaluation\",\n          \"Write a PyTorch class that subclasses torch.utils.data.Dataset to load 100 image files and labels from a folder. The data would be randomly created and the class should also be defined such that its a custom class.Use this class with a DataLoader for batching. \",\n          \"Write a Python function using TensorFlow to create and compile a simple linear regression model which has a normalizer layer and a dense layer. Train it on the fuel efficiency dataset.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Few shot c2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"from torch.nn import Module\\nfrom torch.nn import Conv2d\\nfrom torch.nn import Linear\\nfrom torch.nn import MaxPool2d\\nfrom torch.nn import ReLU\\nfrom torch.nn import LogSoftmax\\nfrom torch import flatten\\nimport matplotlib\\nmatplotlib.use(\\\"Agg\\\")\\nfrom pyimagesearch.lenet import LeNet\\nfrom sklearn.metrics import classification_report\\nfrom torch.utils.data import random_split\\nfrom torch.utils.data import DataLoader\\nfrom torchvision.transforms import ToTensor\\nfrom torchvision.datasets import KMNIST\\nfrom torch.optim import Adam\\nfrom torch import nn\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport argparse\\nimport torch\\nimport time\\n\\nclass LeNet(Module):\\n        def __init__(self, numChannels, classes):\\n                # call the parent constructor\\n                super(LeNet, self).__init__()\\n                # initialize first set of CONV => RELU => POOL layers\\n                self.conv1 = Conv2d(in_channels=numChannels, out_channels=20,\\n                        kernel_size=(5, 5))\\n                self.relu1 = ReLU()\\n                self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\\n                # initialize second set of CONV => RELU => POOL layers\\n                self.conv2 = Conv2d(in_channels=20, out_channels=50,\\n                        kernel_size=(5, 5))\\n                self.relu2 = ReLU()\\n                self.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\\n                # initialize first (and only) set of FC => RELU layers\\n                self.fc1 = Linear(in_features=800, out_features=500)\\n                self.relu3 = ReLU()\\n                # initialize our softmax classifier\\n                self.fc2 = Linear(in_features=500, out_features=classes)\\n                self.logSoftmax = LogSoftmax(dim=1)\\n\\ndef forward(self, x):\\n                # pass the input through our first set of CONV => RELU =>\\n                # POOL layers\\n                x = self.conv1(x)\\n                x = self.relu1(x)\\n                x = self.maxpool1(x)\\n                # pass the output from the previous layer through the second\\n                # set of CONV => RELU => POOL layers\\n                x = self.conv2(x)\\n                x = self.relu2(x)\\n                x = self.maxpool2(x)\\n                # flatten the output from the previous layer and pass it\\n                # through our only set of FC => RELU layers\\n                x = flatten(x, 1)\\n                x = self.fc1(x)\\n                x = self.relu3(x)\\n                # pass the output to our softmax classifier to get our output\\n                # predictions\\n                x = self.fc2(x)\\n                output = self.logSoftmax(x)\\n                # return the output predictions\\n                return output\\n# construct the argument parser and parse the arguments\\nap = argparse.ArgumentParser()\\nap.add_argument(\\\"-m\\\", \\\"--model\\\", type=str, required=True,\\n        help=\\\"path to output trained model\\\")\\nap.add_argument(\\\"-p\\\", \\\"--plot\\\", type=str, required=True,\\n        help=\\\"path to output loss/accuracy plot\\\")\\nargs = vars(ap.parse_args())\\n\\nPyTorch: Training your first Convolutional Neural Network (CNN)\\n# define training hyperparameters\\nINIT_LR = 1e-3\\nBATCH_SIZE = 64\\nEPOCHS = 10\\n# define the train and val splits\\nTRAIN_SPLIT = 0.75\\nVAL_SPLIT = 1 - TRAIN_SPLIT\\n# set the device we will be using to train the model\\ndevice = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n\\n# load the KMNIST dataset\\nprint(\\\"[INFO] loading the KMNIST dataset...\\\")\\ntrainData = KMNIST(root=\\\"data\\\", train=True, download=True,\\n        transform=ToTensor())\\ntestData = KMNIST(root=\\\"data\\\", train=False, download=True,\\n        transform=ToTensor())\\n# calculate the train/validation split\\nprint(\\\"[INFO] generating the train/validation split...\\\")\\nnumTrainSamples = int(len(trainData) * TRAIN_SPLIT)\\nnumValSamples = int(len(trainData) * VAL_SPLIT)\\n(trainData, valData) = random_split(trainData,\\n        [numTrainSamples, numValSamples],\\n        generator=torch.Generator().manual_seed(42))\\n\\n# initialize the train, validation, and test data loaders\\ntrainDataLoader = DataLoader(trainData, shuffle=True,\\n        batch_size=BATCH_SIZE)\\nvalDataLoader = DataLoader(valData, batch_size=BATCH_SIZE)\\ntestDataLoader = DataLoader(testData, batch_size=BATCH_SIZE)\\n# calculate steps per epoch for training and validation set\\ntrainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\\nvalSteps = len(valDataLoader.dataset) // BATCH_SIZE\\n\\n# initialize the LeNet model\\nprint(\\\"[INFO] initializing the LeNet model...\\\")\\nmodel = LeNet(\\n        numChannels=1,\\n        classes=len(trainData.dataset.classes)).to(device)\\n# initialize our optimizer and loss function\\nopt = Adam(model.parameters(), lr=INIT_LR)\\nlossFn = nn.NLLLoss()\\n# initialize a dictionary to store training history\\nH = {\\n        \\\"train_loss\\\": [],\\n        \\\"train_acc\\\": [],\\n        \\\"val_loss\\\": [],\\n        \\\"val_acc\\\": []\\n}\\n# measure how long training is going to take\\nprint(\\\"[INFO] training the network...\\\")\\n\\n# loop over our epochs\\nfor e in range(0, EPOCHS):\\n        # set the model in training mode\\n        model.train()\\n        # initialize the total training and validation loss\\n        totalTrainLoss = 0\\n        totalValLoss = 0\\n        # initialize the number of correct predictions in the training\\n        # and validation step\\n        trainCorrect = 0\\n        valCorrect = 0\\n        # loop over the training set\\n        for (x, y) in trainDataLoader:\\n                # send the input to the device\\n                (x, y) = (x.to(device), y.to(device))\\n                # perform a forward pass and calculate the training loss\\n                pred = model(x)\\n                loss = lossFn(pred, y)\\n                # zero out the gradients, perform the backpropagation step,\\n                # and update the weights\\n                opt.zero_grad()\\n                loss.backward()\\n                opt.step()\\n                # add the loss to the total training loss so far and\\n                # calculate the number of correct predictions\\n                totalTrainLoss += loss\\n                trainCorrect += (pred.argmax(1) == y).type(\\n                        torch.float).sum().item()\\n\\n        # switch off autograd for evaluation\\n        with torch.no_grad():\\n                # set the model in evaluation mode\\n                model.eval()\\n                # loop over the validation set\\n                for (x, y) in valDataLoader:\\n                        # send the input to the device\\n                        (x, y) = (x.to(device), y.to(device))\\n                        # make the predictions and calculate the validation loss\\n                        pred = model(x)\\n                        totalValLoss += lossFn(pred, y)\\n                        # calculate the number of correct predictions\\n                        valCorrect += (pred.argmax(1) == y).type(\\n                                torch.float).sum().item()\\n\\n        # calculate the average training and validation loss\\n        avgTrainLoss = totalTrainLoss / trainSteps\\n        avgValLoss = totalValLoss / valSteps\\n        # calculate the training and validation accuracy\\n        trainCorrect = trainCorrect / len(trainDataLoader.dataset)\\n        valCorrect = valCorrect / len(valDataLoader.dataset)\\n        # update our training history\\n        H[\\\"train_loss\\\"].append(avgTrainLoss.cpu().detach().numpy())\\n        H[\\\"train_acc\\\"].append(trainCorrect)\\n        H[\\\"val_loss\\\"].append(avgValLoss.cpu().detach().numpy())\\n        H[\\\"val_acc\\\"].append(valCorrect)\\n        # print the model training and validation information\\n        print(\\\"[INFO] EPOCH: {}/{}\\\".format(e + 1, EPOCHS))\\n        print(\\\"Train loss: {:.6f}, Train accuracy: {:.4f}\\\".format(\\n                avgTrainLoss, trainCorrect))\\n        print(\\\"Val loss: {:.6f}, Val accuracy: {:.4f}\\\\n\\\".format(\\n                avgValLoss, valCorrect))\",\n          \"import torch\\nfrom torch.utils.data import Dataset, DataLoader\\nimport torch.nn as nn\\nimport torch.optim as optim\\nimport numpy as np\\n\\n# Custom Dataset class\\nclass CustomDataset(Dataset):\\n    def __init__(self, data, labels):\\n        self.data = data\\n        self.labels = labels\\n\\n    def __len__(self):\\n        return len(self.data)\\n\\n    def __getitem__(self, idx):\\n        sample = self.data[idx]\\n        label = self.labels[idx]\\n        return sample, label\\n\\n# Prepare data\\ndata = np.random.randn(100, 3, 32, 32)  # 100 samples of 3x32x32 images\\nlabels = np.random.randint(0, 10, size=(100,))  # 100 labels in the range 0-9\\n\\n# Create Dataset\\ndataset = CustomDataset(data, labels)\\n\\n# Create DataLoader\\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)\\n\",\n          \"pip install -q seaborn\\n\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd\\nimport seaborn as sns\\n\\n# Make NumPy printouts easier to read.\\nnp.set_printoptions(precision=3, suppress=True)\\nimport tensorflow as tf\\n\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\n\\nprint(tf.__version__)\\n\\nurl = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\\ncolumn_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\\n                'Acceleration', 'Model Year', 'Origin']\\n\\nraw_dataset = pd.read_csv(url, names=column_names,\\n                          na_values='?', comment='\\\\t',\\n                          sep=' ', skipinitialspace=True)\\n\\ndataset = raw_dataset.copy()\\ndataset.tail()\\n\\ndataset.isna().sum()\\n\\ndataset = dataset.dropna()\\n\\ndataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\\n\\ndataset = pd.get_dummies(dataset, columns=['Origin'], prefix='', prefix_sep='')\\ndataset.tail()\\n\\ntrain_dataset = dataset.sample(frac=0.8, random_state=0)\\ntest_dataset = dataset.drop(train_dataset.index)\\n\\ntrain_features = train_dataset.copy()\\ntest_features = test_dataset.copy()\\n\\ntrain_labels = train_features.pop('MPG')\\ntest_labels = test_features.pop('MPG')\\n\\nhorsepower = np.array(train_features['Horsepower'])\\n\\nhorsepower_normalizer = layers.Normalization(input_shape=[1,], axis=None)\\nhorsepower_normalizer.adapt(horsepower)\\n\\nhorsepower_model = tf.keras.Sequential([\\n    horsepower_normalizer,\\n    layers.Dense(units=1)\\n])\\n\\nhorsepower_model.summary()\\n\\nhorsepower_model.compile(\\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\\n    loss='mean_absolute_error')\\n\\n\\nhistory = horsepower_model.fit(\\n    train_features['Horsepower'],\\n    train_labels,\\n    epochs=100,\\n    # Suppress logging.\\n    verbose=0,\\n    # Calculate validation results on 20% of the training data.\\n    validation_split = 0.2)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 7\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["tasks=df['Task'].to_list()\n","tasks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OATUQ9YAx-FA","executionInfo":{"status":"ok","timestamp":1748916360698,"user_tz":420,"elapsed":6,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"4136043f-9513-470a-be93-143ffa50a3a3"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Write a Python function using TensorFlow to create and compile a simple linear regression model with one dense layer. Train it on the classic California housing dataset.\\n',\n"," 'Write a Python script using PyTorch to train a convolutional neural network (CNN) on the Cifar 10 dataset. Include data loading, model definition, training loop, and evaluation',\n"," 'Create a scikit-learn pipeline that generates a random n-class classification problem and creates a pipeline to compute the mean and standard deviation on a training set so as to be able to later re-apply the same transformation on the testing set. Train the model Fit the dataset using the same pipeline and compute score on the test set. ',\n"," 'Write a Python function that uses Hugging Face to train a model(distilbert/distilbert-base-uncaseddistilbert/distilbert-base-uncased) using the IMDb Reviews dataset. Its  binary classification task. Involve any necessary preprocessing steps if required.',\n"," 'Build a TensorFlow model for image classification using the Fashion MNIST dataset and integrate early stopping and model checkpoint callbacks during training.',\n"," 'Write a PyTorch class that subclasses torch.utils.data.Dataset to load image files and labels from a folder. Use this class with a DataLoader for batching. Use FashionMNIST dataset.',\n"," 'Write a Python script that loads the Iris dataset, reduces its dimensionality using PCA, and fits a k-nearest neighbors classifier using scikit-learn.',\n"," 'Write a Java program using the Hadoop MapReduce API to count the frequency of each word in a large text file, such as a sample from Project Gutenberg.']"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"U_TZS9vXixKg","executionInfo":{"status":"ok","timestamp":1748916361493,"user_tz":420,"elapsed":796,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"d69b4a3d-524f-4e93-c7f7-091d6fa072fb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                       neural_gemini\n","0  ```python\\nimport tensorflow as tf\\nfrom sklea...\n","1  ```python\\nimport torch\\nimport torch.nn as nn...\n","2  Okay, here is an API usage pattern using sciki...\n","3  ```python\\nimport torch\\nfrom datasets import ...\n","4  Okay, let's outline the API usage pattern for ...\n","5  ```python\\nimport torch\\nimport torch.utils.da...\n","6  ```python\\nimport matplotlib.pyplot as plt  # ...\n","7  Okay, the provided API structures (`tensorflow..."],"text/html":["\n","  <div id=\"df-30967fa1-0677-4895-81e9-56c24f2b7764\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>neural_gemini</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>```python\\nimport tensorflow as tf\\nfrom sklea...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>```python\\nimport torch\\nimport torch.nn as nn...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Okay, here is an API usage pattern using sciki...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>```python\\nimport torch\\nfrom datasets import ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Okay, let's outline the API usage pattern for ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>```python\\nimport torch\\nimport torch.utils.da...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>```python\\nimport matplotlib.pyplot as plt  # ...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Okay, the provided API structures (`tensorflow...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30967fa1-0677-4895-81e9-56c24f2b7764')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-30967fa1-0677-4895-81e9-56c24f2b7764 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-30967fa1-0677-4895-81e9-56c24f2b7764');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-f577228f-d0cb-4f52-896d-bc01e86b9375\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f577228f-d0cb-4f52-896d-bc01e86b9375')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-f577228f-d0cb-4f52-896d-bc01e86b9375 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_32142534-8f53-4606-94a6-d9162e144364\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_neural')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_32142534-8f53-4606-94a6-d9162e144364 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_neural');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_neural","summary":"{\n  \"name\": \"df_neural\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"neural_gemini\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"```python\\nimport torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\nimport torchvision\\nimport torchvision.transforms as transforms\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n\\n# --- Configuration ---\\n# Using basic Python types (int, float, bool)\\nBATCH_SIZE = 128\\nLEARNING_RATE = 0.001\\nNUM_EPOCHS = 10\\nDEVICE = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\nprint(f\\\"Using device: {DEVICE}\\\")\\n\\n# --- Data Loading ---\\n# Based on DataLoader, Dataset, ToTensor API documentation concepts\\n# We use torchvision.datasets.CIFAR10 which is a subclass of torch.utils.data.Dataset\\n# ToTensor is used for conversion, as described in its documentation.\\n# DataLoader is used for batching, shuffling, and multi-processing.\\n\\n# Define transformations\\n# Using torchvision.transforms\\ntransform = transforms.Compose(\\n    [transforms.ToTensor(), # Uses the ToTensor transform (converts PIL/ndarray to Tensor, scales [0, 255] to [0, 1] for uint8)\\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # Standard normalization for CIFAR10\\n\\n# Load CIFAR10 dataset\\n# Using torchvision.datasets.CIFAR10 (implied Dataset usage)\\n# DataLoader constructor usage with dataset, batch_size, shuffle, num_workers\\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\\n                                        download=True, transform=transform)\\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\\n                                          shuffle=True, num_workers=2)\\n\\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\\n                                       download=True, transform=transform)\\ntestloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\\n                                         shuffle=False, num_workers=2)\\n\\nclasses = ('plane', 'car', 'bird', 'cat',\\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\\n\\n# --- Model Definition ---\\n# Based on the concept of torch.nn.Module and standard CNN layers (though specific layers not documented)\\n# We define a simple CNN by subclassing torch.nn.Module\\n# __init__ method defines the layers, forward method defines the data flow.\\n# Uses Conv2d, MaxPool2d, ReLU, Flatten, Linear layers from torch.nn (standard PyTorch pattern)\\n\\nclass SimpleCNN(nn.Module):\\n    def __init__(self):\\n        # Calls the parent constructor\\n        super(SimpleCNN, self).__init__()\\n        # Define convolutional layers\\n        # Using torch.nn.Conv2d\\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1) # Input channels=3 (RGB), output channels=32\\n        # Using torch.nn.ReLU (activation function)\\n        self.relu = nn.ReLU()\\n        # Using torch.nn.MaxPool2d\\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # Reduces spatial dimensions by half\\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # Input channels=32, output channels=64\\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # Input channels=64, output channels=128\\n\\n        # Define fully connected layers (Dense in Keras, Linear in PyTorch)\\n        # Calculate input size for the first linear layer based on image size (32x32) and pooling\\n        # (32 / 2 / 2 / 2)^2 * 128 channels = (4^2) * 128 = 16 * 128 = 2048\\n        # Using torch.nn.Linear\\n        self.fc1 = nn.Linear(128 * 4 * 4, 512) # Input features based on Conv/Pool output, output features=512\\n        self.fc2 = nn.Linear(512, 10) # Input features=512, output features=10 (for 10 classes)\\n\\n    def forward(self, x):\\n        # Implement the forward pass\\n        # Using torch.nn.functional for functional API like pooling and activation\\n        x = self.pool(self.relu(self.conv1(x)))\\n        x = self.pool(self.relu(self.conv2(x)))\\n        x = self.pool(self.relu(self.conv3(x)))\\n        # Flatten the tensor before passing to fully connected layers\\n        # Using torch.flatten (or x.view/reshape)\\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\\n        x = self.relu(self.fc1(x))\\n        x = self.fc2(x) # Output layer, no activation here (CrossEntropyLoss includes Softmax)\\n        return x\\n\\n# Instantiate the model and move it to the chosen device\\nmodel = SimpleCNN()\\n# Using Tensor.to(device) method\\nmodel.to(DEVICE)\\n\\n# --- Loss Function and Optimizer ---\\n# Using standard PyTorch loss function and optimizer (specific classes not documented)\\n# Using torch.nn.CrossEntropyLoss (loss function)\\ncriterion = nn.CrossEntropyLoss()\\n# Using torch.optim package concept (Optimizer instantiation and methods)\\n# Using Adam optimizer from torch.optim and its constructor with model parameters and learning rate\\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\\n\\n# --- Training Loop ---\\n# Iterates over DataLoader, performs forward/backward passes, updates weights.\\n\\nprint(\\\"Starting training...\\\")\\nfor epoch in range(NUM_EPOCHS):  # Loop over the dataset multiple times\\n    # Set model to training mode\\n    # Using torch.nn.Module.train() method\\n    model.train()\\n    running_loss = 0.0\\n    # Iterate over the DataLoader (using its iterable behavior)\\n    for i, data in enumerate(trainloader, 0):\\n        # Get the inputs; data is a list of [inputs, labels]\\n        inputs, labels = data\\n        # Move data to the appropriate device\\n        # Using Tensor.to(device) method\\n        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\\n\\n        # Zero the parameter gradients\\n        # Using optimizer.zero_grad() method (part of torch.optim interface)\\n        optimizer.zero_grad()\\n\\n        # Forward pass\\n        # Calling the model instance (which calls the forward method)\\n        outputs = model(inputs)\\n        # Calculate loss\\n        # Using the criterion (nn.CrossEntropyLoss instance)\\n        loss = criterion(outputs, labels)\\n\\n        # Backward pass\\n        # Using Tensor.backward() method\\n        loss.backward()\\n        # Optimize\\n        # Using optimizer.step() method (part of torch.optim interface)\\n        optimizer.step()\\n\\n        # Print statistics\\n        # Using Tensor.item() method to get scalar value\\n        running_loss += loss.item()\\n        if i % 100 == 99:    # print every 100 mini-batches\\n            print(f'Epoch {epoch + 1}, Batch {i + 1}: loss = {running_loss / 100:.3f}')\\n            running_loss = 0.0\\n\\nprint('Finished Training')\\n\\n# --- Evaluation ---\\n# Iterates over test DataLoader, calculates accuracy.\\n\\nprint(\\\"Starting evaluation...\\\")\\n# Set model to evaluation mode\\n# Using torch.nn.Module.eval() method\\nmodel.eval()\\ncorrect = 0\\ntotal = 0\\n# Disable gradient calculation during evaluation\\n# Using torch.no_grad() context manager\\nwith torch.no_grad():\\n    # Iterate over the test DataLoader\\n    for data in testloader:\\n        images, labels = data\\n        # Move data to device\\n        # Using Tensor.to(device) method\\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\\n        # Forward pass (inference)\\n        outputs = model(images)\\n        # Get predictions\\n        # Using Tensor.argmax() method to find the index of the max value (predicted class)\\n        # Using Tensor.to(device).cpu() if necessary to move to CPU for numpy conversion or other operations\\n        _, predicted = torch.max(outputs.data, 1)\\n        # Calculate total samples\\n        # Using Tensor.size() method\\n        total += labels.size(0)\\n        # Calculate correct predictions\\n        # Using Tensor comparison (==) and sum() method\\n        correct += (predicted == labels).sum().item() # Using item() to get scalar\\n\\n# Calculate and print accuracy\\naccuracy = 100 * correct / total\\nprint(f'Accuracy of the network on the 10000 test images: {accuracy:.2f} %')\\n\\n# --- Optional: Visualize some predictions ---\\n# Using matplotlib.pyplot (plt alias) for plotting\\ndef imshow(img):\\n    # Unnormalize image for display\\n    img = img / 2 + 0.5     # unnormalize\\n    # Using numpy.transpose and numpy.asarray\\n    npimg = img.numpy()\\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\\n    plt.show()\\n\\n# Get some random test images\\ndataiter = iter(testloader)\\nimages, labels = next(dataiter)\\n\\n# Print images\\n# Using matplotlib.pyplot (plt) and torchvision.utils.make_grid\\n# imshow(torchvision.utils.make_grid(images))\\n# print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(BATCH_SIZE))) # Assuming BATCH_SIZE <= len(images)\\n\\n# Make predictions\\nimages = images.to(DEVICE) # Move to device for inference\\noutputs = model(images)\\n# Using Tensor.max()\\n_, predicted = torch.max(outputs, 1)\\n\\n# Print predictions\\n# print('Predicted:   ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(BATCH_SIZE)))\\n\\n```\",\n          \"```python\\nimport torch\\nimport torch.utils.data as data\\nimport torchvision.datasets as datasets\\nimport torchvision.transforms as transforms\\nimport os\\nfrom PIL import Image\\nfrom pathlib import Path\\nimport numpy as np\\n\\n# --- Step 1: Simulate the folder structure using the actual FashionMNIST data ---\\n# This step is necessary because torchvision.datasets.FashionMNIST loads data\\n# from internal structures (like .gz files) rather than a user-provided folder\\n# structure where labels are determined by directory names.\\n# We will download the data, then save it into the desired folder format.\\n\\ndef save_fashion_mnist_to_folder(root_dir=\\\"fashion_mnist_folder\\\"):\\n    \\\"\\\"\\\"\\n    Downloads FashionMNIST and saves images into a folder structure:\\n    root_dir/label/image_idx.png\\n    \\\"\\\"\\\"\\n    # Define a temporary directory to store the original downloaded data\\n    temp_download_dir = \\\"./fashion_mnist_temp\\\"\\n\\n    # Download the standard FashionMNIST dataset\\n    print(f\\\"Downloading FashionMNIST to {temp_download_dir}...\\\")\\n    train_dataset = datasets.FashionMNIST(root=temp_download_dir, train=True, download=True)\\n    test_dataset = datasets.FashionMNIST(root=temp_download_dir, train=False, download=True)\\n    print(\\\"Download complete.\\\")\\n\\n    # Combine train and test data for saving\\n    all_data = train_dataset.data.numpy()\\n    all_targets = train_dataset.targets.numpy()\\n    all_data = np.concatenate((all_data, test_dataset.data.numpy()), axis=0)\\n    all_targets = np.concatenate((all_targets, test_dataset.targets.numpy()), axis=0)\\n\\n    print(f\\\"Saving FashionMNIST images to folder structure in {root_dir}...\\\")\\n    # Create the root directory if it doesn't exist\\n    Path(root_dir).mkdir(parents=True, exist_ok=True)\\n\\n    # Create subdirectories for each class label\\n    for i in range(10):\\n        class_dir = Path(root_dir) / str(i)\\n        class_dir.mkdir(parents=True, exist_ok=True)\\n\\n    # Save each image\\n    for i in range(len(all_data)):\\n        image_np = all_data[i]\\n        label = all_targets[i]\\n        class_dir = Path(root_dir) / str(label)\\n        image_path = class_dir / f\\\"image_{i:05d}.png\\\" # Use 5 digits for indexing\\n\\n        # Convert numpy array to PIL Image (FashionMNIST is grayscale)\\n        img = Image.fromarray(image_np, mode='L')\\n        img.save(image_path)\\n\\n    print(f\\\"Finished saving {len(all_data)} images.\\\")\\n    # Note: In a real scenario, you might want to remove the temporary download dir\\n    # import shutil\\n    # shutil.rmtree(temp_download_dir)\\n\\n\\n# --- Step 2: Create the custom Dataset class subclasing torch.utils.data.Dataset ---\\n\\n# Based on the Dataset API:\\n# - Subclasses torch.utils.data.Dataset\\n# - Must implement __getitem__(self, index) -> sample\\n# - Should implement __len__(self) -> int (required for default DataLoader options)\\n\\nclass FashionMNISTFolderDataset(data.Dataset):\\n    \\\"\\\"\\\"\\n    Custom Dataset to load FashionMNIST-like images and labels from a folder structure.\\n    Assumes structure: root_dir/label/image_name.png\\n    \\\"\\\"\\\"\\n    def __init__(self, root_dir, transform=None):\\n        \\\"\\\"\\\"\\n        Initializes the dataset by scanning the folder structure.\\n\\n        Args:\\n            root_dir (string): Directory with all the images structured in subfolders.\\n            transform (callable, optional): Optional transform to be applied on a sample.\\n        \\\"\\\"\\\"\\n        self.root_dir = Path(root_dir)\\n        self.transform = transform\\n        self.image_paths = []\\n        self.labels = []\\n        self.classes = [] # Store class names/labels found\\n\\n        # Scan the directory structure\\n        print(f\\\"Scanning images in {self.root_dir}...\\\")\\n        for class_dir in sorted(self.root_dir.iterdir()): # Sort for consistent order\\n            if class_dir.is_dir():\\n                class_name = class_dir.name # Folder name is the class label (as string)\\n                # Attempt to convert class_name to integer label\\n                try:\\n                    label = int(class_name)\\n                    self.classes.append(label)\\n                except ValueError:\\n                    print(f\\\"Warning: Skipping directory '{class_dir}' as it's not an integer label.\\\")\\n                    continue\\n\\n                # Sort image files for consistent order\\n                for img_path in sorted(class_dir.glob(\\\"*.png\\\")): # Assuming .png from simulation\\n                    self.image_paths.append(img_path)\\n                    self.labels.append(label) # Store integer label\\n\\n        if not self.image_paths:\\n            raise RuntimeError(f\\\"Found 0 images in subfolders of {self.root_dir}. \\\"\\n                               \\\"Please ensure the directory structure is correct and contains .png files.\\\")\\n\\n        print(f\\\"Found {len(self.image_paths)} images belonging to {len(self.classes)} classes.\\\")\\n\\n    def __len__(self):\\n        \\\"\\\"\\\"\\n        Returns the total number of samples (images).\\n        Matches the Dataset API requirement for __len__.\\n        \\\"\\\"\\\"\\n        return len(self.image_paths)\\n\\n    def __getitem__(self, idx):\\n        \\\"\\\"\\\"\\n        Loads and returns one sample (image and label) from the dataset at the given index.\\n        Matches the Dataset API requirement for __getitem__.\\n\\n        Args:\\n            idx (int): Index of the sample to load.\\n\\n        Returns:\\n            tuple: (image, label) where image is a Tensor and label is an integer.\\n        \\\"\\\"\\\"\\n        if torch.is_tensor(idx):\\n            idx = idx.tolist()\\n\\n        img_path = self.image_paths[idx]\\n        label = self.labels[idx]\\n\\n        # Load image using Pillow (PIL)\\n        image = Image.open(img_path).convert('L') # FashionMNIST is grayscale ('L')\\n\\n        # Apply transformations\\n        if self.transform:\\n            image = self.transform(image)\\n\\n        return image, label\\n\\n# --- Step 3: Define Transforms ---\\n# We need at least ToTensor. FashionMNIST images are 28x28 grayscale.\\n# ToTensor will convert PIL Image or ndarray (H x W x C) to Tensor (C x H x W)\\n# and scale uint8 [0, 255] to float [0.0, 1.0].\\n# Based on ToTensor API: converts PIL/ndarray to torch.Tensor, scales [0, 255] to [0.0, 1.0].\\n\\n# For grayscale, PIL 'L' mode (8-bit pixels, grayscale) will be scaled.\\n# ToTensor description: \\\"Scales values accordingly for specific input types.\\\"\\n# \\\"PIL Image.Image with modes ['L', ..., '1']\\\" -> scales to [0.0, 1.0]\\n\\nimage_transforms = transforms.Compose([\\n    transforms.ToTensor(), # Converts PIL Image (H, W) to Tensor (1, H, W) and scales [0, 255] to [0.0, 1.0]\\n    # Add other transforms here if needed, e.g.,\\n    # transforms.Normalize((0.5,), (0.5,)) # Normalize grayscale images\\n])\\n\\n# --- Step 4: Use the custom Dataset with DataLoader for batching ---\\n\\n# Based on DataLoader API:\\n# - Combines a dataset and a sampler, provides an iterable over the dataset.\\n# - Constructor takes 'dataset', 'batch_size', 'shuffle', 'num_workers', etc.\\n\\nif __name__ == \\\"__main__\\\":\\n    # Define the root directory for our simulated dataset\\n    simulated_root = \\\"./custom_fashion_mnist_data\\\"\\n\\n    # Simulate the data if it doesn't exist\\n    # Check if any class directory exists, assuming data is saved if any subdir exists\\n    if not any(Path(simulated_root).iterdir()):\\n         save_fashion_mnist_to_folder(simulated_root)\\n    else:\\n         print(f\\\"Data already found in {simulated_root}. Skipping simulation.\\\")\\n\\n\\n    # Instantiate the custom dataset\\n    print(\\\"\\\\nCreating custom dataset...\\\")\\n    try:\\n        custom_dataset = FashionMNISTFolderDataset(root_dir=simulated_root, transform=image_transforms)\\n        print(f\\\"Dataset created with {len(custom_dataset)} samples.\\\")\\n    except RuntimeError as e:\\n        print(f\\\"Error creating dataset: {e}\\\")\\n        print(\\\"Please ensure the simulation step ran correctly or the directory structure is valid.\\\")\\n        exit()\\n\\n\\n    # Define DataLoader parameters\\n    batch_size = 64\\n    shuffle_data = True # Set to True to shuffle data at each epoch\\n    num_workers = 2     # Number of subprocesses for data loading (0 means main process)\\n                        # Based on DataLoader API: num_workers\\n\\n    # Instantiate the DataLoader\\n    print(f\\\"\\\\nCreating DataLoader with batch_size={batch_size}, shuffle={shuffle_data}, num_workers={num_workers}...\\\")\\n    dataloader = data.DataLoader(\\n        dataset=custom_dataset,\\n        batch_size=batch_size,\\n        shuffle=shuffle_data,\\n        num_workers=num_workers,\\n        # pin_memory=True # Often useful for GPU training, based on DataLoader API\\n    )\\n    print(\\\"DataLoader created.\\\")\\n\\n    # --- Step 5: Iterate through the DataLoader to get batches ---\\n\\n    print(\\\"\\\\nIterating through DataLoader for one epoch:\\\")\\n    # The DataLoader is an iterable, as described in the DataLoader API\\n    for i, (images, labels) in enumerate(dataloader):\\n        # 'images' will be a Tensor batch of shape (batch_size, C, H, W)\\n        # 'labels' will be a Tensor batch of shape (batch_size,)\\n        # The batch structure is handled by DataLoader's default collate_fn\\n\\n        print(f\\\"Batch {i+1}:\\\")\\n        print(f\\\"  Images batch shape: {images.shape}\\\")\\n        print(f\\\"  Labels batch shape: {labels.shape}\\\")\\n        print(f\\\"  Image dtype: {images.dtype}\\\")\\n        print(f\\\"  Label dtype: {labels.dtype}\\\")\\n\\n        # Example: Print first few labels in the batch\\n        print(f\\\"  First 5 labels in batch: {labels[:5].tolist()}\\\")\\n\\n        # Stop after a few batches for demonstration\\n        if i >= 2: # Process first 3 batches\\n            break\\n\\n    print(\\\"\\\\nFinished iterating through a few batches.\\\")\\n    print(f\\\"Total batches per epoch: {len(dataloader)}\\\")\\n\\n    # The custom dataset and dataloader can now be used in a standard PyTorch training loop\\n    # e.g., iterate dataloader, pass images to model, compute loss, backprop, etc.\\n\\n```\\n\\n**Explanation:**\\n\\n1.  **Simulate Data (`save_fashion_mnist_to_folder`)**: This is an auxiliary function created specifically to fulfill the \\\"load from a folder\\\" requirement using the FashionMNIST data source. It downloads the standard `torchvision.datasets.FashionMNIST`, then manually saves each image into a directory structure (`root_dir/label_int/image_idx.png`) that our custom dataset can understand. This bridging step is necessary because the standard `FashionMNIST` dataset class doesn't operate by scanning a user-defined folder of loose image files.\\n2.  **`FashionMNISTFolderDataset` Class**:\\n    *   It inherits from `torch.utils.data.Dataset`, as required by the task and indicated by the `Dataset` API documentation.\\n    *   **`__init__`**: This method scans the provided `root_dir`. It iterates through subdirectories (which represent labels), lists all image files within them, and stores their paths and corresponding integer labels in lists (`self.image_paths` and `self.labels`). This pre-processing step is crucial for map-style datasets to know the size of the dataset and quickly retrieve any item by index.\\n    *   **`__len__`**: This method returns the total number of image paths collected. The `Dataset` API specifies that `__len__` is optional but expected by `DataLoader` for default sampler behavior and `len(dataset)` calls.\\n    *   **`__getitem__`**: This is the core method required by the `Dataset` API. Given an `index`, it retrieves the stored image path and label, loads the image using Pillow (`PIL.Image.open`), applies the specified `transform` (like `ToTensor`), and returns the image tensor and the integer label.\\n3.  **Transforms (`image_transforms`)**:\\n    *   We define a `transforms.Compose` which is a common way to chain multiple transformations.\\n    *   `transforms.ToTensor()` is included, as described in the `ToTensor` API. It correctly handles the conversion from a grayscale PIL Image to a PyTorch Tensor and scales the pixel values from the original [0, 255] range to [0.0, 1.0].\\n4.  **DataLoader Usage**:\\n    *   An instance of our custom `FashionMNISTFolderDataset` is created, pointing to the root directory of the simulated data and providing the desired transformations.\\n    *   An instance of `torch.utils.data.DataLoader` is created, as per the `DataLoader` API. We pass our `custom_dataset`, set the `batch_size`, enable `shuffle` to randomize the data order each epoch, and set `num_workers` for potentially faster data loading (though 0 is fine for basic testing).\\n    *   The `DataLoader` object is an iterable. We demonstrate this by looping through it. In each iteration, the `DataLoader` automatically calls our dataset's `__getitem__` for a batch of indices (handled by an internal Sampler), combines the individual samples into tensors (handled by an internal `collate_fn`), and yields the batch (`images`, `labels`).\\n\\nThis pattern effectively demonstrates how to use `torch.utils.data.Dataset` and `torch.utils.data.DataLoader` to load data from a custom folder structure, using the FashionMNIST dataset as the source of the data to be loaded.\",\n          \"```python\\nimport tensorflow as tf\\nfrom sklearn.datasets import fetch_california_housing\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nimport numpy as np\\n\\ndef train_linear_regression_model():\\n    \\\"\\\"\\\"\\n    Creates, compiles, and trains a simple linear regression model\\n    on the California housing dataset using TensorFlow/Keras.\\n    \\\"\\\"\\\"\\n    print(\\\"Loading and preparing data...\\\")\\n\\n    # 1. Load the California housing dataset\\n    # Using sklearn.datasets.fetch_california_housing\\n    # API Reference: {'fetch_california_housing': '...'}\\n    X, y = fetch_california_housing(return_X_y=True)\\n    # X is features, y is target (median house value)\\n\\n    # Data has 8 features (dimensionality: 8)\\n    n_features = X.shape[1]\\n    # Target is a single value (real 0.15 - 5, in units of $100,000)\\n    n_targets = 1\\n\\n    print(f\\\"Dataset loaded. Features shape: {X.shape}, Target shape: {y.shape}\\\")\\n\\n    # 2. Split data into training and testing sets\\n    # Using sklearn.model_selection.train_test_split\\n    # API Reference: {'train_test_split': '...'}\\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n    print(f\\\"Data split into training ({X_train.shape[0]} samples) and testing ({X_test.shape[0]} samples).\\\")\\n\\n    # 3. Scale features and target\\n    # Using sklearn.preprocessing.StandardScaler\\n    # API Reference: {'StandardScaler': '...'}\\n    # It's good practice to scale features for many models, including neural networks.\\n    # Scaling the target can also improve training stability in regression.\\n\\n    scaler_X = StandardScaler()\\n    X_train_scaled = scaler_X.fit_transform(X_train) # Fit on training data, then transform\\n    X_test_scaled = scaler_X.transform(X_test)     # Use scaler fitted on training data to transform test data\\n\\n    # Reshape y to be 2D for the scaler (StandardScaler expects shape (n_samples, n_features))\\n    scaler_y = StandardScaler()\\n    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\\n    y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1))\\n\\n    print(\\\"Features and target scaled.\\\")\\n\\n    # 4. Define the simple linear regression model using Keras Sequential API\\n    # A linear regression model is essentially a single Dense layer with no activation.\\n    # Using tensorflow.keras.Sequential and tensorflow.keras.layers.Dense\\n    # API References: {'tensorflow': '...', 'tensorflow.keras': '...', 'Sequential': '...', 'Dense': '...'}\\n\\n    model = tf.keras.Sequential([\\n        # The Dense layer will take care of the linear transformation (W*x + b)\\n        # units=1 because we are predicting a single value (house price)\\n        # activation='linear' is the default and is suitable for linear regression output\\n        # input_shape is required for the first layer if not using the functional API or model.build\\n        tf.keras.layers.Dense(units=n_targets, input_shape=(n_features,))\\n    ])\\n\\n    print(\\\"Model defined: Sequential with one Dense layer.\\\")\\n\\n    # 5. Compile the model\\n    # Using keras.Model.compile\\n    # API Reference: {'Sequential': '...'} (as Sequential inherits from Model)\\n    # optimizer: 'adam' is a good general-purpose optimizer.\\n    # loss: 'mse' (Mean Squared Error) is the standard loss function for regression.\\n    model.compile(optimizer='adam', loss='mse')\\n\\n    print(\\\"Model compiled with Adam optimizer and Mean Squared Error loss.\\\")\\n\\n    # Display model summary (optional)\\n    model.summary()\\n\\n    # 6. Train the model\\n    # Using keras.Model.fit\\n    # API Reference: {'Sequential': '...'} (as Sequential inherits from Model)\\n    # x, y: Scaled training data\\n    # epochs: Number of passes over the training data\\n    # validation_data: Optional data to evaluate the model on after each epoch (monitors overfitting)\\n    print(\\\"Training the model...\\\")\\n    history = model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test_scaled))\\n\\n    print(\\\"Training finished.\\\")\\n\\n    # Optional: Evaluate the model on the test set\\n    # Using keras.Model.evaluate\\n    # API Reference: Mentioned in Sequential as a common method but not detailed\\n    loss = model.evaluate(X_test_scaled, y_test_scaled, verbose=0)\\n    print(f\\\"Test Loss (MSE): {loss}\\\")\\n\\n    # The trained model can now be used for predictions\\n    # To predict, use model.predict(X_new_scaled) and inverse_transform with scaler_y\\n    # Example prediction on the first test sample:\\n    # sample_prediction_scaled = model.predict(X_test_scaled[0].reshape(1, -1))\\n    # sample_prediction_original_scale = scaler_y.inverse_transform(sample_prediction_scaled)\\n    # print(f\\\"Example prediction (scaled): {sample_prediction_scaled[0][0]:.4f}\\\")\\n    # print(f\\\"Example prediction (original scale): ${sample_prediction_original_scale[0][0]*100000:.2f}\\\")\\n    # print(f\\\"Actual value (original scale): ${y_test[0]*100000:.2f}\\\")\\n\\n\\n    return model, scaler_X, scaler_y # Return the trained model and scalers\\n\\n# Example usage:\\nif __name__ == \\\"__main__\\\":\\n    trained_model, feature_scaler, target_scaler = train_linear_regression_model()\\n\\n    # Demonstrate a prediction\\n    print(\\\"\\\\nDemonstrating prediction...\\\")\\n    # Take the first sample from the *original* test data\\n    sample_X_original = X_test[0]\\n    sample_y_original = y_test[0]\\n\\n    # Scale the sample using the fitted feature scaler\\n    sample_X_scaled = feature_scaler.transform(sample_X_original.reshape(1, -1))\\n\\n    # Make a prediction using the trained model\\n    sample_prediction_scaled = trained_model.predict(sample_X_scaled)\\n\\n    # Inverse transform the prediction using the fitted target scaler to get original scale\\n    sample_prediction_original_scale = target_scaler.inverse_transform(sample_prediction_scaled)\\n\\n    print(f\\\"Original Sample Features: {sample_X_original}\\\")\\n    print(f\\\"Actual Median House Value: ${sample_y_original * 100000:.2f}\\\")\\n    print(f\\\"Predicted Median House Value: ${sample_prediction_original_scale[0][0] * 100000:.2f}\\\")\\n\\n```\\n\\n**API Usage Pattern Explanation:**\\n\\n1.  **Data Loading (`sklearn.datasets.fetch_california_housing`):**\\n    *   The first step in most ML tasks is data acquisition.\\n    *   `fetch_california_housing` is used directly to load the standard dataset.\\n    *   The `return_X_y=True` parameter is a common pattern in scikit-learn datasets to get features (`X`) and target (`y`) as separate NumPy arrays, which is convenient for subsequent processing and feeding into models like Keras.\\n    *   This function is called without arguments or with simple boolean flags based on its API description.\\n\\n2.  **Data Splitting (`sklearn.model_selection.train_test_split`):**\\n    *   It's crucial to split data to evaluate the model's performance on unseen examples.\\n    *   `train_test_split` takes the feature and target arrays (`X`, `y`) and splits them into corresponding training and testing subsets (`X_train`, `X_test`, `y_train`, `y_test`).\\n    *   Key parameters used are `test_size` (proportion of data for testing) and `random_state` (for reproducibility).\\n\\n3.  **Data Preprocessing/Scaling (`sklearn.preprocessing.StandardScaler`):**\\n    *   Neural networks, especially simple ones, often benefit from input features being on a similar scale. The target variable scale can also affect training stability.\\n    *   `StandardScaler` is instantiated for both features and the target.\\n    *   The `fit` method is called *only* on the training data (`X_train`, `y_train.reshape(-1, 1)`) to learn the mean and standard deviation from the training distribution.\\n    *   The `transform` method is then called on *both* the training and testing data (`X_train`, `X_test`, `y_train`, `y_test`) using the *same* fitted scaler. This ensures test data is scaled consistently with the training data, preventing data leakage from the test set into the training process. The target `y` is reshaped because `StandardScaler` expects a 2D array.\\n\\n4.  **Model Definition (`tf.keras.Sequential`, `tf.keras.layers.Dense`):**\\n    *   `tf.keras.Sequential` is used for building models layer-by-layer in a linear stack, which is perfect for this simple model.\\n    *   An instance of `tf.keras.Sequential` is created.\\n    *   The single layer, `tf.keras.layers.Dense`, is added to the sequential model using the `.add()` method.\\n    *   `Dense` is configured with `units=1` because linear regression predicts a single output value (the house price).\\n    *   `input_shape=(n_features,)` is specified in the first layer. This tells Keras the shape of a single input sample, allowing the model to be built immediately (rather than using the Delayed-Build Pattern which builds the model on the first `fit` call). `n_features` is derived from the data shape. The default `activation='linear'` is suitable for linear regression.\\n\\n5.  **Model Compilation (`model.compile`):**\\n    *   Before training, the model must be configured. This involves specifying the optimizer and the loss function.\\n    *   The `.compile()` method of the `Sequential` model (inherited from `keras.Model`) is called.\\n    *   `optimizer='adam'` is chosen as a robust general-purpose optimizer. Keras accepts string names for common optimizers.\\n    *   `loss='mse'` (Mean Squared Error) is the standard loss function for regression tasks. Keras accepts string names for common losses.\\n\\n6.  **Model Training (`model.fit`):**\\n    *   The model is trained using the `.fit()` method.\\n    *   It takes the scaled training features (`X_train_scaled`) and scaled training targets (`y_train_scaled`).\\n    *   `epochs` determines how many times the training process iterates over the entire dataset.\\n    *   `batch_size` specifies the number of samples processed before updating the model weights.\\n    *   `validation_data=(X_test_scaled, y_test_scaled)` is provided to monitor the model's performance on the test set after each epoch. This is helpful for detecting overfitting.\\n\\nThis pattern follows the standard machine learning workflow: data loading -> preprocessing -> model definition -> model compilation -> model training. It specifically leverages the Keras Sequential API for simplicity and the scikit-learn utilities for dataset handling and standard preprocessing steps, integrating APIs from both libraries as needed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}],"source":["df_neural = pd.read_csv(\"/content/drive/MyDrive/Stanford NLP/neural_results_gemini.csv\")\n","df_neural"]},{"cell_type":"code","source":["df_api = pd.read_csv(\"/content/drive/MyDrive/Stanford NLP/api_documentation_new.csv\")\n","df_api"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"3FMxoWaKujoY","executionInfo":{"status":"ok","timestamp":1748916362417,"user_tz":420,"elapsed":923,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"2b7ef2d9-1633-48ef-c713-2ba90fba0456"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                         API Component  \\\n","0                           tensorflow   \n","1                     tensorflow.keras   \n","2                           Sequential   \n","3                                Dense   \n","4                                Input   \n","5                          Concatenate   \n","6             fetch_california_housing   \n","7                  make_classification   \n","8                     train_test_split   \n","9                       StandardScaler   \n","10                  LogisticRegression   \n","11                       make_pipeline   \n","12                                 PCA   \n","13                               torch   \n","14                            torch.nn   \n","15                         torch.optim   \n","16                         torchvision   \n","17              torchvision.transforms   \n","18                 torch.nn.functional   \n","19                             Dataset   \n","20                          DataLoader   \n","21                torchvision.datasets   \n","22                            ToTensor   \n","23                               numpy   \n","24                              pandas   \n","25                   matplotlib.pyplot   \n","26                       AutoTokenizer   \n","27             DataCollatorWithPadding   \n","28  AutoModelForSequenceClassification   \n","29                   TrainingArguments   \n","30                             Trainer   \n","31                      notebook_login   \n","32                        load_dataset   \n","\n","                                        Documentation  \\\n","0   Top-level module of TensorFlow. By convention,...   \n","1   DO NOT EDIT.  This file was autogenerated. Do ...   \n","2   `Sequential` groups a linear stack of layers i...   \n","3   Just your regular densely-connected NN layer. ...   \n","4   Used to instantiate a Keras tensor.  A Keras t...   \n","5   Concatenates a list of inputs.  It takes as in...   \n","6   Load the California housing dataset (regressio...   \n","7   Generate a random n-class classification probl...   \n","8   Split arrays or matrices into random train and...   \n","9   Standardize features by removing the mean and ...   \n","10  Logistic Regression (aka logit, MaxEnt) classi...   \n","11  Construct a :class:`Pipeline` from the given e...   \n","12  Principal component analysis (PCA).  Linear di...   \n","13  The torch package contains data structures for...   \n","14                            No documentation found.   \n","15  :mod:`torch.optim` is a package implementing v...   \n","16                            No documentation found.   \n","17                            No documentation found.   \n","18                              Functional interface.   \n","19  An abstract class representing a :class:`Datas...   \n","20  Data loader combines a dataset and a sampler, ...   \n","21                            No documentation found.   \n","22  Convert a PIL Image or ndarray to tensor and s...   \n","23  NumPy =====  Provides   1. An array object of ...   \n","24  pandas - a powerful data analysis and manipula...   \n","25  `matplotlib.pyplot` is a state-based interface...   \n","26  This is a generic tokenizer class that will be...   \n","27  Data collator that will dynamically pad the in...   \n","28  This is a generic model class that will be ins...   \n","29  TrainingArguments is the subset of the argumen...   \n","30  Trainer is a simple but feature-complete train...   \n","31  Displays a widget to log in to the HF website ...   \n","32  Load a dataset from the Hugging Face Hub, or a...   \n","\n","                                   api_extract_gemini  \\\n","0   ```json\\n{\\n  \"module\": {\\n    \"name\": \"tf\",\\n...   \n","1   ```json\\n{\\n  \"types\": {\\n    \"SomeType\": {\\n ...   \n","2   ```json\\n{\\n  \"description\": \"API representati...   \n","3   ```json\\n{\\n  \"name\": \"Dense\",\\n  \"type\": \"Lay...   \n","4   ```json\\n{\\n  \"types\": [\\n    {\\n      \"name\":...   \n","5   ```json\\n{\\n  \"name\": \"Concatenate\",\\n  \"type\"...   \n","6   ```json\\n{\\n  \"module\": \"sklearn.datasets\",\\n ...   \n","7   ```json\\n{\\n  \"function\": {\\n    \"name\": \"make...   \n","8   ```json\\n{\\n  \"function\": {\\n    \"name\": \"trai...   \n","9   ```json\\n{\\n  \"classes\": [\\n    {\\n      \"name...   \n","10  ```json\\n{\\n  \"name\": \"LogisticRegression\",\\n ...   \n","11  ```json\\n{\\n  \"api_element\": {\\n    \"type\": \"f...   \n","12  ```json\\n{\\n  \"class\": \"PCA\",\\n  \"description\"...   \n","13  ```json\\n{\\n  \"package\": {\\n    \"name\": \"torch...   \n","14  Based on the input provided (\"No documentation...   \n","15  ```json\\n{\\n  \"package\": {\\n    \"name\": \"torch...   \n","16  ```json\\n{\\n  \"status\": \"error\",\\n  \"message\":...   \n","17  Based on the input \"No documentation found,\" I...   \n","18  ```json\\n{\\n  \"api_description\": \"Structured r...   \n","19  ```json\\n{\\n  \"types\": [\\n    {\\n      \"name\":...   \n","20  ```json\\n{\\n  \"api_description\": \"Data loader ...   \n","21  ```json\\n{\\n  \"types\": [],\\n  \"functions\": [],...   \n","22  ```json\\n{\\n  \"api_component\": \"Transform\",\\n ...   \n","23  ```json\\n{\\n  \"name\": \"NumPy\",\\n  \"description...   \n","24  ```json\\n{\\n  \"library\": \"pandas\",\\n  \"descrip...   \n","25  ```json\\n{\\n  \"module\": {\\n    \"name\": \"matplo...   \n","26  ```json\\n{\\n  \"classes\": [\\n    {\\n      \"name...   \n","27  ```json\\n[\\n  {\\n    \"name\": \"DataCollatorWith...   \n","28  ```json\\n{\\n  \"types\": [\\n    {\\n      \"name\":...   \n","29  ```json\\n{\\n  \"class_name\": \"TrainingArguments...   \n","30  ```json\\n{\\n  \"api\": {\\n    \"name\": \"Hugging F...   \n","31  ```json\\n{\\n  \"api\": {\\n    \"name\": \"Hugging F...   \n","32  ```json\\n{\\n  \"name\": \"load_dataset\",\\n  \"desc...   \n","\n","                                      api_extract_gpt  \n","0   ```json\\n{\\n  \"module\": \"tensorflow\",\\n  \"alia...  \n","1   Of course! Please provide the API documentatio...  \n","2   Certainly! Here's a structured representation ...  \n","3   Here is a structured representation of the API...  \n","4   To extract the structured representation of th...  \n","5   ```json\\n{\\n  \"API\": \"Concatenate\",\\n  \"Type\":...  \n","6   Here's a structured representation of the API ...  \n","7   Here's a structured representation of the API ...  \n","8   Below is the structured representation of the ...  \n","9   ```json\\n{\\n  \"class\": \"StandardScaler\",\\n  \"d...  \n","10  ```json\\n{\\n  \"class\": \"LogisticRegression\",\\n...  \n","11  Here is the structured representation of the A...  \n","12  Here is a structured representation of the giv...  \n","13  Based on the provided description of the `torc...  \n","14  Unfortunately, without any documentation or de...  \n","15  To extract a structured representation for the...  \n","16  To create a structured representation of an AP...  \n","17  To create a structured representation of an AP...  \n","18  To create a structured representation of the A...  \n","19  ```json\\n{\\n  \"class\": \"Dataset\",\\n  \"descript...  \n","20  Here's a structured representation of the API ...  \n","21  Since there is no documentation provided, it's...  \n","22  ```json\\n{\\n  \"API\": {\\n    \"name\": \"ConvertTo...  \n","23  Here's a structured representation of the NumP...  \n","24  Certainly! Below is a structured representatio...  \n","25  ```json\\n{\\n  \"module\": \"matplotlib.pyplot\",\\n...  \n","26  Certainly! Based on the provided API documenta...  \n","27  ```json\\n{\\n  \"DataCollator\": {\\n    \"descript...  \n","28  Based on the provided API documentation, the s...  \n","29  Below is a structured JSON representation of t...  \n","30  Here is a structured representation of the API...  \n","31  ```json\\n{\\n  \"API\": {\\n    \"function\": \"noteb...  \n","32  Below is a structured JSON representation of t...  "],"text/html":["\n","  <div id=\"df-348ec4cc-e5da-4051-84f3-566e4fad59e1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>API Component</th>\n","      <th>Documentation</th>\n","      <th>api_extract_gemini</th>\n","      <th>api_extract_gpt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>tensorflow</td>\n","      <td>Top-level module of TensorFlow. By convention,...</td>\n","      <td>```json\\n{\\n  \"module\": {\\n    \"name\": \"tf\",\\n...</td>\n","      <td>```json\\n{\\n  \"module\": \"tensorflow\",\\n  \"alia...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>tensorflow.keras</td>\n","      <td>DO NOT EDIT.  This file was autogenerated. Do ...</td>\n","      <td>```json\\n{\\n  \"types\": {\\n    \"SomeType\": {\\n ...</td>\n","      <td>Of course! Please provide the API documentatio...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sequential</td>\n","      <td>`Sequential` groups a linear stack of layers i...</td>\n","      <td>```json\\n{\\n  \"description\": \"API representati...</td>\n","      <td>Certainly! Here's a structured representation ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Dense</td>\n","      <td>Just your regular densely-connected NN layer. ...</td>\n","      <td>```json\\n{\\n  \"name\": \"Dense\",\\n  \"type\": \"Lay...</td>\n","      <td>Here is a structured representation of the API...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Input</td>\n","      <td>Used to instantiate a Keras tensor.  A Keras t...</td>\n","      <td>```json\\n{\\n  \"types\": [\\n    {\\n      \"name\":...</td>\n","      <td>To extract the structured representation of th...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Concatenate</td>\n","      <td>Concatenates a list of inputs.  It takes as in...</td>\n","      <td>```json\\n{\\n  \"name\": \"Concatenate\",\\n  \"type\"...</td>\n","      <td>```json\\n{\\n  \"API\": \"Concatenate\",\\n  \"Type\":...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>fetch_california_housing</td>\n","      <td>Load the California housing dataset (regressio...</td>\n","      <td>```json\\n{\\n  \"module\": \"sklearn.datasets\",\\n ...</td>\n","      <td>Here's a structured representation of the API ...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>make_classification</td>\n","      <td>Generate a random n-class classification probl...</td>\n","      <td>```json\\n{\\n  \"function\": {\\n    \"name\": \"make...</td>\n","      <td>Here's a structured representation of the API ...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>train_test_split</td>\n","      <td>Split arrays or matrices into random train and...</td>\n","      <td>```json\\n{\\n  \"function\": {\\n    \"name\": \"trai...</td>\n","      <td>Below is the structured representation of the ...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>StandardScaler</td>\n","      <td>Standardize features by removing the mean and ...</td>\n","      <td>```json\\n{\\n  \"classes\": [\\n    {\\n      \"name...</td>\n","      <td>```json\\n{\\n  \"class\": \"StandardScaler\",\\n  \"d...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>LogisticRegression</td>\n","      <td>Logistic Regression (aka logit, MaxEnt) classi...</td>\n","      <td>```json\\n{\\n  \"name\": \"LogisticRegression\",\\n ...</td>\n","      <td>```json\\n{\\n  \"class\": \"LogisticRegression\",\\n...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>make_pipeline</td>\n","      <td>Construct a :class:`Pipeline` from the given e...</td>\n","      <td>```json\\n{\\n  \"api_element\": {\\n    \"type\": \"f...</td>\n","      <td>Here is the structured representation of the A...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>PCA</td>\n","      <td>Principal component analysis (PCA).  Linear di...</td>\n","      <td>```json\\n{\\n  \"class\": \"PCA\",\\n  \"description\"...</td>\n","      <td>Here is a structured representation of the giv...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>torch</td>\n","      <td>The torch package contains data structures for...</td>\n","      <td>```json\\n{\\n  \"package\": {\\n    \"name\": \"torch...</td>\n","      <td>Based on the provided description of the `torc...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>torch.nn</td>\n","      <td>No documentation found.</td>\n","      <td>Based on the input provided (\"No documentation...</td>\n","      <td>Unfortunately, without any documentation or de...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>torch.optim</td>\n","      <td>:mod:`torch.optim` is a package implementing v...</td>\n","      <td>```json\\n{\\n  \"package\": {\\n    \"name\": \"torch...</td>\n","      <td>To extract a structured representation for the...</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>torchvision</td>\n","      <td>No documentation found.</td>\n","      <td>```json\\n{\\n  \"status\": \"error\",\\n  \"message\":...</td>\n","      <td>To create a structured representation of an AP...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>torchvision.transforms</td>\n","      <td>No documentation found.</td>\n","      <td>Based on the input \"No documentation found,\" I...</td>\n","      <td>To create a structured representation of an AP...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>torch.nn.functional</td>\n","      <td>Functional interface.</td>\n","      <td>```json\\n{\\n  \"api_description\": \"Structured r...</td>\n","      <td>To create a structured representation of the A...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Dataset</td>\n","      <td>An abstract class representing a :class:`Datas...</td>\n","      <td>```json\\n{\\n  \"types\": [\\n    {\\n      \"name\":...</td>\n","      <td>```json\\n{\\n  \"class\": \"Dataset\",\\n  \"descript...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>DataLoader</td>\n","      <td>Data loader combines a dataset and a sampler, ...</td>\n","      <td>```json\\n{\\n  \"api_description\": \"Data loader ...</td>\n","      <td>Here's a structured representation of the API ...</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>torchvision.datasets</td>\n","      <td>No documentation found.</td>\n","      <td>```json\\n{\\n  \"types\": [],\\n  \"functions\": [],...</td>\n","      <td>Since there is no documentation provided, it's...</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>ToTensor</td>\n","      <td>Convert a PIL Image or ndarray to tensor and s...</td>\n","      <td>```json\\n{\\n  \"api_component\": \"Transform\",\\n ...</td>\n","      <td>```json\\n{\\n  \"API\": {\\n    \"name\": \"ConvertTo...</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>numpy</td>\n","      <td>NumPy =====  Provides   1. An array object of ...</td>\n","      <td>```json\\n{\\n  \"name\": \"NumPy\",\\n  \"description...</td>\n","      <td>Here's a structured representation of the NumP...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>pandas</td>\n","      <td>pandas - a powerful data analysis and manipula...</td>\n","      <td>```json\\n{\\n  \"library\": \"pandas\",\\n  \"descrip...</td>\n","      <td>Certainly! Below is a structured representatio...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>matplotlib.pyplot</td>\n","      <td>`matplotlib.pyplot` is a state-based interface...</td>\n","      <td>```json\\n{\\n  \"module\": {\\n    \"name\": \"matplo...</td>\n","      <td>```json\\n{\\n  \"module\": \"matplotlib.pyplot\",\\n...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>AutoTokenizer</td>\n","      <td>This is a generic tokenizer class that will be...</td>\n","      <td>```json\\n{\\n  \"classes\": [\\n    {\\n      \"name...</td>\n","      <td>Certainly! Based on the provided API documenta...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>DataCollatorWithPadding</td>\n","      <td>Data collator that will dynamically pad the in...</td>\n","      <td>```json\\n[\\n  {\\n    \"name\": \"DataCollatorWith...</td>\n","      <td>```json\\n{\\n  \"DataCollator\": {\\n    \"descript...</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>AutoModelForSequenceClassification</td>\n","      <td>This is a generic model class that will be ins...</td>\n","      <td>```json\\n{\\n  \"types\": [\\n    {\\n      \"name\":...</td>\n","      <td>Based on the provided API documentation, the s...</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>TrainingArguments</td>\n","      <td>TrainingArguments is the subset of the argumen...</td>\n","      <td>```json\\n{\\n  \"class_name\": \"TrainingArguments...</td>\n","      <td>Below is a structured JSON representation of t...</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Trainer</td>\n","      <td>Trainer is a simple but feature-complete train...</td>\n","      <td>```json\\n{\\n  \"api\": {\\n    \"name\": \"Hugging F...</td>\n","      <td>Here is a structured representation of the API...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>notebook_login</td>\n","      <td>Displays a widget to log in to the HF website ...</td>\n","      <td>```json\\n{\\n  \"api\": {\\n    \"name\": \"Hugging F...</td>\n","      <td>```json\\n{\\n  \"API\": {\\n    \"function\": \"noteb...</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>load_dataset</td>\n","      <td>Load a dataset from the Hugging Face Hub, or a...</td>\n","      <td>```json\\n{\\n  \"name\": \"load_dataset\",\\n  \"desc...</td>\n","      <td>Below is a structured JSON representation of t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-348ec4cc-e5da-4051-84f3-566e4fad59e1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-348ec4cc-e5da-4051-84f3-566e4fad59e1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-348ec4cc-e5da-4051-84f3-566e4fad59e1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-735e4832-0e6a-4402-af34-34b712eac1dc\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-735e4832-0e6a-4402-af34-34b712eac1dc')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-735e4832-0e6a-4402-af34-34b712eac1dc button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_69561716-171f-4019-8c7a-a1fdb80cc4c0\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_api')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_69561716-171f-4019-8c7a-a1fdb80cc4c0 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_api');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_api","summary":"{\n  \"name\": \"df_api\",\n  \"rows\": 33,\n  \"fields\": [\n    {\n      \"column\": \"API Component\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"notebook_login\",\n          \"torch.optim\",\n          \"AutoTokenizer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Documentation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Trainer is a simple but feature-complete training and eval loop for PyTorch, optimized for \\ud83e\\udd17 Transformers.  Args:     model ([`PreTrainedModel`] or `torch.nn.Module`, *optional*):         The model to train, evaluate or use for predictions. If not provided, a `model_init` must be passed.          <Tip>          [`Trainer`] is optimized to work with the [`PreTrainedModel`] provided by the library. You can still use         your own models defined as `torch.nn.Module` as long as they work the same way as the \\ud83e\\udd17 Transformers         models.          </Tip>      args ([`TrainingArguments`], *optional*):         The arguments to tweak for training. Will default to a basic instance of [`TrainingArguments`] with the         `output_dir` set to a directory named *tmp_trainer* in the current directory if not provided.     data_collator (`DataCollator`, *optional*):         The function to use to form a batch from a list of elements of `train_dataset` or `eval_dataset`. Will         default to [`default_data_collator`] if no `processing_class` is provided, an instance of         [`DataCollatorWithPadding`] otherwise if the processing_class is a feature extractor or tokenizer.     train_dataset (Union[`torch.utils.data.Dataset`, `torch.utils.data.IterableDataset`, `datasets.Dataset`], *optional*):         The dataset to use for training. If it is a [`~datasets.Dataset`], columns not accepted by the         `model.forward()` method are automatically removed.          Note that if it's a `torch.utils.data.IterableDataset` with some randomization and you are training in a         distributed fashion, your iterable dataset should either use a internal attribute `generator` that is a         `torch.Generator` for the randomization that must be identical on all processes (and the Trainer will         manually set the seed of this `generator` at each epoch) or have a `set_epoch()` method that internally         sets the seed of the RNGs used.     eval_dataset (Union[`torch.utils.data.Dataset`, Dict[str, `torch.utils.data.Dataset`, `datasets.Dataset`]), *optional*):          The dataset to use for evaluation. If it is a [`~datasets.Dataset`], columns not accepted by the          `model.forward()` method are automatically removed. If it is a dictionary, it will evaluate on each          dataset prepending the dictionary key to the metric name.     processing_class (`PreTrainedTokenizerBase` or `BaseImageProcessor` or `FeatureExtractionMixin` or `ProcessorMixin`, *optional*):         Processing class used to process the data. If provided, will be used to automatically process the inputs         for the model, and it will be saved along the model to make it easier to rerun an interrupted training or         reuse the fine-tuned model.         This supersedes the `tokenizer` argument, which is now deprecated.     model_init (`Callable[[], PreTrainedModel]`, *optional*):         A function that instantiates the model to be used. If provided, each call to [`~Trainer.train`] will start         from a new instance of the model as given by this function.          The function may have zero argument, or a single one containing the optuna/Ray Tune/SigOpt trial object, to         be able to choose different architectures according to hyper parameters (such as layer count, sizes of         inner layers, dropout probabilities etc).     compute_loss_func (`Callable`, *optional*):         A function that accepts the raw model outputs, labels, and the number of items in the entire accumulated         batch (batch_size * gradient_accumulation_steps) and returns the loss. For example, see the default [loss function](https://github.com/huggingface/transformers/blob/052e652d6d53c2b26ffde87e039b723949a53493/src/transformers/trainer.py#L3618) used by [`Trainer`].     compute_metrics (`Callable[[EvalPrediction], Dict]`, *optional*):         The function that will be used to compute metrics at evaluation. Must take a [`EvalPrediction`] and return         a dictionary string to metric values. *Note* When passing TrainingArgs with `batch_eval_metrics` set to         `True`, your compute_metrics function must take a boolean `compute_result` argument. This will be triggered         after the last eval batch to signal that the function needs to calculate and return the global summary         statistics rather than accumulating the batch-level statistics     callbacks (List of [`TrainerCallback`], *optional*):         A list of callbacks to customize the training loop. Will add those to the list of default callbacks         detailed in [here](callback).          If you want to remove one of the default callbacks used, use the [`Trainer.remove_callback`] method.     optimizers (`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`, *optional*, defaults to `(None, None)`):         A tuple containing the optimizer and the scheduler to use. Will default to an instance of [`AdamW`] on your         model and a scheduler given by [`get_linear_schedule_with_warmup`] controlled by `args`.     optimizer_cls_and_kwargs (`Tuple[Type[torch.optim.Optimizer], Dict[str, Any]]`, *optional*):         A tuple containing the optimizer class and keyword arguments to use.         Overrides `optim` and `optim_args` in `args`. Incompatible with the `optimizers` argument.          Unlike `optimizers`, this argument avoids the need to place model parameters on the correct devices before initializing the Trainer.     preprocess_logits_for_metrics (`Callable[[torch.Tensor, torch.Tensor], torch.Tensor]`, *optional*):         A function that preprocess the logits right before caching them at each evaluation step. Must take two         tensors, the logits and the labels, and return the logits once processed as desired. The modifications made         by this function will be reflected in the predictions received by `compute_metrics`.          Note that the labels (second parameter) will be `None` if the dataset does not have them.  Important attributes:      - **model** -- Always points to the core model. If using a transformers model, it will be a [`PreTrainedModel`]       subclass.     - **model_wrapped** -- Always points to the most external model in case one or more other modules wrap the       original model. This is the model that should be used for the forward pass. For example, under `DeepSpeed`,       the inner model is wrapped in `DeepSpeed` and then again in `torch.nn.DistributedDataParallel`. If the inner       model hasn't been wrapped, then `self.model_wrapped` is the same as `self.model`.     - **is_model_parallel** -- Whether or not a model has been switched to a model parallel mode (different from       data parallelism, this means some of the model layers are split on different GPUs).     - **place_model_on_device** -- Whether or not to automatically place the model on the device - it will be set       to `False` if model parallel or deepspeed is used, or if the default       `TrainingArguments.place_model_on_device` is overridden to return `False` .     - **is_in_train** -- Whether or not a model is currently running `train` (e.g. when `evaluate` is called while       in `train`)\",\n          \":mod:`torch.optim` is a package implementing various optimization algorithms.  Most commonly used methods are already supported, and the interface is general enough, so that more sophisticated ones can also be easily integrated in the future.\",\n          \"This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when created with the [`AutoTokenizer.from_pretrained`] class method.  This class cannot be instantiated directly using `__init__()` (throws an error).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"api_extract_gemini\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"```json\\n{\\n  \\\"api\\\": {\\n    \\\"name\\\": \\\"Hugging Face Login API (Partial)\\\",\\n    \\\"description\\\": \\\"API functions related to user authentication and token management.\\\",\\n    \\\"functions\\\": [\\n      {\\n        \\\"name\\\": \\\"notebook_login\\\",\\n        \\\"description\\\": \\\"Displays a widget to log in to the HF website and store the token. Equivalent to `login` without passing a token when run in a notebook. Useful if you want to force the use of the notebook widget instead of a prompt in the terminal. For more details, see `login`.\\\",\\n        \\\"parameters\\\": [\\n          {\\n            \\\"name\\\": \\\"new_session\\\",\\n            \\\"type\\\": \\\"bool\\\",\\n            \\\"description\\\": \\\"If `True`, will request a token even if one is already saved on the machine.\\\",\\n            \\\"default_value\\\": true,\\n            \\\"required\\\": false\\n          },\\n          {\\n            \\\"name\\\": \\\"write_permission\\\",\\n            \\\"type\\\": \\\"bool\\\",\\n            \\\"description\\\": \\\"Ignored and deprecated argument.\\\",\\n            \\\"required\\\": false,\\n            \\\"notes\\\": [\\\"ignored\\\", \\\"deprecated\\\"]\\n          }\\n        ],\\n        \\\"returns\\\": null,\\n        \\\"relationships\\\": [\\n          {\\n            \\\"type\\\": \\\"related_to\\\",\\n            \\\"target\\\": \\\"login\\\",\\n            \\\"description\\\": \\\"Equivalent to `login` without a token in a notebook context, and provides a widget UI. See `login` for more details.\\\"\\n          }\\n        ],\\n        \\\"notes\\\": \\\"Specifically designed for notebook environments to provide a GUI login experience.\\\"\\n      }\\n    ],\\n    \\\"types\\\": [\\n      {\\n        \\\"name\\\": \\\"bool\\\",\\n        \\\"description\\\": \\\"A boolean value, either true or false.\\\"\\n      }\\n      // The type of the \\\"token\\\" is not explicitly defined as an input/output type\\n      // for this specific function's signature, so it's not listed here.\\n    ]\\n  }\\n}\\n```\",\n          \"```json\\n{\\n  \\\"package\\\": {\\n    \\\"name\\\": \\\"torch.optim\\\",\\n    \\\"description\\\": \\\"A package implementing various optimization algorithms. Most commonly used methods are already supported, and the interface is general enough, so that more sophisticated ones can also be easily integrated in the future.\\\",\\n    \\\"contents\\\": {\\n      \\\"types\\\": [\\n        {\\n          \\\"category\\\": \\\"Optimization Algorithm\\\",\\n          \\\"description\\\": \\\"Classes that implement specific optimization algorithms (e.g., SGD, Adam). The exact names and specific details of these types are not provided in the source documentation snippet.\\\",\\n          \\\"nature\\\": \\\"Class (inferred, as optimizers typically maintain state and have methods like step())\\\",\\n          \\\"count\\\": \\\"Multiple (implied by 'various', 'most commonly used')\\\"\\n        }\\n      ],\\n      \\\"functions\\\": [\\n        {\\n          \\\"category\\\": \\\"Interface Functionality\\\",\\n          \\\"description\\\": \\\"While specific functions within the package namespace are not named, the description implies a general interface, which would involve methods on the optimizer objects (e.g., step(), zero_grad()). The package itself might expose utility functions, but none are specified.\\\",\\n          \\\"details_available\\\": false\\n        }\\n      ]\\n    },\\n    \\\"relationships\\\": [\\n      {\\n        \\\"type\\\": \\\"Adherence to Interface\\\",\\n        \\\"description\\\": \\\"The optimization algorithm types/classes within this package adhere to a general interface.\\\",\\n        \\\"scope\\\": \\\"Internal package components (optimizer types)\\\",\\n        \\\"purpose\\\": \\\"Ensures compatibility, ease of use, and allows for integration of new optimizers.\\\"\\n      },\\n      {\\n        \\\"type\\\": \\\"Implementation Provider\\\",\\n        \\\"description\\\": \\\"The package provides concrete implementations of optimization algorithms.\\\",\\n        \\\"from\\\": \\\"torch.optim (package)\\\",\\n        \\\"to\\\": \\\"Optimization algorithms (conceptual/types)\\\"\\n      }\\n    ]\\n  }\\n}\\n```\",\n          \"```json\\n{\\n  \\\"classes\\\": [\\n    {\\n      \\\"name\\\": \\\"AutoTokenizer\\\",\\n      \\\"description\\\": \\\"A generic tokenizer class that will be instantiated as one of the specific tokenizer classes from the library.\\\",\\n      \\\"instantiation_notes\\\": \\\"Cannot be instantiated directly using `__init__()` (throws an error). Must be created using the `from_pretrained` class method.\\\",\\n      \\\"methods\\\": [\\n        {\\n          \\\"name\\\": \\\"from_pretrained\\\",\\n          \\\"type\\\": \\\"class method\\\",\\n          \\\"description\\\": \\\"Method used to instantiate the generic AutoTokenizer as a specific tokenizer class.\\\"\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"types\\\": [],\\n  \\\"functions\\\": []\\n}\\n```\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"api_extract_gpt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"```json\\n{\\n  \\\"API\\\": {\\n    \\\"function\\\": \\\"notebook_login\\\",\\n    \\\"description\\\": \\\"Displays a widget to log in to the HF website and store the token. Equivalent to the login function without passing a token when run in a notebook. Useful to force the use of the notebook widget instead of a prompt in the terminal.\\\",\\n    \\\"arguments\\\": {\\n      \\\"new_session\\\": {\\n        \\\"type\\\": \\\"bool\\\",\\n        \\\"default\\\": true,\\n        \\\"description\\\": \\\"If True, will request a token even if one is already saved on the machine.\\\"\\n      },\\n      \\\"write_permission\\\": {\\n        \\\"type\\\": \\\"bool\\\",\\n        \\\"description\\\": \\\"Ignored and deprecated argument.\\\"\\n      }\\n    },\\n    \\\"related_functions\\\": [\\\"login\\\"]\\n  }\\n}\\n```\",\n          \"To extract a structured representation for the `torch.optim` API described, we will focus on the main components and relationships specified in the documentation. Since only a brief description is provided, the structured representation will be based on typical content expected in such an API, with placeholder values indicative of the expected content structure. If more concrete content was provided, it would enable a more accurate extraction. For now, the representation is general.\\n\\n```json\\n{\\n  \\\"module\\\": \\\"torch.optim\\\",\\n  \\\"description\\\": \\\"A package implementing various optimization algorithms with a general interface.\\\",\\n  \\\"types\\\": [],\\n  \\\"functions\\\": [],\\n  \\\"classes\\\": [\\n    {\\n      \\\"name\\\": \\\"<Optimizer Name>\\\",\\n      \\\"description\\\": \\\"A class implementing a specific optimization algorithm.\\\",\\n      \\\"methods\\\": [],\\n      \\\"properties\\\": [],\\n      \\\"relationships\\\": []\\n    }\\n  ]\\n}\\n```\\n\\nThis structured representation outlines the basic structure based on the given brief description. Typically, this would be expanded to include actual optimizer names and descriptions along with methods, properties, and relationships, depending on the full content of the module.\",\n          \"Certainly! Based on the provided API documentation, here's a structured JSON representation of the API, capturing the relevant types, functions, and their relationships:\\n\\n```json\\n{\\n  \\\"classes\\\": [\\n    {\\n      \\\"name\\\": \\\"Tokenizer\\\",\\n      \\\"description\\\": \\\"A generic tokenizer class that cannot be instantiated directly.\\\",\\n      \\\"constructor\\\": {\\n        \\\"method\\\": \\\"__init__\\\",\\n        \\\"instantiable\\\": false,\\n        \\\"error_message\\\": \\\"This class cannot be instantiated directly using __init__()\\\"\\n      },\\n      \\\"methods\\\": [],\\n      \\\"instantiation\\\": {\\n        \\\"method\\\": \\\"AutoTokenizer.from_pretrained\\\",\\n        \\\"description\\\": \\\"Instantiates the tokenizer as one of the library's tokenizer classes.\\\"\\n      }\\n    }\\n  ],\\n  \\\"methods\\\": [\\n    {\\n      \\\"class\\\": \\\"AutoTokenizer\\\",\\n      \\\"name\\\": \\\"from_pretrained\\\",\\n      \\\"description\\\": \\\"Class method to create a tokenizer object\\\",\\n      \\\"type\\\": \\\"class_method\\\"\\n    }\\n  ]\\n}\\n```\\n\\nThis JSON structure captures the key concepts from the API specification: the `Tokenizer` class, the fact that it cannot be instantiated directly, and how it can be instantiated through a class method of `AutoTokenizer`.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df_gemini_sym = pd.read_csv(\"/content/drive/MyDrive/Stanford NLP/symbolic_gemini.csv\")\n","df_gemini_sym"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Tn8of7UwqQU3","executionInfo":{"status":"ok","timestamp":1748916400560,"user_tz":420,"elapsed":1758,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"f7f06a12-0e71-4921-cb53-e33f4dd58f21"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                      gemini_symbolic\n","0   Here are rule-based checking constraints deriv...\n","1   Based on the provided API structure (which app...\n","2   Here are rule-based checking constraints for t...\n","3   Here are the rule based checking constraints f...\n","4   Here are rule-based checking constraints for t...\n","5   Here are the rule-based checking constraints f...\n","6   Here are the rule-based checking constraints f...\n","7   Here are the rule-based checking constraints f...\n","8   Here are the rule-based checking constraints f...\n","9   Here are rule-based checking constraints for t...\n","10  Here are rule-based checking constraints for t...\n","11  Here are rule-based checking constraints for t...\n","12  Here are rule-based checking constraints for t...\n","13  Based on the provided API structure for `torch...\n","14  Based on the common structure and usage patter...\n","15  Based on the provided API structure for `torch...\n","16  Based on the general knowledge of the `torchvi...\n","17  Okay, despite the lack of explicit documentati...\n","18  Here are rule-based checking constraints for t...\n","19  Based on the provided API structure for the `D...\n","20  Here are the rule-based checking constraints f...\n","21  Based on the common structure and usage of `to...\n","22  Here are the rule-based checking constraints f...\n","23  Here are rule-based checking constraints based...\n","24  Based on the extracted API structure for panda...\n","25  Here are rule-based checking constraints for t...\n","26  Based on the provided API structure for `AutoT...\n","27  Here are the rule-based checking constraints f...\n","28  Based on the provided API structure for `AutoM...\n","29  Here are important rule-based checking constra...\n","30  Here are rule-based checking constraints for t...\n","31  Here are the rule based checking constraints f...\n","32  Here are the rule-based checking constraints f..."],"text/html":["\n","  <div id=\"df-6a3b9919-df09-4330-8e98-83cab76198c4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>gemini_symbolic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Here are rule-based checking constraints deriv...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Based on the provided API structure (which app...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Here are rule-based checking constraints for t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Here are the rule based checking constraints f...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Here are rule-based checking constraints for t...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Here are the rule-based checking constraints f...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Here are the rule-based checking constraints f...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Here are the rule-based checking constraints f...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Here are the rule-based checking constraints f...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Here are rule-based checking constraints for t...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Here are rule-based checking constraints for t...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Here are rule-based checking constraints for t...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Here are rule-based checking constraints for t...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Based on the provided API structure for `torch...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Based on the common structure and usage patter...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Based on the provided API structure for `torch...</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Based on the general knowledge of the `torchvi...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Okay, despite the lack of explicit documentati...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Here are rule-based checking constraints for t...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Based on the provided API structure for the `D...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Here are the rule-based checking constraints f...</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Based on the common structure and usage of `to...</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Here are the rule-based checking constraints f...</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Here are rule-based checking constraints based...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Based on the extracted API structure for panda...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Here are rule-based checking constraints for t...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Based on the provided API structure for `AutoT...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Here are the rule-based checking constraints f...</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Based on the provided API structure for `AutoM...</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Here are important rule-based checking constra...</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Here are rule-based checking constraints for t...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Here are the rule based checking constraints f...</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>Here are the rule-based checking constraints f...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a3b9919-df09-4330-8e98-83cab76198c4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6a3b9919-df09-4330-8e98-83cab76198c4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6a3b9919-df09-4330-8e98-83cab76198c4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-9ce9428c-1e53-469b-8eb2-66ea6f63e7b6\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ce9428c-1e53-469b-8eb2-66ea6f63e7b6')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-9ce9428c-1e53-469b-8eb2-66ea6f63e7b6 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_1e7626a3-d3bc-451b-b6e5-fadc30584c0a\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_gemini_sym')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_1e7626a3-d3bc-451b-b6e5-fadc30584c0a button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_gemini_sym');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_gemini_sym","summary":"{\n  \"name\": \"df_gemini_sym\",\n  \"rows\": 33,\n  \"fields\": [\n    {\n      \"column\": \"gemini_symbolic\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"Here are the rule based checking constraints for the `notebook_login` component based on the provided structure:\\n\\n*   The function `notebook_login` is specifically designed for notebook environments.\\n*   The `new_session` parameter must be of boolean type (`bool`).\\n*   The `write_permission` parameter, if provided, must be of boolean type (`bool`).\\n*   The `write_permission` parameter is ignored by the API, regardless of the value provided.\\n*   The `write_permission` parameter is deprecated and its use is discouraged.\\n*   The function itself does not return a specific value (returns `null`).\",\n          \"Based on the provided API structure for `torch.optim`, here are rule-based checking constraints:\\n\\n*   **Package Existence:** The `torch.optim` package must be a valid and importable Python module.\\n*   **Presence of Multiple Optimizer Types:** The `torch.optim` package must contain multiple public members that are Python classes, representing distinct optimization algorithms.\\n*   **Optimizer Types are Classes:** Each identified component categorized as an \\\"Optimization Algorithm\\\" within `torch.optim` must be a Python class (`type`).\\n*   **Interface Adherence - `step` Method:** Instances of the optimization algorithm classes must expose a public method named `step`.\\n*   **Interface Adherence - `zero_grad` Method:** Instances of the optimization algorithm classes must expose a public method named `zero_grad`.\",\n          \"Based on the provided API structure for `AutoTokenizer`:\\n\\n*   Direct instantiation using `AutoTokenizer()` is not allowed and will result in an error.\\n*   The component must be instantiated using the `AutoTokenizer.from_pretrained()` class method.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["api_dict = dict(zip(df_api['API Component'], df_gemini_sym['gemini_symbolic']))\n","api_dict.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BN17ZOpFqIKL","executionInfo":{"status":"ok","timestamp":1748916402893,"user_tz":420,"elapsed":2,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"41f9bb69-b148-40ad-8766-934f51c7322d"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['tensorflow', 'tensorflow.keras', 'Sequential', 'Dense', 'Input', 'Concatenate', 'fetch_california_housing', 'make_classification', 'train_test_split', 'StandardScaler', 'LogisticRegression', 'make_pipeline', 'PCA', 'torch', 'torch.nn', 'torch.optim', 'torchvision', 'torchvision.transforms', 'torch.nn.functional', 'Dataset', 'DataLoader', 'torchvision.datasets', 'ToTensor', 'numpy', 'pandas', 'matplotlib.pyplot', 'AutoTokenizer', 'DataCollatorWithPadding', 'AutoModelForSequenceClassification', 'TrainingArguments', 'Trainer', 'notebook_login', 'load_dataset'])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["api_key = \"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\"\n","\n","client = OpenAI(api_key=api_key)"],"metadata":{"id":"pCr2MNMXZIGA","executionInfo":{"status":"ok","timestamp":1748916445898,"user_tz":420,"elapsed":309,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["REQUESTS_PER_MINUTE = 10\n","DELAY_BETWEEN_REQUESTS = 60 / REQUESTS_PER_MINUTE"],"metadata":{"id":"lL2I8-n11T88","executionInfo":{"status":"ok","timestamp":1748916454590,"user_tz":420,"elapsed":1,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def make_request_openai(prompt, model_name=\"gpt-4o\"):\n","\n","    response = client.chat.completions.create(\n","        model=model_name,\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","            {\"role\": \"user\", \"content\": prompt}\n","        ]\n","    )\n","    return response.choices[0].message.content.strip()"],"metadata":{"id":"LPLY_GX11XzQ","executionInfo":{"status":"ok","timestamp":1748916454816,"user_tz":420,"elapsed":4,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["output = []\n","\n","for index, row in df_neural.iterrows():\n","    print(f\"Processing row {index+1}/{len(df)}...\")\n","\n","    try:\n","        prompt = (\n","            f\"Given the task and its code:\\n\"\n","            f\"{tasks[index]}\\n\"\n","            f\"{df_neural['neural_gemini']}\\n\\n\"\n","            f\" identify the APIs being used based on the task. Then, refer to the extracted documentation data provided below to verify their usage. If you encounter any inconsistencies or constraint violations, report them in a single line. If no issues are found, simply reply with 'perfect'.\\n\"\n","            f\"{api_dict}\\n\\n\"\n","        )\n","\n","        response = make_request_openai(prompt)\n","    except Exception as e:\n","        print(f\"Error generating response: {e}\")\n","        response = f\"Error: {e}\"\n","\n","    output.append(response)\n","\n","    time.sleep(DELAY_BETWEEN_REQUESTS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dpe9wLC-wYgD","executionInfo":{"status":"ok","timestamp":1748916983145,"user_tz":420,"elapsed":206226,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"2b9f4074-c367-44a0-bf31-3cd6121fa82e"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing row 1/8...\n","Processing row 2/8...\n","Processing row 3/8...\n","Processing row 4/8...\n","Processing row 5/8...\n","Processing row 6/8...\n","Processing row 7/8...\n","Processing row 8/8...\n"]}]},{"cell_type":"code","source":["output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ieGEhQq9kDsG","executionInfo":{"status":"ok","timestamp":1748916983363,"user_tz":420,"elapsed":12,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"6f7f2514-b173-414b-bfb7-518aa1ec599f"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['perfect',\n"," 'perfect',\n"," 'perfect',\n"," 'The APIs being used based on the task and provided input are:\\n\\n1. TensorFlow (`tensorflow`): A machine learning library for neural network tasks, often used with alias `tf`.\\n2. Scikit-learn (`sklearn`): A machine learning library in Python, offering functions like `train_test_split`, `StandardScaler`, etc.\\n3. Torch/PyTorch (`torch`): A machine learning library for deep learning tasks.\\n4. Hugging Face Transformer Components (`AutoTokenizer`, `AutoModelForSequenceClassification`): Used for tokenizing and model loading in language-related tasks.\\n5. Datasets (`load_dataset`): Used to load datasets from various sources.\\n\\nLooking at your extracted task description and documentation, everything aligns perfectly with the usage of these APIs with no discrepancies.\\n\\nPerfect.',\n"," 'perfect',\n"," \"The task specifically refers to using PyTorch and the torchvision library for loading the FashionMNIST dataset using a custom Dataset class for image files and labels. Based on the provided code snippets, it seems that lines referencing PyTorch (index 1 and 5) are relevant for this task. Here are the extracted API components which relate to PyTorch and its associated usage:\\n- `torch`\\n- `torch.nn`\\n- `Dataset` (from `torch.utils.data`)\\n- `DataLoader` (from `torch.utils.data`)\\n- `torchvision`\\n- `torchvision.datasets`\\n\\nAccording to the constraints provided for these components: \\n\\n- **Dataset** and **DataLoader** are used correctly as they play roles in iterating over datasets and batching data.\\n- **torch.nn** and **torch** mention subclassing and ensuring tensor operations which aren't directly highlighted in the context but seem indirectly related in ensuring module definition constraints. \\n- **torchvision** and **torchvision.datasets** constraints include verifying dataset class construction with standard arguments like `root`, `train`, and ensuring dataset objects implement `__len__` and `__getitem__`.\\n\\nNo inconsistencies or constraint violations were noted in these areas, so based on this analysis and the context provided, I would report:\\n\\nperfect\",\n"," 'perfect',\n"," 'perfect']"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["df_results = pd.DataFrame({'gemini_check': output})\n","\n","output_path = \"/content/drive/MyDrive/Stanford NLP/check_gemini.csv\"\n","df_results.to_csv(output_path, index=False)"],"metadata":{"id":"EtlXTjof0tgv","executionInfo":{"status":"ok","timestamp":1748917029523,"user_tz":420,"elapsed":925,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"70juxJsli8ME"},"execution_count":null,"outputs":[]}]}