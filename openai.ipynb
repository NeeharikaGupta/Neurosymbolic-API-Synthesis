{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1S5f7f47yPIEePHgeRT8_1eE2z1sYzR28","authorship_tag":"ABX9TyPYO5mA8dRLZMoa+1NLao5r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"C9AFRvCGY-Sm","executionInfo":{"status":"ok","timestamp":1748754713330,"user_tz":420,"elapsed":5367,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}}},"outputs":[],"source":["import os\n","from openai import OpenAI\n","import pandas as pd\n","import time\n","import openai"]},{"cell_type":"code","source":["api_key = \"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\"\n","\n","client = OpenAI(api_key=api_key)"],"metadata":{"id":"pCr2MNMXZIGA","executionInfo":{"status":"ok","timestamp":1748754714661,"user_tz":420,"elapsed":1320,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["REQUESTS_PER_MINUTE = 10\n","DELAY_BETWEEN_REQUESTS = 60 / REQUESTS_PER_MINUTE"],"metadata":{"id":"lL2I8-n11T88","executionInfo":{"status":"ok","timestamp":1748754723442,"user_tz":420,"elapsed":15,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def make_request_openai(prompt, model_name=\"gpt-4o\"):\n","\n","    response = client.chat.completions.create(\n","        model=model_name,\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","            {\"role\": \"user\", \"content\": prompt}\n","        ]\n","    )\n","    return response.choices[0].message.content.strip()"],"metadata":{"id":"LPLY_GX11XzQ","executionInfo":{"status":"ok","timestamp":1748754733203,"user_tz":420,"elapsed":5,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["##Direct prompting and COT"],"metadata":{"id":"jJwM99LF51s4"}},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/Stanford NLP/prompts-step2 - prompts.csv\")\n","df"],"metadata":{"id":"44bXG1eKGqZd","colab":{"base_uri":"https://localhost:8080/","height":318},"executionInfo":{"status":"ok","timestamp":1748754723429,"user_tz":420,"elapsed":8757,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"acd800ab-f9f3-4fdd-8c42-e0d2a4946650"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Task  \\\n","0  Write a Python function using TensorFlow to cr...   \n","1  Write a Python script using PyTorch to train a...   \n","2  Create a scikit-learn pipeline that generates ...   \n","3  Write a Python function that uses Hugging Face...   \n","4  Build a TensorFlow model for image classificat...   \n","5  Write a PyTorch class that subclasses torch.ut...   \n","6  Write a Python script that loads the Iris data...   \n","7  Write a Java program using the Hadoop MapReduc...   \n","\n","                                       direct prompt  \\\n","0  Write a Python function using TensorFlow to cr...   \n","1  Write a Python script using PyTorch to train a...   \n","2  Create a scikit-learn pipeline that generates ...   \n","3  Write a Python function that uses Hugging Face...   \n","4  Build a TensorFlow model for image classificat...   \n","5  Write a PyTorch class that subclasses torch.ut...   \n","6  Write a Python script that loads the Iris data...   \n","7  Write a Java program using the Hadoop MapReduc...   \n","\n","                                                 cot  \n","0  Write a Python function using TensorFlow to cr...  \n","1  Write a Python script using PyTorch to train a...  \n","2  Create a scikit-learn pipeline that generates ...  \n","3  Write a Python function that uses Hugging Face...  \n","4  Build a TensorFlow model for image classificat...  \n","5  Write a PyTorch class that subclasses torch.ut...  \n","6  Write a Python script that loads the Iris data...  \n","7  Write a Java program using the Hadoop MapReduc...  "],"text/html":["\n","  <div id=\"df-83f87a1f-a878-4c0c-bc6f-f84eed4168e7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Task</th>\n","      <th>direct prompt</th>\n","      <th>cot</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Write a Python function using TensorFlow to cr...</td>\n","      <td>Write a Python function using TensorFlow to cr...</td>\n","      <td>Write a Python function using TensorFlow to cr...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Write a Python script using PyTorch to train a...</td>\n","      <td>Write a Python script using PyTorch to train a...</td>\n","      <td>Write a Python script using PyTorch to train a...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Create a scikit-learn pipeline that generates ...</td>\n","      <td>Create a scikit-learn pipeline that generates ...</td>\n","      <td>Create a scikit-learn pipeline that generates ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Write a Python function that uses Hugging Face...</td>\n","      <td>Write a Python function that uses Hugging Face...</td>\n","      <td>Write a Python function that uses Hugging Face...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Build a TensorFlow model for image classificat...</td>\n","      <td>Build a TensorFlow model for image classificat...</td>\n","      <td>Build a TensorFlow model for image classificat...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Write a PyTorch class that subclasses torch.ut...</td>\n","      <td>Write a PyTorch class that subclasses torch.ut...</td>\n","      <td>Write a PyTorch class that subclasses torch.ut...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Write a Python script that loads the Iris data...</td>\n","      <td>Write a Python script that loads the Iris data...</td>\n","      <td>Write a Python script that loads the Iris data...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Write a Java program using the Hadoop MapReduc...</td>\n","      <td>Write a Java program using the Hadoop MapReduc...</td>\n","      <td>Write a Java program using the Hadoop MapReduc...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83f87a1f-a878-4c0c-bc6f-f84eed4168e7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-83f87a1f-a878-4c0c-bc6f-f84eed4168e7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-83f87a1f-a878-4c0c-bc6f-f84eed4168e7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-d10c8ef1-cc12-4c2d-bdc6-78f102080397\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d10c8ef1-cc12-4c2d-bdc6-78f102080397')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-d10c8ef1-cc12-4c2d-bdc6-78f102080397 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_0eab8edd-44a4-494a-8ae0-027c27d7987a\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_0eab8edd-44a4-494a-8ae0-027c27d7987a button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Task\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Write a Python script using PyTorch to train a convolutional neural network (CNN) on the Cifar 10 dataset. Include data loading, model definition, training loop, and evaluation\",\n          \"Write a PyTorch class that subclasses torch.utils.data.Dataset to load image files and labels from a folder. Use this class with a DataLoader for batching. Use FashionMNIST dataset.\",\n          \"Write a Python function using TensorFlow to create and compile a simple linear regression model with one dense layer. Train it on the classic California housing dataset.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"direct prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Write a Python script using PyTorch to train a convolutional neural network (CNN) on the Cifar 10 dataset. Include data loading, model definition, training loop, and evaluation. Just write the code, no explanations necessary.\",\n          \"Write a PyTorch class that subclasses torch.utils.data.Dataset to load image files and labels from a folder. Use this class with a DataLoader for batching. Use FashionMNIST dataset. Just write the code, no explanations necessary.\",\n          \"Write a Python function using TensorFlow to create and compile a simple linear regression model with one dense layer. Train it on the classic California housing dataset. Just write the code, no explanations necessary.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cot\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Write a Python script using PyTorch to train a convolutional neural network (CNN) on the Cifar 10 dataset. Include data loading, model definition, training loop, and evaluation. Please explain your reasoning step-by-step while generating code.\",\n          \"Write a PyTorch class that subclasses torch.utils.data.Dataset to load image files and labels from a folder. Use this class with a DataLoader for batching. Use FashionMNIST dataset. Please explain your reasoning step-by-step while generating code.\",\n          \"Write a Python function using TensorFlow to create and compile a simple linear regression model with one dense layer. Train it on the classic California housing dataset. Please explain your reasoning step-by-step while generating code.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["if \"direct_response\" not in df.columns:\n","    df[\"direct_response\"] = \"\"\n","if \"cot_response\" not in df.columns:\n","    df[\"cot_response\"] = \"\"\n","\n","for index, row in df.iterrows():\n","    print(f\"Processing row {index+1}/{len(df)}...\")\n","\n","    try:\n","        prompt_direct = row['direct prompt']\n","        response_direct = make_request_openai(prompt_direct)\n","        df.at[index, \"direct_response\"] = response_direct\n","    except Exception as e:\n","        print(f\"Error generating direct response: {e}\")\n","        df.at[index, \"direct_response\"] = f\"Error: {e}\"\n","\n","    time.sleep(DELAY_BETWEEN_REQUESTS)\n","\n","    try:\n","        prompt_cot = row['cot']\n","        response_cot = make_request_openai(prompt_cot)\n","        df.at[index, \"cot_response\"] = response_cot\n","    except Exception as e:\n","        print(f\"Error generating CoT response: {e}\")\n","        df.at[index, \"cot_response\"] = f\"Error: {e}\"\n","\n","    time.sleep(DELAY_BETWEEN_REQUESTS)\n","\n","    df.to_csv(\"/content/drive/MyDrive/Stanford NLP/prompts-step2 - responses_gpt.csv\", index=False)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zd7bO5jXZTs9","executionInfo":{"status":"ok","timestamp":1748738255007,"user_tz":420,"elapsed":225381,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"701e1fd0-7c20-4587-d502-ead30e8ab466"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing row 1/8...\n","Processing row 2/8...\n","Processing row 3/8...\n","Processing row 4/8...\n","Processing row 5/8...\n","Processing row 6/8...\n","Processing row 7/8...\n","Processing row 8/8...\n"]}]},{"cell_type":"markdown","source":["##Few Shot"],"metadata":{"id":"mpdT3XAX-Jvp"}},{"cell_type":"code","source":["df_fs = pd.read_csv(\"/content/drive/MyDrive/Stanford NLP/few_shot_prompts.csv\")\n","df_fs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"ztmdLnM0SAvS","executionInfo":{"status":"ok","timestamp":1748741358423,"user_tz":420,"elapsed":269,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"049ba24e-dff6-4f90-d351-365614e2bc62"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              prompt\n","0  Create a python script that uses tensorflow to...\n","1  Write a Python script using PyTorch to train a...\n","2  Create a scikit learn pipeline that builds sta...\n","3  In this example we learn to identify past vs p...\n","4  Build an image recognition tensorflow model to...\n","5  Write a PyTorch class that creates custom data...\n","6  Write a Python script that loads the UCI handw...\n","7  Write a Java program using the Hadoop MapReduc..."],"text/html":["\n","  <div id=\"df-5bb45fc6-3a1b-4a6c-8fdf-0bf05ac7ac2c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Create a python script that uses tensorflow to...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Write a Python script using PyTorch to train a...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Create a scikit learn pipeline that builds sta...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>In this example we learn to identify past vs p...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Build an image recognition tensorflow model to...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Write a PyTorch class that creates custom data...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Write a Python script that loads the UCI handw...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Write a Java program using the Hadoop MapReduc...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bb45fc6-3a1b-4a6c-8fdf-0bf05ac7ac2c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5bb45fc6-3a1b-4a6c-8fdf-0bf05ac7ac2c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5bb45fc6-3a1b-4a6c-8fdf-0bf05ac7ac2c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-e4fe0fa1-aa27-4652-8672-93734af3a1f6\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4fe0fa1-aa27-4652-8672-93734af3a1f6')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-e4fe0fa1-aa27-4652-8672-93734af3a1f6 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_51c09dcd-9fd4-4b3f-891d-fdcc95d52f56\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_fs')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_51c09dcd-9fd4-4b3f-891d-fdcc95d52f56 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_fs');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_fs","summary":"{\n  \"name\": \"df_fs\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Write a Python script using PyTorch to train a convolutional neural network (CNN) on the MNIST dataset. Include data loading, model definition, training loop, and evaluation\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n\\nimport torch\\nfrom torch import optim\\nfrom torch import nn\\nfrom torch.utils.data import DataLoader\\nfrom tqdm import tqdm\\n\\n# !pip install torchvision\\nimport torchvision\\n\\nimport torch.nn.functional as F\\nimport torchvision.datasets as datasets\\nimport torchvision.transforms as transforms\\n\\n# !pip install torchmetrics\\nimport torchmetrics\\n\\nbatch_size = 60\\n\\ntrain_dataset = datasets.MNIST(root=\\\"dataset/\\\", download=True, train=True, transform=transforms.ToTensor())\\n\\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\\n\\ntest_dataset = datasets.MNIST(root=\\\"dataset/\\\", download=True, train=False, transform=transforms.ToTensor())\\n\\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\\n\\nclass CNN(nn.Module):\\n   def __init__(self, in_channels, num_classes):\\n\\n       \\\"\\\"\\\"\\n       Building blocks of convolutional neural network.\\n\\n       Parameters:\\n           * in_channels: Number of channels in the input image (for grayscale images, 1)\\n           * num_classes: Number of classes to predict. In our problem, 10 (i.e digits from  0 to 9).\\n       \\\"\\\"\\\"\\n       super(CNN, self).__init__()\\n\\n       # 1st convolutional layer\\n       self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=3, padding=1)\\n       # Max pooling layer\\n       self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\\n       # 2nd convolutional layer\\n       self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\\n       # Fully connected layer\\n       self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\\n\\n   def forward(self, x):\\n       \\\"\\\"\\\"\\n       Define the forward pass of the neural network.\\n\\n       Parameters:\\n           x: Input tensor.\\n\\n       Returns:\\n           torch.Tensor\\n               The output tensor after passing through the network.\\n       \\\"\\\"\\\"\\n       x = F.relu(self.conv1(x))  # Apply first convolution and ReLU activation\\n       x = self.pool(x)           # Apply max pooling\\n       x = F.relu(self.conv2(x))  # Apply second convolution and ReLU activation\\n       x = self.pool(x)           # Apply max pooling\\n       x = x.reshape(x.shape[0], -1)  # Flatten the tensor\\n       x = self.fc1(x)            # Apply fully connected layer\\n       return x\\n       x = x.reshape(x.shape[0], -1)  # Flatten the tensor\\n       x = self.fc1(x)            # Apply fully connected layer\\n       return x\\n\\n# Define the loss function\\ncriterion = nn.CrossEntropyLoss()\\n\\n# Define the optimizer\\noptimizer = optim.Adam(model.parameters(), lr=0.001)\\n\\nnum_epochs=10\\nfor epoch in range(num_epochs):\\n # Iterate over training batches\\n   print(f\\\"Epoch [{epoch + 1}/{num_epochs}]\\\")\\n\\n   for batch_index, (data, targets) in enumerate(tqdm(dataloader_train)):\\n       data = data.to(device)\\n       targets = targets.to(device)\\n       scores = model(data)\\n       loss = criterion(scores, targets)\\n       optimizer.zero_grad()\\n       loss.backward()\\n       optimizer.step()\\n# Set up of multiclass accuracy metric\\nacc = Accuracy(task=\\\"multiclass\\\",num_classes=10)\\n\\n# Iterate over the dataset batches\\nmodel.eval()\\nwith torch.no_grad():\\n   for images, labels in dataloader_test:\\n       # Get predicted probabilities for test data batch\\n       outputs = model(images)\\n       _, preds = torch.max(outputs, 1)\\n       acc(preds, labels)\\n       precision(preds, labels)\\n       recall(preds, labels)\\n\\n#Compute total test accuracy\\ntest_accuracy = acc.compute()\\nprint(f\\\"Test accuracy: {test_accuracy}\\\")\\n\\nWrite a Python script using PyTorch to train a convolutional neural network (CNN) on the KMNIST dataset. Include data loading, model definition, training loop, and evaluation\\nfrom torch.nn import Module\\nfrom torch.nn import Conv2d\\nfrom torch.nn import Linear\\nfrom torch.nn import MaxPool2d\\nfrom torch.nn import ReLU\\nfrom torch.nn import LogSoftmax\\nfrom torch import flatten\\nimport matplotlib\\nmatplotlib.use(\\\"Agg\\\")\\nfrom pyimagesearch.lenet import LeNet\\nfrom sklearn.metrics import classification_report\\nfrom torch.utils.data import random_split\\nfrom torch.utils.data import DataLoader\\nfrom torchvision.transforms import ToTensor\\nfrom torchvision.datasets import KMNIST\\nfrom torch.optim import Adam\\nfrom torch import nn\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport argparse\\nimport torch\\nimport time\\n\\nclass LeNet(Module):\\n        def __init__(self, numChannels, classes):\\n                # call the parent constructor\\n                super(LeNet, self).__init__()\\n                # initialize first set of CONV => RELU => POOL layers\\n                self.conv1 = Conv2d(in_channels=numChannels, out_channels=20,\\n                        kernel_size=(5, 5))\\n                self.relu1 = ReLU()\\n                self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\\n                # initialize second set of CONV => RELU => POOL layers\\n                self.conv2 = Conv2d(in_channels=20, out_channels=50,\\n                        kernel_size=(5, 5))\\n                self.relu2 = ReLU()\\n                self.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\\n                # initialize first (and only) set of FC => RELU layers\\n                self.fc1 = Linear(in_features=800, out_features=500)\\n                self.relu3 = ReLU()\\n                # initialize our softmax classifier\\n                self.fc2 = Linear(in_features=500, out_features=classes)\\n                self.logSoftmax = LogSoftmax(dim=1)\\n\\ndef forward(self, x):\\n                # pass the input through our first set of CONV => RELU =>\\n                # POOL layers\\n                x = self.conv1(x)\\n                x = self.relu1(x)\\n                x = self.maxpool1(x)\\n                # pass the output from the previous layer through the second\\n                # set of CONV => RELU => POOL layers\\n                x = self.conv2(x)\\n                x = self.relu2(x)\\n                x = self.maxpool2(x)\\n                # flatten the output from the previous layer and pass it\\n                # through our only set of FC => RELU layers\\n                x = flatten(x, 1)\\n                x = self.fc1(x)\\n                x = self.relu3(x)\\n                # pass the output to our softmax classifier to get our output\\n                # predictions\\n                x = self.fc2(x)\\n                output = self.logSoftmax(x)\\n                # return the output predictions\\n                return output\\n# construct the argument parser and parse the arguments\\nap = argparse.ArgumentParser()\\nap.add_argument(\\\"-m\\\", \\\"--model\\\", type=str, required=True,\\n        help=\\\"path to output trained model\\\")\\nap.add_argument(\\\"-p\\\", \\\"--plot\\\", type=str, required=True,\\n        help=\\\"path to output loss/accuracy plot\\\")\\nargs = vars(ap.parse_args())\\n\\nPyTorch: Training your first Convolutional Neural Network (CNN)\\n# define training hyperparameters\\nINIT_LR = 1e-3\\nBATCH_SIZE = 64\\nEPOCHS = 10\\n# define the train and val splits\\nTRAIN_SPLIT = 0.75\\nVAL_SPLIT = 1 - TRAIN_SPLIT\\n# set the device we will be using to train the model\\ndevice = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n\\n# load the KMNIST dataset\\nprint(\\\"[INFO] loading the KMNIST dataset...\\\")\\ntrainData = KMNIST(root=\\\"data\\\", train=True, download=True,\\n        transform=ToTensor())\\ntestData = KMNIST(root=\\\"data\\\", train=False, download=True,\\n        transform=ToTensor())\\n# calculate the train/validation split\\nprint(\\\"[INFO] generating the train/validation split...\\\")\\nnumTrainSamples = int(len(trainData) * TRAIN_SPLIT)\\nnumValSamples = int(len(trainData) * VAL_SPLIT)\\n(trainData, valData) = random_split(trainData,\\n        [numTrainSamples, numValSamples],\\n        generator=torch.Generator().manual_seed(42))\\n\\n# initialize the train, validation, and test data loaders\\ntrainDataLoader = DataLoader(trainData, shuffle=True,\\n        batch_size=BATCH_SIZE)\\nvalDataLoader = DataLoader(valData, batch_size=BATCH_SIZE)\\ntestDataLoader = DataLoader(testData, batch_size=BATCH_SIZE)\\n# calculate steps per epoch for training and validation set\\ntrainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\\nvalSteps = len(valDataLoader.dataset) // BATCH_SIZE\\n\\n# initialize the LeNet model\\nprint(\\\"[INFO] initializing the LeNet model...\\\")\\nmodel = LeNet(\\n        numChannels=1,\\n        classes=len(trainData.dataset.classes)).to(device)\\n# initialize our optimizer and loss function\\nopt = Adam(model.parameters(), lr=INIT_LR)\\nlossFn = nn.NLLLoss()\\n# initialize a dictionary to store training history\\nH = {\\n        \\\"train_loss\\\": [],\\n        \\\"train_acc\\\": [],\\n        \\\"val_loss\\\": [],\\n        \\\"val_acc\\\": []\\n}\\n# measure how long training is going to take\\nprint(\\\"[INFO] training the network...\\\")\\n\\n# loop over our epochs\\nfor e in range(0, EPOCHS):\\n        # set the model in training mode\\n        model.train()\\n        # initialize the total training and validation loss\\n        totalTrainLoss = 0\\n        totalValLoss = 0\\n        # initialize the number of correct predictions in the training\\n        # and validation step\\n        trainCorrect = 0\\n        valCorrect = 0\\n        # loop over the training set\\n        for (x, y) in trainDataLoader:\\n                # send the input to the device\\n                (x, y) = (x.to(device), y.to(device))\\n                # perform a forward pass and calculate the training loss\\n                pred = model(x)\\n                loss = lossFn(pred, y)\\n                # zero out the gradients, perform the backpropagation step,\\n                # and update the weights\\n                opt.zero_grad()\\n                loss.backward()\\n                opt.step()\\n                # add the loss to the total training loss so far and\\n                # calculate the number of correct predictions\\n                totalTrainLoss += loss\\n                trainCorrect += (pred.argmax(1) == y).type(\\n                        torch.float).sum().item()\\n\\n        # switch off autograd for evaluation\\n        with torch.no_grad():\\n                # set the model in evaluation mode\\n                model.eval()\\n                # loop over the validation set\\n                for (x, y) in valDataLoader:\\n                        # send the input to the device\\n                        (x, y) = (x.to(device), y.to(device))\\n                        # make the predictions and calculate the validation loss\\n                        pred = model(x)\\n                        totalValLoss += lossFn(pred, y)\\n                        # calculate the number of correct predictions\\n                        valCorrect += (pred.argmax(1) == y).type(\\n                                torch.float).sum().item()\\n\\n        # calculate the average training and validation loss\\n        avgTrainLoss = totalTrainLoss / trainSteps\\n        avgValLoss = totalValLoss / valSteps\\n        # calculate the training and validation accuracy\\n        trainCorrect = trainCorrect / len(trainDataLoader.dataset)\\n        valCorrect = valCorrect / len(valDataLoader.dataset)\\n        # update our training history\\n        H[\\\"train_loss\\\"].append(avgTrainLoss.cpu().detach().numpy())\\n        H[\\\"train_acc\\\"].append(trainCorrect)\\n        H[\\\"val_loss\\\"].append(avgValLoss.cpu().detach().numpy())\\n        H[\\\"val_acc\\\"].append(valCorrect)\\n        # print the model training and validation information\\n        print(\\\"[INFO] EPOCH: {}/{}\\\".format(e + 1, EPOCHS))\\n        print(\\\"Train loss: {:.6f}, Train accuracy: {:.4f}\\\".format(\\n                avgTrainLoss, trainCorrect))\\n        print(\\\"Val loss: {:.6f}, Val accuracy: {:.4f}\\\\n\\\".format(\\n                avgValLoss, valCorrect))\\n\\nWrite a Python script using PyTorch to train a convolutional neural network (CNN) on the Cifar 10 dataset. Include data loading, model definition, training loop, and evaluation\\n\",\n          \"Write a PyTorch class that creates custom dataset. It takes in input of img dir and annotations csv file.\\nimport os\\nimport pandas as pd\\nfrom torchvision.io import read_image\\n\\nclass CustomImageDataset(Dataset):\\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\\n        self.img_labels = pd.read_csv(annotations_file)\\n        self.img_dir = img_dir\\n        self.transform = transform\\n        self.target_transform = target_transform\\n\\n    def __len__(self):\\n        return len(self.img_labels)\\n\\n    def __getitem__(self, idx):\\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\\n        image = read_image(img_path)\\n        label = self.img_labels.iloc[idx, 1]\\n        if self.transform:\\n            image = self.transform(image)\\n        if self.target_transform:\\n            label = self.target_transform(label)\\n        return image, label\\n\\nWrite a PyTorch class that subclasses torch.utils.data.Dataset to load 100 image files and labels from a folder. The data would be randomly created and the class should also be defined such that its a custom class.Use this class with a DataLoader for batching.\\nimport torch\\nfrom torch.utils.data import Dataset, DataLoader\\nimport torch.nn as nn\\nimport torch.optim as optim\\nimport numpy as np\\n\\n# Custom Dataset class\\nclass CustomDataset(Dataset):\\n    def __init__(self, data, labels):\\n        self.data = data\\n        self.labels = labels\\n\\n    def __len__(self):\\n        return len(self.data)\\n\\n    def __getitem__(self, idx):\\n        sample = self.data[idx]\\n        label = self.labels[idx]\\n        return sample, label\\n\\n# Prepare data\\ndata = np.random.randn(100, 3, 32, 32)  # 100 samples of 3x32x32 images\\nlabels = np.random.randint(0, 10, size=(100,))  # 100 labels in the range 0-9\\n\\n# Create Dataset\\ndataset = CustomDataset(data, labels)\\n\\n# Create DataLoader\\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)\\n\\nWrite a PyTorch class that subclasses torch.utils.data.Dataset to load image files and labels from a folder. Use this class with a DataLoader for batching. Use FashionMNIST dataset.\\n\",\n          \"Create a python script that uses tensorflow to model a linear regression problem using randomly genenrated 50 datat points. You need to train the model and also get the predictions.\\nimport numpy as np\\nimport tensorflow as tf\\nimport matplotlib.pyplot as plt\\n\\nnp.random.seed(101)\\n\\n# Generating random linear data\\n# There will be 50 data points ranging from 0 to 50\\nx = np.linspace(0, 50, 50)\\ny = np.linspace(0, 50, 50)\\n\\n# Adding noise to the random linear data\\nx += np.random.uniform(-4, 4, 50)\\ny += np.random.uniform(-4, 4, 50)\\n\\nn = len(x) # Number of data points\\n\\n# Plot of Training Data\\nplt.scatter(x, y)\\nplt.xlabel('x')\\nplt.ylabel('y')\\nplt.title(\\\"Training Data\\\")\\nplt.show()\\n\\nX = tf.placeholder(\\\"float\\\")\\nY = tf.placeholder(\\\"float\\\")\\n\\nW = tf.Variable(np.random.randn(), name = \\\"W\\\")\\nb = tf.Variable(np.random.randn(), name = \\\"b\\\")\\n\\nlearning_rate = 0.01\\ntraining_epochs = 1000\\n# Hypothesis\\ny_pred = tf.add(tf.multiply(X, W), b)\\n\\n# Mean Squared Error Cost Function\\ncost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n)\\n\\n# Gradient Descent Optimizer\\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\\n\\n# Global Variables Initializer\\ninit = tf.global_variables_initializer()\\n\\n# Starting the Tensorflow Session\\nwith tf.Session() as sess:\\n    \\n    # Initializing the Variables\\n    sess.run(init)\\n    \\n    # Iterating through all the epochs\\n    for epoch in range(training_epochs):\\n        \\n        # Feeding each data point into the optimizer using Feed Dictionary\\n        for (_x, _y) in zip(x, y):\\n            sess.run(optimizer, feed_dict = {X : _x, Y : _y})\\n        \\n        # Displaying the result after every 50 epochs\\n        if (epoch + 1) % 50 == 0:\\n            # Calculating the cost a every epoch\\n            c = sess.run(cost, feed_dict = {X : x, Y : y})\\n            print(\\\"Epoch\\\", (epoch + 1), \\\": cost =\\\", c, \\\"W =\\\", sess.run(W), \\\"b =\\\", sess.run(b))\\n    \\n    # Storing necessary values to be used outside the Session\\n    training_cost = sess.run(cost, feed_dict ={X: x, Y: y})\\n    weight = sess.run(W)\\n    bias = sess.run(b)\\n\\n# Calculating the predictions\\npredictions = weight * x + bias\\nprint(\\\"Training cost =\\\", training_cost, \\\"Weight =\\\", weight, \\\"bias =\\\", bias, '\\\\n')\\n\\nWrite a Python function using TensorFlow to create and compile a simple linear regression model which has a normalizer layer and a dense layer. Train it on the fuel efficiency dataset.\\npip install -q seaborn\\n\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd\\nimport seaborn as sns\\n\\n# Make NumPy printouts easier to read.\\nnp.set_printoptions(precision=3, suppress=True)\\nimport tensorflow as tf\\n\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\n\\nprint(tf.__version__)\\n\\nurl = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\\ncolumn_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\\n                'Acceleration', 'Model Year', 'Origin']\\n\\nraw_dataset = pd.read_csv(url, names=column_names,\\n                          na_values='?', comment='\\\\t',\\n                          sep=' ', skipinitialspace=True)\\n\\ndataset = raw_dataset.copy()\\ndataset.tail()\\n\\ndataset.isna().sum()\\n\\ndataset = dataset.dropna()\\n\\ndataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\\n\\ndataset = pd.get_dummies(dataset, columns=['Origin'], prefix='', prefix_sep='')\\ndataset.tail()\\n\\ntrain_dataset = dataset.sample(frac=0.8, random_state=0)\\ntest_dataset = dataset.drop(train_dataset.index)\\n\\ntrain_features = train_dataset.copy()\\ntest_features = test_dataset.copy()\\n\\ntrain_labels = train_features.pop('MPG')\\ntest_labels = test_features.pop('MPG')\\n\\nhorsepower = np.array(train_features['Horsepower'])\\n\\nhorsepower_normalizer = layers.Normalization(input_shape=[1,], axis=None)\\nhorsepower_normalizer.adapt(horsepower)\\n\\nhorsepower_model = tf.keras.Sequential([\\n    horsepower_normalizer,\\n    layers.Dense(units=1)\\n])\\n\\nhorsepower_model.summary()\\n\\nhorsepower_model.compile(\\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\\n    loss='mean_absolute_error')\\n\\n\\nhistory = horsepower_model.fit(\\n    train_features['Horsepower'],\\n    train_labels,\\n    epochs=100,\\n    # Suppress logging.\\n    verbose=0,\\n    # Calculate validation results on 20% of the training data.\\n    validation_split = 0.2)\\n\\nWrite a Python function using TensorFlow to create and compile a simple linear regression model with one dense layer. Train it on the classic California housing dataset.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["if \"few_shot\" not in df_fs.columns:\n","    df_fs[\"few_shot\"] = \"\"\n","\n","\n","for index, row in df_fs.iterrows():\n","    print(f\"Processing row {index+1}/{len(df_fs)}...\")\n","\n","    try:\n","        prompt_fs = row['prompt']\n","        response_fs = make_request_openai(prompt_fs)\n","        df_fs.at[index, \"few_shot\"] = response_fs\n","    except Exception as e:\n","        print(f\"Error generating direct response: {e}\")\n","        df_fs.at[index, \"few_shot\"] = f\"Error: {e}\"\n","\n","    time.sleep(DELAY_BETWEEN_REQUESTS)\n","\n","    df_fs.to_csv(\"/content/drive/MyDrive/Stanford NLP/prompts-step2 - responses_few_Shot_gpt.csv\", index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NWJAFbnJG4Hm","executionInfo":{"status":"ok","timestamp":1748741865270,"user_tz":420,"elapsed":114833,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"61988896-9ceb-4ec0-981f-551d2da5d7a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing row 1/8...\n","Processing row 2/8...\n","Processing row 3/8...\n","Processing row 4/8...\n","Processing row 5/8...\n","Processing row 6/8...\n","Processing row 7/8...\n","Processing row 8/8...\n"]}]},{"cell_type":"markdown","source":["##API extraction"],"metadata":{"id":"IlYqErdG1tg-"}},{"cell_type":"code","source":["df_api = pd.read_csv(\"/content/drive/MyDrive/Stanford NLP/api_documentation.csv\")\n","df_api"],"metadata":{"id":"UzDHqVfUJ_aM","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1748754780729,"user_tz":420,"elapsed":630,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}},"outputId":"02a308df-9afb-46d5-b980-8469184012ad"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                         API Component  \\\n","0                           tensorflow   \n","1                     tensorflow.keras   \n","2                           Sequential   \n","3                                Dense   \n","4                                Input   \n","5                          Concatenate   \n","6             fetch_california_housing   \n","7                  make_classification   \n","8                     train_test_split   \n","9                       StandardScaler   \n","10                  LogisticRegression   \n","11                       make_pipeline   \n","12                                 PCA   \n","13                               torch   \n","14                            torch.nn   \n","15                         torch.optim   \n","16                         torchvision   \n","17              torchvision.transforms   \n","18                 torch.nn.functional   \n","19                             Dataset   \n","20                          DataLoader   \n","21                torchvision.datasets   \n","22                            ToTensor   \n","23                               numpy   \n","24                              pandas   \n","25                   matplotlib.pyplot   \n","26                       AutoTokenizer   \n","27             DataCollatorWithPadding   \n","28  AutoModelForSequenceClassification   \n","29                   TrainingArguments   \n","30                             Trainer   \n","31                      notebook_login   \n","32                        load_dataset   \n","\n","                                        Documentation  \n","0   Top-level module of TensorFlow. By convention,...  \n","1   DO NOT EDIT.  This file was autogenerated. Do ...  \n","2   `Sequential` groups a linear stack of layers i...  \n","3   Just your regular densely-connected NN layer. ...  \n","4   Used to instantiate a Keras tensor.  A Keras t...  \n","5   Concatenates a list of inputs.  It takes as in...  \n","6   Load the California housing dataset (regressio...  \n","7   Generate a random n-class classification probl...  \n","8   Split arrays or matrices into random train and...  \n","9   Standardize features by removing the mean and ...  \n","10  Logistic Regression (aka logit, MaxEnt) classi...  \n","11  Construct a :class:`Pipeline` from the given e...  \n","12  Principal component analysis (PCA).  Linear di...  \n","13  The torch package contains data structures for...  \n","14                            No documentation found.  \n","15  :mod:`torch.optim` is a package implementing v...  \n","16                            No documentation found.  \n","17                            No documentation found.  \n","18                              Functional interface.  \n","19  An abstract class representing a :class:`Datas...  \n","20  Data loader combines a dataset and a sampler, ...  \n","21                            No documentation found.  \n","22  Convert a PIL Image or ndarray to tensor and s...  \n","23  NumPy =====  Provides   1. An array object of ...  \n","24  pandas - a powerful data analysis and manipula...  \n","25  `matplotlib.pyplot` is a state-based interface...  \n","26  This is a generic tokenizer class that will be...  \n","27  Data collator that will dynamically pad the in...  \n","28  This is a generic model class that will be ins...  \n","29  TrainingArguments is the subset of the argumen...  \n","30  Trainer is a simple but feature-complete train...  \n","31  Displays a widget to log in to the HF website ...  \n","32  Load a dataset from the Hugging Face Hub, or a...  "],"text/html":["\n","  <div id=\"df-5c668977-ef5a-4c1a-a5c3-d543c95d8256\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>API Component</th>\n","      <th>Documentation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>tensorflow</td>\n","      <td>Top-level module of TensorFlow. By convention,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>tensorflow.keras</td>\n","      <td>DO NOT EDIT.  This file was autogenerated. Do ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sequential</td>\n","      <td>`Sequential` groups a linear stack of layers i...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Dense</td>\n","      <td>Just your regular densely-connected NN layer. ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Input</td>\n","      <td>Used to instantiate a Keras tensor.  A Keras t...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Concatenate</td>\n","      <td>Concatenates a list of inputs.  It takes as in...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>fetch_california_housing</td>\n","      <td>Load the California housing dataset (regressio...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>make_classification</td>\n","      <td>Generate a random n-class classification probl...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>train_test_split</td>\n","      <td>Split arrays or matrices into random train and...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>StandardScaler</td>\n","      <td>Standardize features by removing the mean and ...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>LogisticRegression</td>\n","      <td>Logistic Regression (aka logit, MaxEnt) classi...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>make_pipeline</td>\n","      <td>Construct a :class:`Pipeline` from the given e...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>PCA</td>\n","      <td>Principal component analysis (PCA).  Linear di...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>torch</td>\n","      <td>The torch package contains data structures for...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>torch.nn</td>\n","      <td>No documentation found.</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>torch.optim</td>\n","      <td>:mod:`torch.optim` is a package implementing v...</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>torchvision</td>\n","      <td>No documentation found.</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>torchvision.transforms</td>\n","      <td>No documentation found.</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>torch.nn.functional</td>\n","      <td>Functional interface.</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Dataset</td>\n","      <td>An abstract class representing a :class:`Datas...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>DataLoader</td>\n","      <td>Data loader combines a dataset and a sampler, ...</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>torchvision.datasets</td>\n","      <td>No documentation found.</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>ToTensor</td>\n","      <td>Convert a PIL Image or ndarray to tensor and s...</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>numpy</td>\n","      <td>NumPy =====  Provides   1. An array object of ...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>pandas</td>\n","      <td>pandas - a powerful data analysis and manipula...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>matplotlib.pyplot</td>\n","      <td>`matplotlib.pyplot` is a state-based interface...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>AutoTokenizer</td>\n","      <td>This is a generic tokenizer class that will be...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>DataCollatorWithPadding</td>\n","      <td>Data collator that will dynamically pad the in...</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>AutoModelForSequenceClassification</td>\n","      <td>This is a generic model class that will be ins...</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>TrainingArguments</td>\n","      <td>TrainingArguments is the subset of the argumen...</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Trainer</td>\n","      <td>Trainer is a simple but feature-complete train...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>notebook_login</td>\n","      <td>Displays a widget to log in to the HF website ...</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>load_dataset</td>\n","      <td>Load a dataset from the Hugging Face Hub, or a...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c668977-ef5a-4c1a-a5c3-d543c95d8256')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5c668977-ef5a-4c1a-a5c3-d543c95d8256 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5c668977-ef5a-4c1a-a5c3-d543c95d8256');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-b64fe8c6-c466-46f4-9746-401b57c51066\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b64fe8c6-c466-46f4-9746-401b57c51066')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-b64fe8c6-c466-46f4-9746-401b57c51066 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_07ab005a-47ea-4ea2-a233-befd85edb515\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_api')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_07ab005a-47ea-4ea2-a233-befd85edb515 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_api');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_api","summary":"{\n  \"name\": \"df_api\",\n  \"rows\": 33,\n  \"fields\": [\n    {\n      \"column\": \"API Component\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"notebook_login\",\n          \"torch.optim\",\n          \"AutoTokenizer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Documentation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Trainer is a simple but feature-complete training and eval loop for PyTorch, optimized for \\ud83e\\udd17 Transformers.  Args:     model ([`PreTrainedModel`] or `torch.nn.Module`, *optional*):         The model to train, evaluate or use for predictions. If not provided, a `model_init` must be passed.          <Tip>          [`Trainer`] is optimized to work with the [`PreTrainedModel`] provided by the library. You can still use         your own models defined as `torch.nn.Module` as long as they work the same way as the \\ud83e\\udd17 Transformers         models.          </Tip>      args ([`TrainingArguments`], *optional*):         The arguments to tweak for training. Will default to a basic instance of [`TrainingArguments`] with the         `output_dir` set to a directory named *tmp_trainer* in the current directory if not provided.     data_collator (`DataCollator`, *optional*):         The function to use to form a batch from a list of elements of `train_dataset` or `eval_dataset`. Will         default to [`default_data_collator`] if no `processing_class` is provided, an instance of         [`DataCollatorWithPadding`] otherwise if the processing_class is a feature extractor or tokenizer.     train_dataset (Union[`torch.utils.data.Dataset`, `torch.utils.data.IterableDataset`, `datasets.Dataset`], *optional*):         The dataset to use for training. If it is a [`~datasets.Dataset`], columns not accepted by the         `model.forward()` method are automatically removed.          Note that if it's a `torch.utils.data.IterableDataset` with some randomization and you are training in a         distributed fashion, your iterable dataset should either use a internal attribute `generator` that is a         `torch.Generator` for the randomization that must be identical on all processes (and the Trainer will         manually set the seed of this `generator` at each epoch) or have a `set_epoch()` method that internally         sets the seed of the RNGs used.     eval_dataset (Union[`torch.utils.data.Dataset`, Dict[str, `torch.utils.data.Dataset`, `datasets.Dataset`]), *optional*):          The dataset to use for evaluation. If it is a [`~datasets.Dataset`], columns not accepted by the          `model.forward()` method are automatically removed. If it is a dictionary, it will evaluate on each          dataset prepending the dictionary key to the metric name.     processing_class (`PreTrainedTokenizerBase` or `BaseImageProcessor` or `FeatureExtractionMixin` or `ProcessorMixin`, *optional*):         Processing class used to process the data. If provided, will be used to automatically process the inputs         for the model, and it will be saved along the model to make it easier to rerun an interrupted training or         reuse the fine-tuned model.         This supersedes the `tokenizer` argument, which is now deprecated.     model_init (`Callable[[], PreTrainedModel]`, *optional*):         A function that instantiates the model to be used. If provided, each call to [`~Trainer.train`] will start         from a new instance of the model as given by this function.          The function may have zero argument, or a single one containing the optuna/Ray Tune/SigOpt trial object, to         be able to choose different architectures according to hyper parameters (such as layer count, sizes of         inner layers, dropout probabilities etc).     compute_loss_func (`Callable`, *optional*):         A function that accepts the raw model outputs, labels, and the number of items in the entire accumulated         batch (batch_size * gradient_accumulation_steps) and returns the loss. For example, see the default [loss function](https://github.com/huggingface/transformers/blob/052e652d6d53c2b26ffde87e039b723949a53493/src/transformers/trainer.py#L3618) used by [`Trainer`].     compute_metrics (`Callable[[EvalPrediction], Dict]`, *optional*):         The function that will be used to compute metrics at evaluation. Must take a [`EvalPrediction`] and return         a dictionary string to metric values. *Note* When passing TrainingArgs with `batch_eval_metrics` set to         `True`, your compute_metrics function must take a boolean `compute_result` argument. This will be triggered         after the last eval batch to signal that the function needs to calculate and return the global summary         statistics rather than accumulating the batch-level statistics     callbacks (List of [`TrainerCallback`], *optional*):         A list of callbacks to customize the training loop. Will add those to the list of default callbacks         detailed in [here](callback).          If you want to remove one of the default callbacks used, use the [`Trainer.remove_callback`] method.     optimizers (`Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`, *optional*, defaults to `(None, None)`):         A tuple containing the optimizer and the scheduler to use. Will default to an instance of [`AdamW`] on your         model and a scheduler given by [`get_linear_schedule_with_warmup`] controlled by `args`.     optimizer_cls_and_kwargs (`Tuple[Type[torch.optim.Optimizer], Dict[str, Any]]`, *optional*):         A tuple containing the optimizer class and keyword arguments to use.         Overrides `optim` and `optim_args` in `args`. Incompatible with the `optimizers` argument.          Unlike `optimizers`, this argument avoids the need to place model parameters on the correct devices before initializing the Trainer.     preprocess_logits_for_metrics (`Callable[[torch.Tensor, torch.Tensor], torch.Tensor]`, *optional*):         A function that preprocess the logits right before caching them at each evaluation step. Must take two         tensors, the logits and the labels, and return the logits once processed as desired. The modifications made         by this function will be reflected in the predictions received by `compute_metrics`.          Note that the labels (second parameter) will be `None` if the dataset does not have them.  Important attributes:      - **model** -- Always points to the core model. If using a transformers model, it will be a [`PreTrainedModel`]       subclass.     - **model_wrapped** -- Always points to the most external model in case one or more other modules wrap the       original model. This is the model that should be used for the forward pass. For example, under `DeepSpeed`,       the inner model is wrapped in `DeepSpeed` and then again in `torch.nn.DistributedDataParallel`. If the inner       model hasn't been wrapped, then `self.model_wrapped` is the same as `self.model`.     - **is_model_parallel** -- Whether or not a model has been switched to a model parallel mode (different from       data parallelism, this means some of the model layers are split on different GPUs).     - **place_model_on_device** -- Whether or not to automatically place the model on the device - it will be set       to `False` if model parallel or deepspeed is used, or if the default       `TrainingArguments.place_model_on_device` is overridden to return `False` .     - **is_in_train** -- Whether or not a model is currently running `train` (e.g. when `evaluate` is called while       in `train`)\",\n          \":mod:`torch.optim` is a package implementing various optimization algorithms.  Most commonly used methods are already supported, and the interface is general enough, so that more sophisticated ones can also be easily integrated in the future.\",\n          \"This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when created with the [`AutoTokenizer.from_pretrained`] class method.  This class cannot be instantiated directly using `__init__()` (throws an error).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["prompt=\"Given the following API documentation, extract a structured representation of the API, including types, functions, and their relationships: [API documentation] Provide the structured representation in JSON format.\""],"metadata":{"id":"HMjh3fXY2Z8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["json_outputs = []\n","\n","for index, row in df_api.iterrows():\n","    print(f\"Processing row {index+1}/{len(df_api)}...\")\n","\n","    try:\n","        prompt = (\n","            f\"Given the following API documentation, extract a structured representation of the API, including types, functions, and their relationships:\\n\"\n","            f\"{row['Documentation'].strip()}\\n\\n\"\n","            f\"Provide the structured representation in JSON format.\"\n","        )\n","\n","        response = make_request_openai(prompt)\n","    except Exception as e:\n","        print(f\"Error generating response: {e}\")\n","        response = f\"Error: {e}\"\n","\n","    json_outputs.append(response)\n","\n","    time.sleep(DELAY_BETWEEN_REQUESTS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OMtOaFNA2p5p","outputId":"14345b2f-0363-44fc-b7c3-721ade65ec79","executionInfo":{"status":"ok","timestamp":1748755213889,"user_tz":420,"elapsed":425774,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing row 1/33...\n","Processing row 2/33...\n","Processing row 3/33...\n","Processing row 4/33...\n","Processing row 5/33...\n","Processing row 6/33...\n","Processing row 7/33...\n","Processing row 8/33...\n","Processing row 9/33...\n","Processing row 10/33...\n","Processing row 11/33...\n","Processing row 12/33...\n","Processing row 13/33...\n","Processing row 14/33...\n","Processing row 15/33...\n","Processing row 16/33...\n","Processing row 17/33...\n","Processing row 18/33...\n","Processing row 19/33...\n","Processing row 20/33...\n","Processing row 21/33...\n","Processing row 22/33...\n","Processing row 23/33...\n","Processing row 24/33...\n","Processing row 25/33...\n","Processing row 26/33...\n","Processing row 27/33...\n","Processing row 28/33...\n","Processing row 29/33...\n","Processing row 30/33...\n","Processing row 31/33...\n","Processing row 32/33...\n","Processing row 33/33...\n"]}]},{"cell_type":"code","source":["df_results = pd.DataFrame({'api_extract': json_outputs})\n","\n","output_path = \"/content/drive/MyDrive/Stanford NLP/api_extraction_results_gpt.csv\"\n","df_results.to_csv(output_path, index=False)"],"metadata":{"id":"NUY2W_LY5iA3","executionInfo":{"status":"ok","timestamp":1748755213893,"user_tz":420,"elapsed":7,"user":{"displayName":"Neeharika Gupta","userId":"13434636909198909500"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["##Neurosymbolic Generation"],"metadata":{"id":"5TL4s6DuBcpx"}},{"cell_type":"code","source":[],"metadata":{"id":"Ljyzv4_2HhsW"},"execution_count":null,"outputs":[]}]}